{"cells":[{"cell_type":"markdown","metadata":{},"source":["<table>\n","<tr>\n","<td>V1 </td>\n","<td>Simple feature engineering</td>\n","<td>second</td>\n","</tr>\n","<tr>\n","<td>V2 </td>\n","<td>Add pressure and inefficiency</td>\n","<td>second</td>\n","</tr>    \n","</table>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["| Version   |      Date      |  Score | Score 2\n","|----------|:-------------:|------:|--:|\n","| Baseline |  20240110 | 6.407770748115235 |\n","| Imb, pressure, inefficiency |    20240110   |   6.302917211424277 ||\n","| Add WAP 30 Moving average | 20240112 |  6.302853946841688  ||\n","| Add WAP 60, 120, 240 Moving average | 20240112 |  6.3019380482507374 | 6.302636961287867 ||"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T11:10:59.777579Z","iopub.status.busy":"2023-11-01T11:10:59.777120Z","iopub.status.idle":"2023-11-01T11:10:59.784351Z","shell.execute_reply":"2023-11-01T11:10:59.783070Z","shell.execute_reply.started":"2023-11-01T11:10:59.777532Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import joblib \n","import os\n","import sklearn \n","\n","from load_data import load_data_from_csv"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["from data_preprocessor.data_preprocessor import CompositeDataPreprocessor, ReduceMemUsageDataPreprocessor, FillNaPreProcessor\n","from data_preprocessor.feature_engineering import EnrichDFDataPreprocessor, MovingAvgPreProcessor, RemoveIrrelevantFeaturesDataPreprocessor, DropTargetNADataPreprocessor\n","from data_preprocessor.polynomial_features import PolynomialFeaturesPreProcessor"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from data_generator.data_generator import DefaultTrainEvalDataGenerator, ManualKFoldDataGenerator\n","\n","from model_pipeline.lgb_pipeline import LGBModelPipelineFactory\n","from model_pipeline.xgb_pipeline import XGBModelPipelineFactory\n","from model_pipeline.cbt_pipeline import CatBoostModelPipelineFactory\n","\n","from model_post_processor.model_post_processor import CompositeModelPostProcessor, SaveModelPostProcessor\n","\n","from train_pipeline.train_pipeline import DefaultTrainPipeline\n","\n","from train_pipeline.train_pipeline_callbacks import MAECallback\n","from utils.scoring_utils import ScoringUtils\n","from model_pipeline.dummy_models import BaselineEstimator"]},{"cell_type":"markdown","metadata":{},"source":["## Data preprocessing pipeline"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["processors = [    \n","    ReduceMemUsageDataPreprocessor(),\n","    EnrichDFDataPreprocessor(),\n","    MovingAvgPreProcessor(\"wap\"),    \n","    DropTargetNADataPreprocessor(),    \n","    RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id', 'row_id']),\n","    FillNaPreProcessor(),\n","    PolynomialFeaturesPreProcessor(),\n","]\n","processor = CompositeDataPreprocessor(processors)"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T11:10:59.900936Z","iopub.status.busy":"2023-11-01T11:10:59.900331Z","iopub.status.idle":"2023-11-01T11:11:16.996176Z","shell.execute_reply":"2023-11-01T11:11:16.994733Z","shell.execute_reply.started":"2023-11-01T11:10:59.900901Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n","       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n","       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n","       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n","      dtype='object')\n"]}],"source":["# DATA_PATH = '/kaggle/input'\n","DATA_PATH = '..'\n","df_train, df_test, revealed_targets, sample_submission = load_data_from_csv(DATA_PATH)\n","print(df_train.columns)"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-process data"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing ReduceMemUsageDataPreprocessor...\n","Processing EnrichDFDataPreprocessor...\n","Processing MovingAvgPreProcessor...\n","Processing DropTargetNADataPreprocessor...\n","Processing RemoveIrrelevantFeaturesDataPreprocessor...\n","Processing FillNaPreProcessor...\n","Processing PolynomialFeaturesPreProcessor...\n"]},{"ename":"MemoryError","evalue":"Unable to allocate 32.0 GiB for an array with shape (5237892, 821) and data type float64","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mcolumns)\n","File \u001b[1;32mc:\\Users\\Florence\\Documents\\Repo\\optiver2023\\florence\\data_preprocessor\\data_preprocessor.py:15\u001b[0m, in \u001b[0;36mCompositeDataPreprocessor.apply\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessor\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_df\n","File \u001b[1;32mc:\\Users\\Florence\\Documents\\Repo\\optiver2023\\florence\\data_preprocessor\\polynomial_features.py:12\u001b[0m, in \u001b[0;36mPolynomialFeaturesPreProcessor.apply\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[0;32m     11\u001b[0m     poly \u001b[38;5;241m=\u001b[39m PolynomialFeatures(\u001b[38;5;241m2\u001b[39m, interaction_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpoly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n","File \u001b[1;32mc:\\Users\\Florence\\anaconda3\\envs\\optiver2023\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n","File \u001b[1;32mc:\\Users\\Florence\\anaconda3\\envs\\optiver2023\\lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n","File \u001b[1;32mc:\\Users\\Florence\\anaconda3\\envs\\optiver2023\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n","File \u001b[1;32mc:\\Users\\Florence\\anaconda3\\envs\\optiver2023\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:507\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    503\u001b[0m     XP \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mhstack(columns, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mtocsc()\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;66;03m# Do as if _min_degree = 0 and cut down array after the\u001b[39;00m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# computation, i.e. use _n_out_full instead of n_output_features_.\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m     XP \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_out_full\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# What follows is a faster implementation of:\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# for i, comb in enumerate(combinations):\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;66;03m#     XP[:, i] = X[:, comb].prod(1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m \n\u001b[0;32m    524\u001b[0m     \u001b[38;5;66;03m# degree 0 term\u001b[39;00m\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_bias:\n","\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 32.0 GiB for an array with shape (5237892, 821) and data type float64"]}],"source":["df_train = processor.apply(df_train)\n","print(df_train.shape[0])\n","print(df_train.columns)\n","display(df_train.tail())"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10</td>\n","      <td>20</td>\n","      <td>30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    a   b   c\n","0   1   2   3\n","1  10  20  30"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data = [{'a': 1, 'b': 2, 'c': 3},\n","        {'a': 10, 'b': 20, 'c': 30}]\n"," \n","# Creates DataFrame.\n","df = pd.DataFrame(data)\n","df"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00, 2.00e+00, 3.00e+00,\n","        2.00e+00, 3.00e+00, 6.00e+00, 1.00e+00, 2.00e+00, 3.00e+00,\n","        2.00e+00, 3.00e+00, 6.00e+00, 2.00e+00, 3.00e+00, 2.00e+00,\n","        3.00e+00, 6.00e+00, 6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01,\n","        6.00e+00, 9.00e+00, 1.80e+01, 6.00e+00, 1.20e+01, 1.80e+01,\n","        1.00e+00, 1.00e+00, 2.00e+00, 3.00e+00, 2.00e+00, 3.00e+00,\n","        6.00e+00, 1.00e+00, 2.00e+00, 3.00e+00, 2.00e+00, 3.00e+00,\n","        6.00e+00, 2.00e+00, 3.00e+00, 2.00e+00, 3.00e+00, 6.00e+00,\n","        6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01, 6.00e+00, 9.00e+00,\n","        1.80e+01, 6.00e+00, 1.20e+01, 1.80e+01, 1.00e+00, 2.00e+00,\n","        3.00e+00, 2.00e+00, 3.00e+00, 6.00e+00, 1.00e+00, 2.00e+00,\n","        3.00e+00, 2.00e+00, 3.00e+00, 6.00e+00, 2.00e+00, 3.00e+00,\n","        2.00e+00, 3.00e+00, 6.00e+00, 6.00e+00, 4.00e+00, 6.00e+00,\n","        1.20e+01, 6.00e+00, 9.00e+00, 1.80e+01, 6.00e+00, 1.20e+01,\n","        1.80e+01, 2.00e+00, 3.00e+00, 2.00e+00, 3.00e+00, 6.00e+00,\n","        1.00e+00, 2.00e+00, 3.00e+00, 2.00e+00, 3.00e+00, 6.00e+00,\n","        2.00e+00, 3.00e+00, 2.00e+00, 3.00e+00, 6.00e+00, 6.00e+00,\n","        4.00e+00, 6.00e+00, 1.20e+01, 6.00e+00, 9.00e+00, 1.80e+01,\n","        6.00e+00, 1.20e+01, 1.80e+01, 6.00e+00, 4.00e+00, 6.00e+00,\n","        1.20e+01, 2.00e+00, 4.00e+00, 6.00e+00, 4.00e+00, 6.00e+00,\n","        1.20e+01, 4.00e+00, 6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01,\n","        1.20e+01, 8.00e+00, 1.20e+01, 2.40e+01, 1.20e+01, 1.80e+01,\n","        3.60e+01, 1.20e+01, 2.40e+01, 3.60e+01, 6.00e+00, 9.00e+00,\n","        1.80e+01, 3.00e+00, 6.00e+00, 9.00e+00, 6.00e+00, 9.00e+00,\n","        1.80e+01, 6.00e+00, 9.00e+00, 6.00e+00, 9.00e+00, 1.80e+01,\n","        1.80e+01, 1.20e+01, 1.80e+01, 3.60e+01, 1.80e+01, 2.70e+01,\n","        5.40e+01, 1.80e+01, 3.60e+01, 5.40e+01, 6.00e+00, 1.20e+01,\n","        2.00e+00, 4.00e+00, 6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01,\n","        4.00e+00, 6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01, 1.20e+01,\n","        8.00e+00, 1.20e+01, 2.40e+01, 1.20e+01, 1.80e+01, 3.60e+01,\n","        1.20e+01, 2.40e+01, 3.60e+01, 1.80e+01, 3.00e+00, 6.00e+00,\n","        9.00e+00, 6.00e+00, 9.00e+00, 1.80e+01, 6.00e+00, 9.00e+00,\n","        6.00e+00, 9.00e+00, 1.80e+01, 1.80e+01, 1.20e+01, 1.80e+01,\n","        3.60e+01, 1.80e+01, 2.70e+01, 5.40e+01, 1.80e+01, 3.60e+01,\n","        5.40e+01, 6.00e+00, 1.20e+01, 1.80e+01, 1.20e+01, 1.80e+01,\n","        3.60e+01, 1.20e+01, 1.80e+01, 1.20e+01, 1.80e+01, 3.60e+01,\n","        3.60e+01, 2.40e+01, 3.60e+01, 7.20e+01, 3.60e+01, 5.40e+01,\n","        1.08e+02, 3.60e+01, 7.20e+01, 1.08e+02, 2.00e+00, 3.00e+00,\n","        2.00e+00, 3.00e+00, 6.00e+00, 2.00e+00, 3.00e+00, 2.00e+00,\n","        3.00e+00, 6.00e+00, 6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01,\n","        6.00e+00, 9.00e+00, 1.80e+01, 6.00e+00, 1.20e+01, 1.80e+01,\n","        6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01, 4.00e+00, 6.00e+00,\n","        4.00e+00, 6.00e+00, 1.20e+01, 1.20e+01, 8.00e+00, 1.20e+01,\n","        2.40e+01, 1.20e+01, 1.80e+01, 3.60e+01, 1.20e+01, 2.40e+01,\n","        3.60e+01, 6.00e+00, 9.00e+00, 1.80e+01, 6.00e+00, 9.00e+00,\n","        6.00e+00, 9.00e+00, 1.80e+01, 1.80e+01, 1.20e+01, 1.80e+01,\n","        3.60e+01, 1.80e+01, 2.70e+01, 5.40e+01, 1.80e+01, 3.60e+01,\n","        5.40e+01, 6.00e+00, 1.20e+01, 4.00e+00, 6.00e+00, 4.00e+00,\n","        6.00e+00, 1.20e+01, 1.20e+01, 8.00e+00, 1.20e+01, 2.40e+01,\n","        1.20e+01, 1.80e+01, 3.60e+01, 1.20e+01, 2.40e+01, 3.60e+01,\n","        1.80e+01, 6.00e+00, 9.00e+00, 6.00e+00, 9.00e+00, 1.80e+01,\n","        1.80e+01, 1.20e+01, 1.80e+01, 3.60e+01, 1.80e+01, 2.70e+01,\n","        5.40e+01, 1.80e+01, 3.60e+01, 5.40e+01, 1.20e+01, 1.80e+01,\n","        1.20e+01, 1.80e+01, 3.60e+01, 3.60e+01, 2.40e+01, 3.60e+01,\n","        7.20e+01, 3.60e+01, 5.40e+01, 1.08e+02, 3.60e+01, 7.20e+01,\n","        1.08e+02, 6.00e+00, 4.00e+00, 6.00e+00, 1.20e+01, 1.20e+01,\n","        8.00e+00, 1.20e+01, 2.40e+01, 1.20e+01, 1.80e+01, 3.60e+01,\n","        1.20e+01, 2.40e+01, 3.60e+01, 6.00e+00, 9.00e+00, 1.80e+01,\n","        1.80e+01, 1.20e+01, 1.80e+01, 3.60e+01, 1.80e+01, 2.70e+01,\n","        5.40e+01, 1.80e+01, 3.60e+01, 5.40e+01, 6.00e+00, 1.20e+01,\n","        1.20e+01, 8.00e+00, 1.20e+01, 2.40e+01, 1.20e+01, 1.80e+01,\n","        3.60e+01, 1.20e+01, 2.40e+01, 3.60e+01, 1.80e+01, 1.80e+01,\n","        1.20e+01, 1.80e+01, 3.60e+01, 1.80e+01, 2.70e+01, 5.40e+01,\n","        1.80e+01, 3.60e+01, 5.40e+01, 3.60e+01, 2.40e+01, 3.60e+01,\n","        7.20e+01, 3.60e+01, 5.40e+01, 1.08e+02, 3.60e+01, 7.20e+01,\n","        1.08e+02, 2.40e+01, 3.60e+01, 7.20e+01, 3.60e+01, 5.40e+01,\n","        1.08e+02, 3.60e+01, 7.20e+01, 1.08e+02, 2.40e+01, 4.80e+01,\n","        2.40e+01, 3.60e+01, 7.20e+01, 2.40e+01, 4.80e+01, 7.20e+01,\n","        7.20e+01, 3.60e+01, 5.40e+01, 1.08e+02, 3.60e+01, 7.20e+01,\n","        1.08e+02, 7.20e+01, 1.08e+02, 2.16e+02, 7.20e+01, 1.44e+02,\n","        2.16e+02, 5.40e+01, 1.08e+02, 3.60e+01, 7.20e+01, 1.08e+02,\n","        1.62e+02, 5.40e+01, 1.08e+02, 1.62e+02, 1.08e+02, 2.16e+02,\n","        3.24e+02, 7.20e+01, 1.08e+02, 2.16e+02],\n","       [1.00e+00, 1.00e+00, 1.00e+00, 1.00e+01, 2.00e+01, 3.00e+01,\n","        2.00e+02, 3.00e+02, 6.00e+02, 1.00e+01, 2.00e+01, 3.00e+01,\n","        2.00e+02, 3.00e+02, 6.00e+02, 2.00e+02, 3.00e+02, 2.00e+03,\n","        3.00e+03, 6.00e+03, 6.00e+02, 4.00e+03, 6.00e+03, 1.20e+04,\n","        6.00e+03, 9.00e+03, 1.80e+04, 6.00e+04, 1.20e+05, 1.80e+05,\n","        1.00e+00, 1.00e+01, 2.00e+01, 3.00e+01, 2.00e+02, 3.00e+02,\n","        6.00e+02, 1.00e+01, 2.00e+01, 3.00e+01, 2.00e+02, 3.00e+02,\n","        6.00e+02, 2.00e+02, 3.00e+02, 2.00e+03, 3.00e+03, 6.00e+03,\n","        6.00e+02, 4.00e+03, 6.00e+03, 1.20e+04, 6.00e+03, 9.00e+03,\n","        1.80e+04, 6.00e+04, 1.20e+05, 1.80e+05, 1.00e+01, 2.00e+01,\n","        3.00e+01, 2.00e+02, 3.00e+02, 6.00e+02, 1.00e+01, 2.00e+01,\n","        3.00e+01, 2.00e+02, 3.00e+02, 6.00e+02, 2.00e+02, 3.00e+02,\n","        2.00e+03, 3.00e+03, 6.00e+03, 6.00e+02, 4.00e+03, 6.00e+03,\n","        1.20e+04, 6.00e+03, 9.00e+03, 1.80e+04, 6.00e+04, 1.20e+05,\n","        1.80e+05, 2.00e+02, 3.00e+02, 2.00e+03, 3.00e+03, 6.00e+03,\n","        1.00e+02, 2.00e+02, 3.00e+02, 2.00e+03, 3.00e+03, 6.00e+03,\n","        2.00e+03, 3.00e+03, 2.00e+04, 3.00e+04, 6.00e+04, 6.00e+03,\n","        4.00e+04, 6.00e+04, 1.20e+05, 6.00e+04, 9.00e+04, 1.80e+05,\n","        6.00e+05, 1.20e+06, 1.80e+06, 6.00e+02, 4.00e+03, 6.00e+03,\n","        1.20e+04, 2.00e+02, 4.00e+02, 6.00e+02, 4.00e+03, 6.00e+03,\n","        1.20e+04, 4.00e+03, 6.00e+03, 4.00e+04, 6.00e+04, 1.20e+05,\n","        1.20e+04, 8.00e+04, 1.20e+05, 2.40e+05, 1.20e+05, 1.80e+05,\n","        3.60e+05, 1.20e+06, 2.40e+06, 3.60e+06, 6.00e+03, 9.00e+03,\n","        1.80e+04, 3.00e+02, 6.00e+02, 9.00e+02, 6.00e+03, 9.00e+03,\n","        1.80e+04, 6.00e+03, 9.00e+03, 6.00e+04, 9.00e+04, 1.80e+05,\n","        1.80e+04, 1.20e+05, 1.80e+05, 3.60e+05, 1.80e+05, 2.70e+05,\n","        5.40e+05, 1.80e+06, 3.60e+06, 5.40e+06, 6.00e+04, 1.20e+05,\n","        2.00e+03, 4.00e+03, 6.00e+03, 4.00e+04, 6.00e+04, 1.20e+05,\n","        4.00e+04, 6.00e+04, 4.00e+05, 6.00e+05, 1.20e+06, 1.20e+05,\n","        8.00e+05, 1.20e+06, 2.40e+06, 1.20e+06, 1.80e+06, 3.60e+06,\n","        1.20e+07, 2.40e+07, 3.60e+07, 1.80e+05, 3.00e+03, 6.00e+03,\n","        9.00e+03, 6.00e+04, 9.00e+04, 1.80e+05, 6.00e+04, 9.00e+04,\n","        6.00e+05, 9.00e+05, 1.80e+06, 1.80e+05, 1.20e+06, 1.80e+06,\n","        3.60e+06, 1.80e+06, 2.70e+06, 5.40e+06, 1.80e+07, 3.60e+07,\n","        5.40e+07, 6.00e+03, 1.20e+04, 1.80e+04, 1.20e+05, 1.80e+05,\n","        3.60e+05, 1.20e+05, 1.80e+05, 1.20e+06, 1.80e+06, 3.60e+06,\n","        3.60e+05, 2.40e+06, 3.60e+06, 7.20e+06, 3.60e+06, 5.40e+06,\n","        1.08e+07, 3.60e+07, 7.20e+07, 1.08e+08, 2.00e+02, 3.00e+02,\n","        2.00e+03, 3.00e+03, 6.00e+03, 2.00e+03, 3.00e+03, 2.00e+04,\n","        3.00e+04, 6.00e+04, 6.00e+03, 4.00e+04, 6.00e+04, 1.20e+05,\n","        6.00e+04, 9.00e+04, 1.80e+05, 6.00e+05, 1.20e+06, 1.80e+06,\n","        6.00e+02, 4.00e+03, 6.00e+03, 1.20e+04, 4.00e+03, 6.00e+03,\n","        4.00e+04, 6.00e+04, 1.20e+05, 1.20e+04, 8.00e+04, 1.20e+05,\n","        2.40e+05, 1.20e+05, 1.80e+05, 3.60e+05, 1.20e+06, 2.40e+06,\n","        3.60e+06, 6.00e+03, 9.00e+03, 1.80e+04, 6.00e+03, 9.00e+03,\n","        6.00e+04, 9.00e+04, 1.80e+05, 1.80e+04, 1.20e+05, 1.80e+05,\n","        3.60e+05, 1.80e+05, 2.70e+05, 5.40e+05, 1.80e+06, 3.60e+06,\n","        5.40e+06, 6.00e+04, 1.20e+05, 4.00e+04, 6.00e+04, 4.00e+05,\n","        6.00e+05, 1.20e+06, 1.20e+05, 8.00e+05, 1.20e+06, 2.40e+06,\n","        1.20e+06, 1.80e+06, 3.60e+06, 1.20e+07, 2.40e+07, 3.60e+07,\n","        1.80e+05, 6.00e+04, 9.00e+04, 6.00e+05, 9.00e+05, 1.80e+06,\n","        1.80e+05, 1.20e+06, 1.80e+06, 3.60e+06, 1.80e+06, 2.70e+06,\n","        5.40e+06, 1.80e+07, 3.60e+07, 5.40e+07, 1.20e+05, 1.80e+05,\n","        1.20e+06, 1.80e+06, 3.60e+06, 3.60e+05, 2.40e+06, 3.60e+06,\n","        7.20e+06, 3.60e+06, 5.40e+06, 1.08e+07, 3.60e+07, 7.20e+07,\n","        1.08e+08, 6.00e+04, 4.00e+05, 6.00e+05, 1.20e+06, 1.20e+05,\n","        8.00e+05, 1.20e+06, 2.40e+06, 1.20e+06, 1.80e+06, 3.60e+06,\n","        1.20e+07, 2.40e+07, 3.60e+07, 6.00e+05, 9.00e+05, 1.80e+06,\n","        1.80e+05, 1.20e+06, 1.80e+06, 3.60e+06, 1.80e+06, 2.70e+06,\n","        5.40e+06, 1.80e+07, 3.60e+07, 5.40e+07, 6.00e+06, 1.20e+07,\n","        1.20e+06, 8.00e+06, 1.20e+07, 2.40e+07, 1.20e+07, 1.80e+07,\n","        3.60e+07, 1.20e+08, 2.40e+08, 3.60e+08, 1.80e+07, 1.80e+06,\n","        1.20e+07, 1.80e+07, 3.60e+07, 1.80e+07, 2.70e+07, 5.40e+07,\n","        1.80e+08, 3.60e+08, 5.40e+08, 3.60e+06, 2.40e+07, 3.60e+07,\n","        7.20e+07, 3.60e+07, 5.40e+07, 1.08e+08, 3.60e+08, 7.20e+08,\n","        1.08e+09, 2.40e+06, 3.60e+06, 7.20e+06, 3.60e+06, 5.40e+06,\n","        1.08e+07, 3.60e+07, 7.20e+07, 1.08e+08, 2.40e+07, 4.80e+07,\n","        2.40e+07, 3.60e+07, 7.20e+07, 2.40e+08, 4.80e+08, 7.20e+08,\n","        7.20e+07, 3.60e+07, 5.40e+07, 1.08e+08, 3.60e+08, 7.20e+08,\n","        1.08e+09, 7.20e+07, 1.08e+08, 2.16e+08, 7.20e+08, 1.44e+09,\n","        2.16e+09, 5.40e+07, 1.08e+08, 3.60e+08, 7.20e+08, 1.08e+09,\n","        1.62e+08, 5.40e+08, 1.08e+09, 1.62e+09, 1.08e+09, 2.16e+09,\n","        3.24e+09, 7.20e+09, 1.08e+10, 2.16e+10]], dtype=float32)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import PolynomialFeatures\n","poly = PolynomialFeatures(2, interaction_only=True)\n","df = poly.fit_transform(df).astype(\"float32\")\n","df"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T11:13:04.265881Z","iopub.status.busy":"2023-11-01T11:13:04.264974Z","iopub.status.idle":"2023-11-01T11:13:04.288137Z","shell.execute_reply":"2023-11-01T11:13:04.286805Z","shell.execute_reply.started":"2023-11-01T11:13:04.265844Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["os.system('mkdir models')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T11:13:14.733558Z","iopub.status.busy":"2023-11-01T11:13:14.731900Z","iopub.status.idle":"2023-11-01T11:13:14.753956Z","shell.execute_reply":"2023-11-01T11:13:14.748586Z","shell.execute_reply.started":"2023-11-01T11:13:14.733375Z"},"trusted":true},"outputs":[],"source":["N_fold = 5\n","model_save_dir = './models/'"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["default_data_generator = DefaultTrainEvalDataGenerator()\n","k_fold_data_generator = ManualKFoldDataGenerator(n_fold=N_fold)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model_post_processor = CompositeModelPostProcessor([\n","    SaveModelPostProcessor(save_dir=model_save_dir)\n","])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["lgb_pipeline = DefaultTrainPipeline(LGBModelPipelineFactory(), k_fold_data_generator, model_post_processor, [MAECallback()])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["generate data\n"]},{"name":"stdout","output_type":"stream","text":["start training, num_train_eval_sets: 5\n","Training fold 0 - start\n","Training fold 0 - initialized\n","Training fold 0 - train size: (4190313, 25), eval size: (1047579, 25)\n","Training fold 0 - start training\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.645594 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 5668\n","[LightGBM] [Info] Number of data points in the train set: 4190313, number of used features: 24\n","[LightGBM] [Info] Start training from score -0.060201\n","Training until validation scores don't improve for 100 rounds\n","Did not meet early stopping. Best iteration is:\n","[50]\tvalid_0's l1: 6.40127\n","Training fold 0 - finished training\n","Training fold 0 - finished post processing\n","Training fold 0 - end\n","Training fold 1 - start\n","Training fold 1 - initialized\n","Training fold 1 - train size: (4190313, 25), eval size: (1047579, 25)\n","Training fold 1 - start training\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164588 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5668\n","[LightGBM] [Info] Number of data points in the train set: 4190313, number of used features: 24\n","[LightGBM] [Info] Start training from score -0.069737\n","Training until validation scores don't improve for 100 rounds\n","Did not meet early stopping. Best iteration is:\n","[50]\tvalid_0's l1: 6.25349\n","Training fold 1 - finished training\n","Training fold 1 - finished post processing\n","Training fold 1 - end\n","Training fold 2 - start\n","Training fold 2 - initialized\n","Training fold 2 - train size: (4190314, 25), eval size: (1047578, 25)\n","Training fold 2 - start training\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.567062 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 5668\n","[LightGBM] [Info] Number of data points in the train set: 4190314, number of used features: 24\n","[LightGBM] [Info] Start training from score -0.050068\n","Training until validation scores don't improve for 100 rounds\n","Did not meet early stopping. Best iteration is:\n","[50]\tvalid_0's l1: 6.20097\n","Training fold 2 - finished training\n","Training fold 2 - finished post processing\n","Training fold 2 - end\n","Training fold 3 - start\n","Training fold 3 - initialized\n","Training fold 3 - train size: (4190314, 25), eval size: (1047578, 25)\n","Training fold 3 - start training\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.838809 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 5668\n","[LightGBM] [Info] Number of data points in the train set: 4190314, number of used features: 24\n","[LightGBM] [Info] Start training from score -0.060201\n","Training until validation scores don't improve for 100 rounds\n","Did not meet early stopping. Best iteration is:\n","[50]\tvalid_0's l1: 6.26603\n","Training fold 3 - finished training\n","Training fold 3 - finished post processing\n","Training fold 3 - end\n","Training fold 4 - start\n","Training fold 4 - initialized\n","Training fold 4 - train size: (4190314, 25), eval size: (1047578, 25)\n","Training fold 4 - start training\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.955382 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 5668\n","[LightGBM] [Info] Number of data points in the train set: 4190314, number of used features: 24\n","[LightGBM] [Info] Start training from score -0.060201\n","Training until validation scores don't improve for 100 rounds\n","Did not meet early stopping. Best iteration is:\n","[50]\tvalid_0's l1: 6.39142\n","Training fold 4 - finished training\n","Training fold 4 - finished post processing\n","Training fold 4 - end\n","finished training, num_train_eval_sets: 5\n"]}],"source":["lgb_models, lgb_model_res, lgb_train_dfs, lgb_eval_dfs, lgb_num_train_eval_sets, lgb_callback_results = lgb_pipeline.train(df_train)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["6.302636961287867\n"]}],"source":["lgb_avg_mae = ScoringUtils.calculate_mae(lgb_models, lgb_eval_dfs)\n","print(lgb_avg_mae)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["6.407770748115235\n"]}],"source":["baseline_avg_mae = ScoringUtils.calculate_mae([BaselineEstimator()], [df_train])\n","print(baseline_avg_mae)"]},{"cell_type":"markdown","metadata":{},"source":["# Load"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["models = []"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:17:49.327487Z","iopub.status.idle":"2023-11-01T11:17:49.328007Z","shell.execute_reply":"2023-11-01T11:17:49.327809Z","shell.execute_reply.started":"2023-11-01T11:17:49.327786Z"},"trusted":true},"outputs":[],"source":["def load(modelname, fold):\n","    models.append(joblib.load(f'models/{modelname}_{fold}.model'))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:17:49.334708Z","iopub.status.idle":"2023-11-01T11:17:49.335259Z","shell.execute_reply":"2023-11-01T11:17:49.335057Z","shell.execute_reply.started":"2023-11-01T11:17:49.335036Z"},"trusted":true},"outputs":[],"source":["for i in range (0, 5):\n","    load('lgb', i)\n","    # load('xgb', i)\n","    # load('cbt', i)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:17:49.337877Z","iopub.status.idle":"2023-11-01T11:17:49.338313Z","shell.execute_reply":"2023-11-01T11:17:49.338140Z","shell.execute_reply.started":"2023-11-01T11:17:49.338120Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[LGBMRegressor(n_estimators=50, objective='regression_l1'),\n"," LGBMRegressor(n_estimators=50, objective='regression_l1'),\n"," LGBMRegressor(n_estimators=50, objective='regression_l1'),\n"," LGBMRegressor(n_estimators=50, objective='regression_l1'),\n"," LGBMRegressor(n_estimators=50, objective='regression_l1')]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["models"]},{"cell_type":"markdown","metadata":{},"source":["# Submit"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:17:49.339969Z","iopub.status.idle":"2023-11-01T11:17:49.340375Z","shell.execute_reply":"2023-11-01T11:17:49.340206Z","shell.execute_reply.started":"2023-11-01T11:17:49.340188Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'optiver2023'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptiver2023\u001b[39;00m\n\u001b[0;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m optiver2023\u001b[38;5;241m.\u001b[39mmake_env()\n\u001b[0;32m      3\u001b[0m iter_test \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39miter_test()\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optiver2023'"]}],"source":["import optiver2023\n","env = optiver2023.make_env()\n","iter_test = env.iter_test()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_processors = [\n","    EnrichDFDataPreprocessor(),\n","    RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id', 'row_id'])    \n","]\n","test_processor = CompositeDataPreprocessor(processors)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:17:49.346291Z","iopub.status.idle":"2023-11-01T11:17:49.346722Z","shell.execute_reply":"2023-11-01T11:17:49.346501Z","shell.execute_reply.started":"2023-11-01T11:17:49.346483Z"},"trusted":true},"outputs":[],"source":["counter = 0\n","cache = pd.DataFrame()\n","\n","for (test, revealed_targets, sample_prediction) in iter_test:\n","    test_ = processor.apply(test)\n","    cache = pd.concat([cache, test_], ignore_index=True, axis=0)  \n","    sample_prediction['target'] = np.mean([model.predict(test_) for model in models], 0)\n","    env.predict(sample_prediction)\n","    counter += 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sample_prediction['target'] = 0\n","# env.predict(sample_prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# counter = 0\n","# # sample_prediction['target'] = 0\n","# # env.predict(sample_prediction)\n","# for (test, revealed_targets, sample_prediction) in iter_test:\n","# #     print(test.shape)\n","#     test_ = enrich_df_with_features(test)[features]\n","# #     print(test_.shape)\n","# #     print(len(features))\n","# #     print(len(test_))\n","#     sample_prediction['target'] = np.mean([model.predict(test_) for model in models], 0)\n","#     env.predict(sample_prediction)\n","#     counter += 1"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
