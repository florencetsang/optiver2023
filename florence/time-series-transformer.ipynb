{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9-a3wNZ9mxWT",
   "metadata": {
    "id": "9-a3wNZ9mxWT"
   },
   "source": [
    "# Probabilistic Time Series Forecasting with ðŸ¤— Transformers\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Time series forecasting is an essential scientific and business problem and as such has also seen a lot of innovation recently with the use of [deep learning based](https://dl.acm.org/doi/abs/10.1145/3533382) models in addition to the [classical methods](https://otexts.com/fpp3/). An important difference between classical methods like ARIMA and novel deep learning methods is the following.\n",
    "\n",
    "##  Probabilistic Forecasting\n",
    "\n",
    "Typically, classical methods are fitted on each time series in a dataset individually. These are often referred to as  \"single\" or \"local\" methods. However, when dealing with a large amount of time series for some applications, it is beneficial to train a \"global\" model on all available time series, which enables the model to learn latent representations from many different sources.\n",
    "\n",
    "Some classical methods are point-valued (meaning, they just output a single value per time step) and models are trained by minimizing an L2 or L1 type of loss with respect to the ground truth data. However, since forecasts are often used in some real-world decision making pipeline, even with humans in the loop, it is much more beneficial to provide the uncertainties of predictions. This is also called \"probabilistic forecasting\", as opposed to \"point forecasting\". This entails modeling a probabilistic distribution, from which one can sample.\n",
    "\n",
    "So in short, rather than training local point forecasting models, we hope to train **global probabilistic** models. Deep learning is a great fit for this, as neural networks can learn representations from several related time series as well as model the uncertainty of the data.\n",
    "\n",
    "It is common in the probabilistic setting to learn the future parameters of some chosen parametric distribution, like Gaussian or Student-T; or learn the conditional quantile function; or use the framework of Conformal Prediction adapted to the time series setting. The choice of method does not affect the modeling aspect and thus can be typically thought of as yet another hyperparameter. One can always turn a probabilistic model into a point-forecasting model, by taking empirical means or medians.\n",
    "\n",
    "## The Time Series Transformer\n",
    "\n",
    "In terms of modeling time series data which are sequential in nature, as one can imagine, researchers have come up with models which use Recurrent Neural Networks (RNN) like LSTM or GRU, or Convolutional Networks (CNN), and more recently Transformer based methods which fit naturally to the time series forecasting setting.\n",
    "\n",
    "In this blog post, we're going to leverage the vanilla Transformer [(Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762) for the **univariate** probabilistic forecasting task (i.e. predicting each time series' 1-d distribution individually). The Encoder-Decoder Transformer is a natural choice for forecasting as it encapsulates several inductive biases nicely.\n",
    "\n",
    "To begin with, the use of an Encoder-Decoder architecture is helpful at inference time where typically for some logged data we wish to forecast some prediction steps into the future. This can be thought of as analogous to the text generation task where given some context, we sample the next token and pass it back into the decoder (also called \"autoregressive generation\"). Similarly here we can also, given some distribution type, sample from it to provide forecasts up until our desired prediction horizon. This is known as Greedy Sampling/Search and there is a great blog post about it [here](https://huggingface.co/blog/how-to-generate) for the NLP setting.\n",
    "\n",
    "Secondly, a Transformer helps us to train on time series data which might contain thousands of time points. It might not be feasible to input *all* the history of a time series at once to the model, due to the time- and memory constraints of the attention mechanism. Thus, one can consider some appropriate context window and sample this window and the subsequent prediction length sized window from the training data when constructing batches for stochastic gradient descent (SGD). The context sized window can be passed to the encoder and the prediction window to a *causal-masked* decoder. This means that the decoder can only look at previous time steps when learning the next value. This is equivalent to how one would train a vanilla Transformer for machine translation, referred to as \"teacher forcing\".\n",
    "\n",
    "Another benefit of Transformers over the other architectures is that we can incorporate missing values (which are common in the time series setting) as an additional mask to the encoder or decoder and still train without resorting to in-filling or imputation. This is equivalent to the `attention_mask` of models like BERT and GPT-2 in the Transformers library, to not include padding tokens in the computation of the attention matrix.\n",
    "\n",
    "A drawback of the Transformer architecture is the limit to the sizes of the context and prediction windows because of the quadratic compute and memory requirements of the vanilla Transformer, see [Tay et al., 2020](https://arxiv.org/abs/2009.06732). Additionally, since the Transformer is a powerful architecture, it might overfit or learn spurious correlations much more easily compared to other [methods](https://openreview.net/pdf?id=D7YBmfX_VQy).\n",
    "\n",
    "The ðŸ¤— Transformers library comes with a vanilla probabilistic time series Transformer model, simply called the [Time Series Transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transformer). In the sections below, we'll show how to train such a model on a custom dataset.\n",
    "\n",
    "## Set-up Environment\n",
    "\n",
    "First, let's install the necessary libraries: ðŸ¤— Transformers, ðŸ¤— Datasets, ðŸ¤— Evaluate,  ðŸ¤— Accelerate and [GluonTS](https://github.com/awslabs/gluonts).\n",
    "\n",
    "As we will show, GluonTS will be used for transforming the data to create features as well as for creating appropriate training, validation and test batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96a45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7AkJMJAunLP9",
   "metadata": {
    "executionInfo": {
     "elapsed": 11485,
     "status": "ok",
     "timestamp": 1706407130927,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "7AkJMJAunLP9"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9NeR_ZnSWP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9168,
     "status": "ok",
     "timestamp": 1706407140089,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "cd9NeR_ZnSWP",
    "outputId": "41be51d0-37f6-47c7-91a4-2106d7fd5c9b"
   },
   "outputs": [],
   "source": [
    "# !pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "xl9uzDOCKMoK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9979,
     "status": "ok",
     "timestamp": 1706407150053,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "xl9uzDOCKMoK",
    "outputId": "372ddea8-0c4c-4e80-b4a0-f2f6e1021fc7"
   },
   "outputs": [],
   "source": [
    "!pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3X4oByTHPudz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6463,
     "status": "ok",
     "timestamp": 1706407156505,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "3X4oByTHPudz",
    "outputId": "f97dfd7a-984b-4422-9224-97ff6c8b6bc8"
   },
   "outputs": [],
   "source": [
    "!pip install -q accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6kDYa76nU9J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11008,
     "status": "ok",
     "timestamp": 1706407167507,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "f6kDYa76nU9J",
    "outputId": "1e94e86d-fd29-4570-f5bd-656d9546be6a"
   },
   "outputs": [],
   "source": [
    "!pip install -q gluonts ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b1d8f4-71b9-4d53-bd0c-ea4d416a5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66fcd47d-af93-40a5-bf8d-f927365a02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0948047a-3530-4c2e-ab2b-89e2a77471c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41eb51de-7cf2-4e3c-bcc4-4335732be3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaebea67",
   "metadata": {
    "id": "eaebea67"
   },
   "source": [
    "We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c2cf63",
   "metadata": {
    "executionInfo": {
     "elapsed": 5430,
     "status": "ok",
     "timestamp": 1706407172918,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "98c2cf63"
   },
   "outputs": [],
   "source": [
    "# from transformers.utils import send_example_telemetry\n",
    "\n",
    "# send_example_telemetry(\"time_series_transformers_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f53f548c-a2a6-4070-8a74-101a4c6cea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split, InputDataset, LabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6bd6f37-a2c7-4c31-859f-e2b75268cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.time_feature import (\n",
    "    time_features_from_frequency_str,\n",
    "    TimeFeature,\n",
    "    get_lags_for_frequency,\n",
    ")\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.transform import (\n",
    "    AddAgeFeature,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    AsNumpyArray,\n",
    "    Chain,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    InstanceSplitter,\n",
    "    RemoveFields,\n",
    "    SelectFields,\n",
    "    SetField,\n",
    "    TestSplitSampler,\n",
    "    Transformation,\n",
    "    ValidationSplitSampler,\n",
    "    VstackFeatures,\n",
    "    RenameFields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4286d6a9-4a96-4675-b911-84cca5ed0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6949e0-ad8c-487a-82bc-9fbb153827cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0960404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fdd75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessor.data_preprocessor import CompositeDataPreprocessor\n",
    "from data_preprocessor.feature_engineering import EnrichDFDataPreprocessor, MovingAvgPreProcessor, RemoveIrrelevantFeaturesDataPreprocessor, DropTargetNADataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e167c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e146a20-f860-4595-91ac-d89bcf69bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from gluonts.time_feature import get_seasonality\n",
    "\n",
    "mae_metric = load(\"evaluate-metric/mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9462c8f-b52f-44c7-a645-e824057bced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4m_7_MKqmzfE",
   "metadata": {
    "id": "4m_7_MKqmzfE"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "In this blog post, we'll use the `tourism_monthly` dataset, which is available on the [Hugging Face Hub](https://huggingface.co/datasets/monash_tsf). This dataset contains monthly tourism volumes for 366 regions in Australia.\n",
    "\n",
    "This dataset is part of the [Monash Time Series Forecasting](https://forecastingdata.org/) repository, a collection of  time series datasets from a number of domains. It can be viewed as the GLUE benchmark of time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66f5744f-db2b-4b18-9d1e-2be28523c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../optiver-trading-at-the-close/train.csv\",\n",
    "    dtype={\n",
    "        \"seconds_in_bucket\": np.float32,\n",
    "        \"imbalance_size\": np.float32,\n",
    "        \"imbalance_buy_sell_flag\": np.float32,\n",
    "        \"reference_price\": np.float32,\n",
    "        \"matched_size\": np.float32,\n",
    "        \"far_price\": np.float32,\n",
    "        \"near_price\": np.float32,\n",
    "        \"bid_price\": np.float32,\n",
    "        \"bid_size\": np.float32,\n",
    "        \"ask_price\": np.float32,\n",
    "        \"ask_size\": np.float32,\n",
    "        \"wap\": np.float32,\n",
    "        \"target\": np.float32,\n",
    "        \"time_id\": np.float32,\n",
    "        \"date_id\": np.float32,\n",
    "    },\n",
    ")\n",
    "raw_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3ee5240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                     int64\n",
       "date_id                    float32\n",
       "seconds_in_bucket          float32\n",
       "imbalance_size             float32\n",
       "imbalance_buy_sell_flag    float32\n",
       "reference_price            float32\n",
       "matched_size               float32\n",
       "far_price                  float32\n",
       "near_price                 float32\n",
       "bid_price                  float32\n",
       "bid_size                   float32\n",
       "ask_price                  float32\n",
       "ask_size                   float32\n",
       "wap                        float32\n",
       "target                     float32\n",
       "time_id                    float32\n",
       "row_id                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b1e796a-6f3e-4159-b264-011a29ada63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54536555",
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [\n",
    "    EnrichDFDataPreprocessor(),\n",
    "    MovingAvgPreProcessor(\"wap\"),\n",
    "    # DropTargetNADataPreprocessor(),\n",
    "    # RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id', 'row_id']),\n",
    "]\n",
    "processor = CompositeDataPreprocessor(processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10300229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processor.apply(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4251ef52-31c8-440d-adc9-f2f7ceeca815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5237980\n",
      "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
      "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
      "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
      "       'ask_size', 'wap', 'target', 'time_id', 'row_id', 'imb_s1', 'imb_s2',\n",
      "       'reference_price_ask_price_bid_price_imb2',\n",
      "       'reference_price_ask_price_wap_imb2',\n",
      "       'reference_price_bid_price_wap_imb2', 'ask_price_bid_price_wap_imb2',\n",
      "       'pressure', 'inefficiency', 'wap_mov_avg_3_1', 'wap_mov_avg_6_3',\n",
      "       'wap_mov_avg_12_6', 'wap_mov_avg_24_12'],\n",
      "      dtype='object')\n",
      "stock_id                                      int64\n",
      "date_id                                     float32\n",
      "seconds_in_bucket                           float32\n",
      "imbalance_size                              float32\n",
      "imbalance_buy_sell_flag                     float32\n",
      "reference_price                             float32\n",
      "matched_size                                float32\n",
      "far_price                                   float32\n",
      "near_price                                  float32\n",
      "bid_price                                   float32\n",
      "bid_size                                    float32\n",
      "ask_price                                   float32\n",
      "ask_size                                    float32\n",
      "wap                                         float32\n",
      "target                                      float32\n",
      "time_id                                     float32\n",
      "row_id                                       object\n",
      "imb_s1                                      float32\n",
      "imb_s2                                      float32\n",
      "reference_price_ask_price_bid_price_imb2    float32\n",
      "reference_price_ask_price_wap_imb2          float32\n",
      "reference_price_bid_price_wap_imb2          float32\n",
      "ask_price_bid_price_wap_imb2                float32\n",
      "pressure                                    float32\n",
      "inefficiency                                float32\n",
      "wap_mov_avg_3_1                             float32\n",
      "wap_mov_avg_6_3                             float32\n",
      "wap_mov_avg_12_6                            float32\n",
      "wap_mov_avg_24_12                           float32\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>...</th>\n",
       "      <th>reference_price_ask_price_bid_price_imb2</th>\n",
       "      <th>reference_price_ask_price_wap_imb2</th>\n",
       "      <th>reference_price_bid_price_wap_imb2</th>\n",
       "      <th>ask_price_bid_price_wap_imb2</th>\n",
       "      <th>pressure</th>\n",
       "      <th>inefficiency</th>\n",
       "      <th>wap_mov_avg_3_1</th>\n",
       "      <th>wap_mov_avg_6_3</th>\n",
       "      <th>wap_mov_avg_12_6</th>\n",
       "      <th>wap_mov_avg_24_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380277.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>374.495636</td>\n",
       "      <td>0.237708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666039e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>...</td>\n",
       "      <td>12816.000000</td>\n",
       "      <td>6.344985</td>\n",
       "      <td>1744.000000</td>\n",
       "      <td>6.344985</td>\n",
       "      <td>51.531654</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.028799e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>...</td>\n",
       "      <td>4.662142</td>\n",
       "      <td>0.678887</td>\n",
       "      <td>2.776772</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>7.979763</td>\n",
       "      <td>0.166475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191768e+07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389746.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251127</td>\n",
       "      <td>0.252617</td>\n",
       "      <td>168.705887</td>\n",
       "      <td>239.466660</td>\n",
       "      <td>5126.105469</td>\n",
       "      <td>0.648061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.475500e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>...</td>\n",
       "      <td>3.507559</td>\n",
       "      <td>0.034131</td>\n",
       "      <td>3.391793</td>\n",
       "      <td>0.026360</td>\n",
       "      <td>27.148033</td>\n",
       "      <td>0.025058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237975</th>\n",
       "      <td>195</td>\n",
       "      <td>480.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2.440723e+06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>28280362.00</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.673913</td>\n",
       "      <td>-47.000000</td>\n",
       "      <td>9.673913</td>\n",
       "      <td>75.664818</td>\n",
       "      <td>0.086305</td>\n",
       "      <td>1.000345</td>\n",
       "      <td>1.000304</td>\n",
       "      <td>1.000318</td>\n",
       "      <td>1.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237976</th>\n",
       "      <td>196</td>\n",
       "      <td>480.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.495105e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>9187699.00</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460705</td>\n",
       "      <td>1.704028</td>\n",
       "      <td>0.038041</td>\n",
       "      <td>1.000816</td>\n",
       "      <td>1.000710</td>\n",
       "      <td>1.000560</td>\n",
       "      <td>1.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237977</th>\n",
       "      <td>197</td>\n",
       "      <td>480.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>12725436.00</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>...</td>\n",
       "      <td>1576.000000</td>\n",
       "      <td>10.857142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.857142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.996070</td>\n",
       "      <td>0.996130</td>\n",
       "      <td>0.996436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237978</th>\n",
       "      <td>198</td>\n",
       "      <td>480.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1.000899e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>94773272.00</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.341733</td>\n",
       "      <td>5.341733</td>\n",
       "      <td>1.494117</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>0.999116</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.999305</td>\n",
       "      <td>0.999313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237979</th>\n",
       "      <td>199</td>\n",
       "      <td>480.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1.884286e+06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>24073678.00</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>...</td>\n",
       "      <td>-1335.000000</td>\n",
       "      <td>1.190476</td>\n",
       "      <td>1216.000000</td>\n",
       "      <td>1.190476</td>\n",
       "      <td>7.534688</td>\n",
       "      <td>0.078272</td>\n",
       "      <td>1.002083</td>\n",
       "      <td>1.002337</td>\n",
       "      <td>1.002156</td>\n",
       "      <td>1.001945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5237980 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0               0      0.0                0.0    3.180603e+06   \n",
       "1               1      0.0                0.0    1.666039e+05   \n",
       "2               2      0.0                0.0    3.028799e+05   \n",
       "3               3      0.0                0.0    1.191768e+07   \n",
       "4               4      0.0                0.0    4.475500e+05   \n",
       "...           ...      ...                ...             ...   \n",
       "5237975       195    480.0              540.0    2.440723e+06   \n",
       "5237976       196    480.0              540.0    3.495105e+05   \n",
       "5237977       197    480.0              540.0    0.000000e+00   \n",
       "5237978       198    480.0              540.0    1.000899e+06   \n",
       "5237979       199    480.0              540.0    1.884286e+06   \n",
       "\n",
       "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                            1.0         0.999812   13380277.00        NaN   \n",
       "1                           -1.0         0.999896    1642214.25        NaN   \n",
       "2                           -1.0         0.999561    1819368.00        NaN   \n",
       "3                           -1.0         1.000171   18389746.00        NaN   \n",
       "4                           -1.0         0.999532   17860614.00        NaN   \n",
       "...                          ...              ...           ...        ...   \n",
       "5237975                     -1.0         1.000317   28280362.00   0.999734   \n",
       "5237976                     -1.0         1.000643    9187699.00   1.000129   \n",
       "5237977                      0.0         0.995789   12725436.00   0.995789   \n",
       "5237978                      1.0         0.999210   94773272.00   0.999210   \n",
       "5237979                     -1.0         1.002129   24073678.00   1.000859   \n",
       "\n",
       "         near_price  bid_price  ...  reference_price_ask_price_bid_price_imb2  \\\n",
       "0               NaN   0.999812  ...                                       NaN   \n",
       "1               NaN   0.999896  ...                              12816.000000   \n",
       "2               NaN   0.999403  ...                                  4.662142   \n",
       "3               NaN   0.999999  ...                                  0.251127   \n",
       "4               NaN   0.999394  ...                                  3.507559   \n",
       "...             ...        ...  ...                                       ...   \n",
       "5237975    0.999734   1.000317  ...                                       NaN   \n",
       "5237976    1.000386   1.000643  ...                                       NaN   \n",
       "5237977    0.995789   0.995789  ...                               1576.000000   \n",
       "5237978    0.999210   0.998970  ...                                  0.000000   \n",
       "5237979    1.001494   1.002129  ...                              -1335.000000   \n",
       "\n",
       "         reference_price_ask_price_wap_imb2  \\\n",
       "0                                  0.139683   \n",
       "1                                  6.344985   \n",
       "2                                  0.678887   \n",
       "3                                  0.252617   \n",
       "4                                  0.034131   \n",
       "...                                     ...   \n",
       "5237975                            9.673913   \n",
       "5237976                            0.460705   \n",
       "5237977                           10.857142   \n",
       "5237978                            0.000000   \n",
       "5237979                            1.190476   \n",
       "\n",
       "         reference_price_bid_price_wap_imb2  ask_price_bid_price_wap_imb2  \\\n",
       "0                                       NaN                      0.139683   \n",
       "1                               1744.000000                      6.344985   \n",
       "2                                  2.776772                      0.499201   \n",
       "3                                168.705887                    239.466660   \n",
       "4                                  3.391793                      0.026360   \n",
       "...                                     ...                           ...   \n",
       "5237975                          -47.000000                      9.673913   \n",
       "5237976                                 NaN                      0.460705   \n",
       "5237977                                 NaN                     10.857142   \n",
       "5237978                            5.341733                      5.341733   \n",
       "5237979                         1216.000000                      1.190476   \n",
       "\n",
       "            pressure  inefficiency wap_mov_avg_3_1  wap_mov_avg_6_3  \\\n",
       "0         374.495636      0.237708        1.000000              NaN   \n",
       "1          51.531654      0.101451        1.000000              NaN   \n",
       "2           7.979763      0.166475        1.000000              NaN   \n",
       "3        5126.105469      0.648061        1.000000              NaN   \n",
       "4          27.148033      0.025058        1.000000              NaN   \n",
       "...              ...           ...             ...              ...   \n",
       "5237975    75.664818      0.086305        1.000345         1.000304   \n",
       "5237976     1.704028      0.038041        1.000816         1.000710   \n",
       "5237977     0.000000      0.000000        0.995958         0.996070   \n",
       "5237978     1.494117      0.010561        0.999116         0.999218   \n",
       "5237979     7.534688      0.078272        1.002083         1.002337   \n",
       "\n",
       "         wap_mov_avg_12_6  wap_mov_avg_24_12  \n",
       "0                     NaN                NaN  \n",
       "1                     NaN                NaN  \n",
       "2                     NaN                NaN  \n",
       "3                     NaN                NaN  \n",
       "4                     NaN                NaN  \n",
       "...                   ...                ...  \n",
       "5237975          1.000318           1.000202  \n",
       "5237976          1.000560           1.000506  \n",
       "5237977          0.996130           0.996436  \n",
       "5237978          0.999305           0.999313  \n",
       "5237979          1.002156           1.001945  \n",
       "\n",
       "[5237980 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.shape[0])\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9cbce70-8e50-490e-8394-2f543f4cf4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 00:01:00',\n",
      "               '2018-01-01 00:02:00', '2018-01-01 00:03:00',\n",
      "               '2018-01-01 00:04:00', '2018-01-01 00:05:00',\n",
      "               '2018-01-01 00:06:00', '2018-01-01 00:07:00',\n",
      "               '2018-01-01 00:08:00', '2018-01-01 00:09:00',\n",
      "               ...\n",
      "               '2018-01-19 08:45:00', '2018-01-19 08:46:00',\n",
      "               '2018-01-19 08:47:00', '2018-01-19 08:48:00',\n",
      "               '2018-01-19 08:49:00', '2018-01-19 08:50:00',\n",
      "               '2018-01-19 08:51:00', '2018-01-19 08:52:00',\n",
      "               '2018-01-19 08:53:00', '2018-01-19 08:54:00'],\n",
      "              dtype='datetime64[ns]', length=26455, freq='T')\n",
      "PeriodIndex(['2018-01-01 00:00', '2018-01-01 00:01', '2018-01-01 00:02',\n",
      "             '2018-01-01 00:03', '2018-01-01 00:04', '2018-01-01 00:05',\n",
      "             '2018-01-01 00:06', '2018-01-01 00:07', '2018-01-01 00:08',\n",
      "             '2018-01-01 00:09',\n",
      "             ...\n",
      "             '2018-01-19 08:45', '2018-01-19 08:46', '2018-01-19 08:47',\n",
      "             '2018-01-19 08:48', '2018-01-19 08:49', '2018-01-19 08:50',\n",
      "             '2018-01-19 08:51', '2018-01-19 08:52', '2018-01-19 08:53',\n",
      "             '2018-01-19 08:54'],\n",
      "            dtype='period[T]', length=26455)\n",
      "0.0        2018-01-01 00:00\n",
      "1.0        2018-01-01 00:01\n",
      "2.0        2018-01-01 00:02\n",
      "3.0        2018-01-01 00:03\n",
      "4.0        2018-01-01 00:04\n",
      "                 ...       \n",
      "26450.0    2018-01-19 08:50\n",
      "26451.0    2018-01-19 08:51\n",
      "26452.0    2018-01-19 08:52\n",
      "26453.0    2018-01-19 08:53\n",
      "26454.0    2018-01-19 08:54\n",
      "Length: 26455, dtype: period[T]\n"
     ]
    }
   ],
   "source": [
    "max_time_id = df[\"time_id\"].max()\n",
    "dti_by_time_id = pd.date_range(\"2018-01-01\", periods=max_time_id + 1, freq=\"min\")\n",
    "print(dti_by_time_id)\n",
    "df_period_index_by_time_id = dti_by_time_id.to_period(\"1min\")\n",
    "print(df_period_index_by_time_id)\n",
    "df_index_by_time_id_series = df_period_index_by_time_id.to_series(index=np.arange(max_time_id + 1))\n",
    "print(df_index_by_time_id_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f434ad4-6557-4853-8f15-1e1f1c5bdac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp_by_time_id\"] = df[\"time_id\"].map(df_index_by_time_id_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "240775a6-4afa-4c8e-8159-f8a1b321004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = df[\"timestamp_by_time_id\"]\n",
    "df.index = df[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80162b91-c3a7-4633-9055-bf27f84d8546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>...</th>\n",
       "      <th>reference_price_bid_price_wap_imb2</th>\n",
       "      <th>ask_price_bid_price_wap_imb2</th>\n",
       "      <th>pressure</th>\n",
       "      <th>inefficiency</th>\n",
       "      <th>wap_mov_avg_3_1</th>\n",
       "      <th>wap_mov_avg_6_3</th>\n",
       "      <th>wap_mov_avg_12_6</th>\n",
       "      <th>wap_mov_avg_24_12</th>\n",
       "      <th>timestamp_by_time_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380277.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>374.495636</td>\n",
       "      <td>0.237708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666039e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>...</td>\n",
       "      <td>1744.000000</td>\n",
       "      <td>6.344985</td>\n",
       "      <td>51.531654</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.028799e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>...</td>\n",
       "      <td>2.776772</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>7.979763</td>\n",
       "      <td>0.166475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191768e+07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389746.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>168.705887</td>\n",
       "      <td>239.466660</td>\n",
       "      <td>5126.105469</td>\n",
       "      <td>0.648061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.475500e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>...</td>\n",
       "      <td>3.391793</td>\n",
       "      <td>0.026360</td>\n",
       "      <td>27.148033</td>\n",
       "      <td>0.025058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "timestamp                                                                \n",
       "2018-01-01 00:00         0      0.0                0.0    3.180603e+06   \n",
       "2018-01-01 00:00         1      0.0                0.0    1.666039e+05   \n",
       "2018-01-01 00:00         2      0.0                0.0    3.028799e+05   \n",
       "2018-01-01 00:00         3      0.0                0.0    1.191768e+07   \n",
       "2018-01-01 00:00         4      0.0                0.0    4.475500e+05   \n",
       "\n",
       "                  imbalance_buy_sell_flag  reference_price  matched_size  \\\n",
       "timestamp                                                                  \n",
       "2018-01-01 00:00                      1.0         0.999812   13380277.00   \n",
       "2018-01-01 00:00                     -1.0         0.999896    1642214.25   \n",
       "2018-01-01 00:00                     -1.0         0.999561    1819368.00   \n",
       "2018-01-01 00:00                     -1.0         1.000171   18389746.00   \n",
       "2018-01-01 00:00                     -1.0         0.999532   17860614.00   \n",
       "\n",
       "                  far_price  near_price  bid_price  ...  \\\n",
       "timestamp                                           ...   \n",
       "2018-01-01 00:00        NaN         NaN   0.999812  ...   \n",
       "2018-01-01 00:00        NaN         NaN   0.999896  ...   \n",
       "2018-01-01 00:00        NaN         NaN   0.999403  ...   \n",
       "2018-01-01 00:00        NaN         NaN   0.999999  ...   \n",
       "2018-01-01 00:00        NaN         NaN   0.999394  ...   \n",
       "\n",
       "                  reference_price_bid_price_wap_imb2  \\\n",
       "timestamp                                              \n",
       "2018-01-01 00:00                                 NaN   \n",
       "2018-01-01 00:00                         1744.000000   \n",
       "2018-01-01 00:00                            2.776772   \n",
       "2018-01-01 00:00                          168.705887   \n",
       "2018-01-01 00:00                            3.391793   \n",
       "\n",
       "                  ask_price_bid_price_wap_imb2     pressure  inefficiency  \\\n",
       "timestamp                                                                   \n",
       "2018-01-01 00:00                      0.139683   374.495636      0.237708   \n",
       "2018-01-01 00:00                      6.344985    51.531654      0.101451   \n",
       "2018-01-01 00:00                      0.499201     7.979763      0.166475   \n",
       "2018-01-01 00:00                    239.466660  5126.105469      0.648061   \n",
       "2018-01-01 00:00                      0.026360    27.148033      0.025058   \n",
       "\n",
       "                  wap_mov_avg_3_1  wap_mov_avg_6_3 wap_mov_avg_12_6  \\\n",
       "timestamp                                                             \n",
       "2018-01-01 00:00              1.0              NaN              NaN   \n",
       "2018-01-01 00:00              1.0              NaN              NaN   \n",
       "2018-01-01 00:00              1.0              NaN              NaN   \n",
       "2018-01-01 00:00              1.0              NaN              NaN   \n",
       "2018-01-01 00:00              1.0              NaN              NaN   \n",
       "\n",
       "                  wap_mov_avg_24_12  timestamp_by_time_id         timestamp  \n",
       "timestamp                                                                    \n",
       "2018-01-01 00:00                NaN      2018-01-01 00:00  2018-01-01 00:00  \n",
       "2018-01-01 00:00                NaN      2018-01-01 00:00  2018-01-01 00:00  \n",
       "2018-01-01 00:00                NaN      2018-01-01 00:00  2018-01-01 00:00  \n",
       "2018-01-01 00:00                NaN      2018-01-01 00:00  2018-01-01 00:00  \n",
       "2018-01-01 00:00                NaN      2018-01-01 00:00  2018-01-01 00:00  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a16f416-0068-4c22-8fe7-6aa436d5aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "PeriodIndex: 5237980 entries, 2018-01-01 00:00 to 2018-01-19 08:54\n",
      "Freq: T\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                    Dtype    \n",
      "---  ------                                    -----    \n",
      " 0   stock_id                                  int64    \n",
      " 1   date_id                                   float32  \n",
      " 2   seconds_in_bucket                         float32  \n",
      " 3   imbalance_size                            float32  \n",
      " 4   imbalance_buy_sell_flag                   float32  \n",
      " 5   reference_price                           float32  \n",
      " 6   matched_size                              float32  \n",
      " 7   far_price                                 float32  \n",
      " 8   near_price                                float32  \n",
      " 9   bid_price                                 float32  \n",
      " 10  bid_size                                  float32  \n",
      " 11  ask_price                                 float32  \n",
      " 12  ask_size                                  float32  \n",
      " 13  wap                                       float32  \n",
      " 14  target                                    float32  \n",
      " 15  time_id                                   float32  \n",
      " 16  row_id                                    object   \n",
      " 17  imb_s1                                    float32  \n",
      " 18  imb_s2                                    float32  \n",
      " 19  reference_price_ask_price_bid_price_imb2  float32  \n",
      " 20  reference_price_ask_price_wap_imb2        float32  \n",
      " 21  reference_price_bid_price_wap_imb2        float32  \n",
      " 22  ask_price_bid_price_wap_imb2              float32  \n",
      " 23  pressure                                  float32  \n",
      " 24  inefficiency                              float32  \n",
      " 25  wap_mov_avg_3_1                           float32  \n",
      " 26  wap_mov_avg_6_3                           float32  \n",
      " 27  wap_mov_avg_12_6                          float32  \n",
      " 28  wap_mov_avg_24_12                         float32  \n",
      " 29  timestamp_by_time_id                      period[T]\n",
      " 30  timestamp                                 period[T]\n",
      "dtypes: float32(27), int64(1), object(1), period[T](2)\n",
      "memory usage: 1.0 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6501c8d2-dfb8-4d3a-ad04-563bc408ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "stock_id\n",
      "0      26455\n",
      "1      26455\n",
      "2      26455\n",
      "3      26455\n",
      "4      26455\n",
      "       ...  \n",
      "195    26455\n",
      "196    26455\n",
      "197    26455\n",
      "198    26455\n",
      "199    21615\n",
      "Length: 200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby(\"stock_id\")\n",
    "print(len(df_grouped))\n",
    "print(df_grouped.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9010242-f760-43e7-aa60-c41c7a28507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict = {}\n",
    "for item_id, gdf in df_grouped:\n",
    "    dfs_dict[item_id] = gdf.reindex(df_index_by_time_id_series).drop(\"stock_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74cd5bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>...</th>\n",
       "      <th>reference_price_bid_price_wap_imb2</th>\n",
       "      <th>ask_price_bid_price_wap_imb2</th>\n",
       "      <th>pressure</th>\n",
       "      <th>inefficiency</th>\n",
       "      <th>wap_mov_avg_3_1</th>\n",
       "      <th>wap_mov_avg_6_3</th>\n",
       "      <th>wap_mov_avg_12_6</th>\n",
       "      <th>wap_mov_avg_24_12</th>\n",
       "      <th>timestamp_by_time_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139683</td>\n",
       "      <td>374.495636</td>\n",
       "      <td>0.237708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "      <td>2018-01-01 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.299773e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>15261107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13996.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.671131</td>\n",
       "      <td>1.671131</td>\n",
       "      <td>55.264420</td>\n",
       "      <td>0.085169</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:01</td>\n",
       "      <td>2018-01-01 00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.299773e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>15261107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>4665.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.568588</td>\n",
       "      <td>2.568588</td>\n",
       "      <td>107.139435</td>\n",
       "      <td>0.085169</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:02</td>\n",
       "      <td>2018-01-01 00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.299773e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>15261107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>55998.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810484</td>\n",
       "      <td>0.810484</td>\n",
       "      <td>28.131599</td>\n",
       "      <td>0.085169</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:03</td>\n",
       "      <td>2018-01-01 00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.218204e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>15342675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>14655.950195</td>\n",
       "      <td>...</td>\n",
       "      <td>1.809077</td>\n",
       "      <td>1.809077</td>\n",
       "      <td>45.779175</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>1.000081</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:04</td>\n",
       "      <td>2018-01-01 00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19 08:50</th>\n",
       "      <td>480.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>42161928.0</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>53827.199219</td>\n",
       "      <td>...</td>\n",
       "      <td>-806.000000</td>\n",
       "      <td>2.677459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.999185</td>\n",
       "      <td>0.999024</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>2018-01-19 08:50</td>\n",
       "      <td>2018-01-19 08:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19 08:51</th>\n",
       "      <td>480.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>42161928.0</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>157865.406250</td>\n",
       "      <td>...</td>\n",
       "      <td>-1662.000000</td>\n",
       "      <td>0.768675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999030</td>\n",
       "      <td>0.999190</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>2018-01-19 08:51</td>\n",
       "      <td>2018-01-19 08:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19 08:52</th>\n",
       "      <td>480.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>4.755137e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>41686416.0</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>57596.671875</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.823602</td>\n",
       "      <td>8.255923</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.999098</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>2018-01-19 08:52</td>\n",
       "      <td>2018-01-19 08:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19 08:53</th>\n",
       "      <td>480.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>4.755137e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>41686416.0</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>156610.531250</td>\n",
       "      <td>...</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>0.783718</td>\n",
       "      <td>3.036282</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.999174</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>0.999088</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>2018-01-19 08:53</td>\n",
       "      <td>2018-01-19 08:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19 08:54</th>\n",
       "      <td>480.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>4.755137e+05</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>41686416.0</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>110123.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.571776</td>\n",
       "      <td>4.318023</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.999152</td>\n",
       "      <td>0.999119</td>\n",
       "      <td>0.999013</td>\n",
       "      <td>2018-01-19 08:54</td>\n",
       "      <td>2018-01-19 08:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26455 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "2018-01-01 00:00      0.0                0.0    3.180603e+06   \n",
       "2018-01-01 00:01      0.0               10.0    1.299773e+06   \n",
       "2018-01-01 00:02      0.0               20.0    1.299773e+06   \n",
       "2018-01-01 00:03      0.0               30.0    1.299773e+06   \n",
       "2018-01-01 00:04      0.0               40.0    1.218204e+06   \n",
       "...                   ...                ...             ...   \n",
       "2018-01-19 08:50    480.0              500.0    0.000000e+00   \n",
       "2018-01-19 08:51    480.0              510.0    0.000000e+00   \n",
       "2018-01-19 08:52    480.0              520.0    4.755137e+05   \n",
       "2018-01-19 08:53    480.0              530.0    4.755137e+05   \n",
       "2018-01-19 08:54    480.0              540.0    4.755137e+05   \n",
       "\n",
       "                  imbalance_buy_sell_flag  reference_price  matched_size  \\\n",
       "2018-01-01 00:00                      1.0         0.999812    13380277.0   \n",
       "2018-01-01 00:01                      1.0         1.000026    15261107.0   \n",
       "2018-01-01 00:02                      1.0         0.999919    15261107.0   \n",
       "2018-01-01 00:03                      1.0         1.000133    15261107.0   \n",
       "2018-01-01 00:04                      1.0         1.000455    15342675.0   \n",
       "...                                   ...              ...           ...   \n",
       "2018-01-19 08:50                      0.0         0.999017    42161928.0   \n",
       "2018-01-19 08:51                      0.0         0.998842    42161928.0   \n",
       "2018-01-19 08:52                     -1.0         0.999193    41686416.0   \n",
       "2018-01-19 08:53                     -1.0         0.999193    41686416.0   \n",
       "2018-01-19 08:54                     -1.0         0.999193    41686416.0   \n",
       "\n",
       "                  far_price  near_price  bid_price       bid_size  ...  \\\n",
       "2018-01-01 00:00        NaN         NaN   0.999812   60651.500000  ...   \n",
       "2018-01-01 00:01        NaN         NaN   0.999812   13996.500000  ...   \n",
       "2018-01-01 00:02        NaN         NaN   0.999812    4665.500000  ...   \n",
       "2018-01-01 00:03        NaN         NaN   1.000026   55998.000000  ...   \n",
       "2018-01-01 00:04        NaN         NaN   1.000241   14655.950195  ...   \n",
       "...                     ...         ...        ...            ...  ...   \n",
       "2018-01-19 08:50   0.999017    0.999017   0.999017   53827.199219  ...   \n",
       "2018-01-19 08:51   0.998842    0.998842   0.998842  157865.406250  ...   \n",
       "2018-01-19 08:52   0.999017    0.999017   0.999193   57596.671875  ...   \n",
       "2018-01-19 08:53   0.999017    0.999017   0.999193  156610.531250  ...   \n",
       "2018-01-19 08:54   0.999017    0.999017   0.999193  110123.007812  ...   \n",
       "\n",
       "                  reference_price_bid_price_wap_imb2  \\\n",
       "2018-01-01 00:00                                 NaN   \n",
       "2018-01-01 00:01                            1.671131   \n",
       "2018-01-01 00:02                            2.568588   \n",
       "2018-01-01 00:03                            0.810484   \n",
       "2018-01-01 00:04                            1.809077   \n",
       "...                                              ...   \n",
       "2018-01-19 08:50                         -806.000000   \n",
       "2018-01-19 08:51                        -1662.000000   \n",
       "2018-01-19 08:52                                 NaN   \n",
       "2018-01-19 08:53                          821.000000   \n",
       "2018-01-19 08:54                                 NaN   \n",
       "\n",
       "                  ask_price_bid_price_wap_imb2    pressure  inefficiency  \\\n",
       "2018-01-01 00:00                      0.139683  374.495636      0.237708   \n",
       "2018-01-01 00:01                      1.671131   55.264420      0.085169   \n",
       "2018-01-01 00:02                      2.568588  107.139435      0.085169   \n",
       "2018-01-01 00:03                      0.810484   28.131599      0.085169   \n",
       "2018-01-01 00:04                      1.809077   45.779175      0.079400   \n",
       "...                                        ...         ...           ...   \n",
       "2018-01-19 08:50                      2.677459    0.000000      0.000000   \n",
       "2018-01-19 08:51                      0.768675    0.000000      0.000000   \n",
       "2018-01-19 08:52                      0.823602    8.255923      0.011407   \n",
       "2018-01-19 08:53                      0.783718    3.036282      0.011407   \n",
       "2018-01-19 08:54                      2.571776    4.318023      0.011407   \n",
       "\n",
       "                  wap_mov_avg_3_1 wap_mov_avg_6_3  wap_mov_avg_12_6  \\\n",
       "2018-01-01 00:00         1.000000             NaN               NaN   \n",
       "2018-01-01 00:01         0.999946             NaN               NaN   \n",
       "2018-01-01 00:02         0.999911        0.999911               NaN   \n",
       "2018-01-01 00:03         0.999940        0.999955               NaN   \n",
       "2018-01-01 00:04         1.000081        1.000027               NaN   \n",
       "...                           ...             ...               ...   \n",
       "2018-01-19 08:50         0.999158        0.999185          0.999024   \n",
       "2018-01-19 08:51         0.999030        0.999190          0.999027   \n",
       "2018-01-19 08:52         0.999098        0.999166          0.999057   \n",
       "2018-01-19 08:53         0.999174        0.999166          0.999088   \n",
       "2018-01-19 08:54         0.999274        0.999152          0.999119   \n",
       "\n",
       "                  wap_mov_avg_24_12  timestamp_by_time_id         timestamp  \n",
       "2018-01-01 00:00                NaN      2018-01-01 00:00  2018-01-01 00:00  \n",
       "2018-01-01 00:01                NaN      2018-01-01 00:01  2018-01-01 00:01  \n",
       "2018-01-01 00:02                NaN      2018-01-01 00:02  2018-01-01 00:02  \n",
       "2018-01-01 00:03                NaN      2018-01-01 00:03  2018-01-01 00:03  \n",
       "2018-01-01 00:04                NaN      2018-01-01 00:04  2018-01-01 00:04  \n",
       "...                             ...                   ...               ...  \n",
       "2018-01-19 08:50           0.998936      2018-01-19 08:50  2018-01-19 08:50  \n",
       "2018-01-19 08:51           0.998944      2018-01-19 08:51  2018-01-19 08:51  \n",
       "2018-01-19 08:52           0.998952      2018-01-19 08:52  2018-01-19 08:52  \n",
       "2018-01-19 08:53           0.998969      2018-01-19 08:53  2018-01-19 08:53  \n",
       "2018-01-19 08:54           0.999013      2018-01-19 08:54  2018-01-19 08:54  \n",
       "\n",
       "[26455 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c1e4476-cc0c-4cd8-88c4-2454f6fda343",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item_id, gdf in dfs_dict.items():\n",
    "    gdf[gdf.columns.difference([\"target\"])] = gdf[gdf.columns.difference([\"target\"])].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aeaf9af2-2cb7-4812-bea3-e6bb41179434",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50d90dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id', 'imb_s1', 'imb_s2',\n",
       "       'reference_price_ask_price_bid_price_imb2',\n",
       "       'reference_price_ask_price_wap_imb2',\n",
       "       'reference_price_bid_price_wap_imb2', 'ask_price_bid_price_wap_imb2',\n",
       "       'pressure', 'inefficiency', 'wap_mov_avg_3_1', 'wap_mov_avg_6_3',\n",
       "       'wap_mov_avg_12_6', 'wap_mov_avg_24_12', 'timestamp_by_time_id',\n",
       "       'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b45bef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 ['date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'time_id', 'imb_s1', 'imb_s2', 'reference_price_ask_price_bid_price_imb2', 'reference_price_ask_price_wap_imb2', 'reference_price_bid_price_wap_imb2', 'ask_price_bid_price_wap_imb2', 'pressure', 'inefficiency', 'wap_mov_avg_3_1', 'wap_mov_avg_6_3', 'wap_mov_avg_12_6', 'wap_mov_avg_24_12']\n"
     ]
    }
   ],
   "source": [
    "feat_dynamic_real = [column for column in df.columns if column not in [\n",
    "    \"stock_id\",\n",
    "    # \"date_id\",\n",
    "    \"target\",\n",
    "    # \"time_id\",\n",
    "    \"row_id\",\n",
    "    \"timestamp_by_time_id\",\n",
    "    \"timestamp\"\n",
    "]]\n",
    "print(len(feat_dynamic_real), feat_dynamic_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c6a0cd5-bc5d-46d8-82f3-8a2bea713457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_dynamic_real = [\"imbalance_size\", \"reference_price\", \"matched_size\"]\n",
    "# feat_dynamic_real = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b850ef9-8b48-4a05-9fa7-7d9162ef1abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataset<size=200, freq=1min, num_feat_dynamic_real=26, num_past_feat_dynamic_real=0, num_feat_static_real=0, num_feat_static_cat=0, static_cardinalities=[]>\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "dataset = PandasDataset(dfs_dict, target=\"target\", feat_dynamic_real=feat_dynamic_real, freq=freq, assume_sorted=False)\n",
    "print(dataset)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d99cd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f26a69a0-b30f-42df-9538-2163a4bf5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_length = 55 * 20\n",
    "# window will not overlap\n",
    "validation_window_size = int(validation_length / prediction_length)\n",
    "\n",
    "# Split the data for training and testing\n",
    "training_data, test_gen = split(dataset, offset=-validation_length)\n",
    "test_data = test_gen.generate_instances(prediction_length=prediction_length, windows=validation_window_size)\n",
    "\n",
    "val_data, _ = split(dataset, offset=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "543234f4-2418-437b-9e01-c927e06fa3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 220000 220000\n",
      "TrainingDataset(dataset=PandasDataset<size=200, freq=1min, num_feat_dynamic_real=26, num_past_feat_dynamic_real=0, num_feat_static_real=0, num_feat_static_cat=0, static_cardinalities=[]>, splitter=OffsetSplitter(offset=-1100))\n",
      "InputDataset(test_data=TestData(dataset=PandasDataset<size=200, freq=1min, num_feat_dynamic_real=26, num_past_feat_dynamic_real=0, num_feat_static_real=0, num_feat_static_cat=0, static_cardinalities=[]>, splitter=OffsetSplitter(offset=-1100), prediction_length=1, windows=1100, distance=None, max_history=None))\n",
      "LabelDataset(test_data=TestData(dataset=PandasDataset<size=200, freq=1min, num_feat_dynamic_real=26, num_past_feat_dynamic_real=0, num_feat_static_real=0, num_feat_static_cat=0, static_cardinalities=[]>, splitter=OffsetSplitter(offset=-1100), prediction_length=1, windows=1100, distance=None, max_history=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = training_data\n",
    "test_data_input_dataset = InputDataset(test_data)\n",
    "test_data_label_dataset = LabelDataset(test_data)\n",
    "print(len(train_dataset), len(test_data_input_dataset), len(test_data_label_dataset))\n",
    "print(train_dataset)\n",
    "print(test_data_input_dataset)\n",
    "print(test_data_label_dataset)\n",
    "\n",
    "train_dataset_iter = iter(training_data)\n",
    "test_data_input_dataset_iter = iter(test_data_input_dataset)\n",
    "test_data_label_dataset_iter = iter(test_data_label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bcba3c0-b73c-4026-9ffb-f6e808f634b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "TrainingDataset(dataset=PandasDataset<size=200, freq=1min, num_feat_dynamic_real=26, num_past_feat_dynamic_real=0, num_feat_static_real=0, num_feat_static_cat=0, static_cardinalities=[]>, splitter=OffsetSplitter(offset=-1))\n",
      "(26454,)\n"
     ]
    }
   ],
   "source": [
    "print(len(val_data))\n",
    "print(val_data)\n",
    "print(next(iter(val_data))[\"target\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb3d0d4d-284c-4d50-942e-7a4afed2594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_sample(sample):\n",
    "    print(f\"sample snippet: {sample}\")\n",
    "    print(f\"sample dict keys: {sample.keys()}\")\n",
    "    print(f'start: {sample[\"start\"]} {type(sample[\"start\"])}')\n",
    "    print(f'target shape: {type(sample[\"target\"])} {sample[\"target\"].shape}')\n",
    "    print(f'item id: {sample[\"item_id\"]}')\n",
    "    if \"feat_dynamic_real\" in sample:\n",
    "        print(f'feat_dynamic_real\": {type(sample[\"feat_dynamic_real\"])} {sample[\"feat_dynamic_real\"].shape} {sample[\"feat_dynamic_real\"].dtype}')\n",
    "    else:\n",
    "        print(\"no feat_dynamic_real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f183bee-66e6-4a5f-8ea4-973148980c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample snippet: {'start': Period('2018-01-01 00:00', 'T'), 'target': array([-3.029704  ,  0.38981438,  4.220009  , ..., -4.580021  ,\n",
      "       -6.740093  ,  0.61035156], dtype=float32), 'item_id': 0, 'feat_dynamic_real': array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 4.6000000e+02,\n",
      "        4.6000000e+02, 4.6000000e+02],\n",
      "       [0.0000000e+00, 1.0000000e+01, 2.0000000e+01, ..., 5.2000000e+02,\n",
      "        5.3000000e+02, 5.4000000e+02],\n",
      "       [3.1806028e+06, 1.2997728e+06, 1.2997728e+06, ..., 3.3379682e+06,\n",
      "        3.3363655e+06, 3.3363655e+06],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 9.9991131e-01, ..., 1.0021669e+00,\n",
      "        1.0021746e+00, 1.0021343e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0019615e+00,\n",
      "        1.0020020e+00, 1.0020415e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0019550e+00,\n",
      "        1.0019579e+00, 1.0019501e+00]], dtype=float32)}\n",
      "sample dict keys: dict_keys(['start', 'target', 'item_id', 'feat_dynamic_real'])\n",
      "start: 2018-01-01 00:00 <class 'pandas._libs.tslibs.period.Period'>\n",
      "target shape: <class 'numpy.ndarray'> (25355,)\n",
      "item id: 0\n",
      "feat_dynamic_real\": <class 'numpy.ndarray'> (26, 25355) float32\n"
     ]
    }
   ],
   "source": [
    "train_sample = next(train_dataset_iter)\n",
    "print_data_sample(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe86c160-169d-45d5-8597-efdbbf380bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample snippet: {'start': Period('2018-01-01 00:00', 'T'), 'target': array([-3.029704  ,  0.38981438,  4.220009  , ..., -4.580021  ,\n",
      "       -6.740093  ,  0.61035156], dtype=float32), 'item_id': 0, 'feat_dynamic_real': array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 4.6000000e+02,\n",
      "        4.6000000e+02, 4.6100000e+02],\n",
      "       [0.0000000e+00, 1.0000000e+01, 2.0000000e+01, ..., 5.3000000e+02,\n",
      "        5.4000000e+02, 0.0000000e+00],\n",
      "       [3.1806028e+06, 1.2997728e+06, 1.2997728e+06, ..., 3.3363655e+06,\n",
      "        3.3363655e+06, 1.0247004e+06],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 9.9991131e-01, ..., 1.0021746e+00,\n",
      "        1.0021343e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0020020e+00,\n",
      "        1.0020415e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0019579e+00,\n",
      "        1.0019501e+00, 0.0000000e+00]], dtype=float32)}\n",
      "sample dict keys: dict_keys(['start', 'target', 'item_id', 'feat_dynamic_real'])\n",
      "start: 2018-01-01 00:00 <class 'pandas._libs.tslibs.period.Period'>\n",
      "target shape: <class 'numpy.ndarray'> (25355,)\n",
      "item id: 0\n",
      "feat_dynamic_real\": <class 'numpy.ndarray'> (26, 25356) float32\n",
      "sample snippet: {'start': Period('2018-01-18 14:35', 'T'), 'target': array([2.900362], dtype=float32), 'item_id': 0, 'feat_dynamic_real': array([[ 4.61000000e+02,  4.61000000e+02],\n",
      "       [ 0.00000000e+00,  1.00000000e+01],\n",
      "       [ 1.02470038e+06,  1.79978062e+06],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [ 1.00033104e+00,  9.99993026e-01],\n",
      "       [ 1.52228570e+07,  1.52248740e+07],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 9.99993026e-01,  9.99825001e-01],\n",
      "       [ 1.30504004e+03,  2.16481504e+04],\n",
      "       [ 1.00033104e+00,  9.99993026e-01],\n",
      "       [ 6.59267422e+04,  3.04904805e+04],\n",
      "       [ 1.00000000e+00,  9.99894977e-01],\n",
      "       [ 2.53550000e+04,  2.53560000e+04],\n",
      "       [-9.61177886e-01, -1.69592679e-01],\n",
      "       [-8.73864114e-01, -7.88567722e-01],\n",
      "       [ 0.00000000e+00, -7.08968437e-04],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 4.83130417e+01,  1.40323961e+00],\n",
      "       [ 4.83130417e+01,  1.40323961e+00],\n",
      "       [ 1.55430155e+01,  5.90276260e+01],\n",
      "       [ 6.73132762e-02,  1.18213169e-01],\n",
      "       [ 1.00000000e+00,  9.99947488e-01],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]], dtype=float32)}\n",
      "sample dict keys: dict_keys(['start', 'target', 'item_id', 'feat_dynamic_real'])\n",
      "start: 2018-01-18 14:35 <class 'pandas._libs.tslibs.period.Period'>\n",
      "target shape: <class 'numpy.ndarray'> (1,)\n",
      "item id: 0\n",
      "feat_dynamic_real\": <class 'numpy.ndarray'> (26, 2) float32\n",
      "----------\n",
      "sample snippet: {'start': Period('2018-01-01 00:00', 'T'), 'target': array([-3.029704  ,  0.38981438,  4.220009  , ..., -6.740093  ,\n",
      "        0.61035156,  2.900362  ], dtype=float32), 'item_id': 0, 'feat_dynamic_real': array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 4.6000000e+02,\n",
      "        4.6100000e+02, 4.6100000e+02],\n",
      "       [0.0000000e+00, 1.0000000e+01, 2.0000000e+01, ..., 5.4000000e+02,\n",
      "        0.0000000e+00, 1.0000000e+01],\n",
      "       [3.1806028e+06, 1.2997728e+06, 1.2997728e+06, ..., 3.3363655e+06,\n",
      "        1.0247004e+06, 1.7997806e+06],\n",
      "       ...,\n",
      "       [0.0000000e+00, 0.0000000e+00, 9.9991131e-01, ..., 1.0021343e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0020415e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0019501e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32)}\n",
      "sample dict keys: dict_keys(['start', 'target', 'item_id', 'feat_dynamic_real'])\n",
      "start: 2018-01-01 00:00 <class 'pandas._libs.tslibs.period.Period'>\n",
      "target shape: <class 'numpy.ndarray'> (25356,)\n",
      "item id: 0\n",
      "feat_dynamic_real\": <class 'numpy.ndarray'> (26, 25357) float32\n",
      "sample snippet: {'start': Period('2018-01-18 14:36', 'T'), 'target': array([8.339882], dtype=float32), 'item_id': 0, 'feat_dynamic_real': array([[ 4.6100000e+02,  4.6100000e+02],\n",
      "       [ 1.0000000e+01,  2.0000000e+01],\n",
      "       [ 1.7997806e+06,  1.7997806e+06],\n",
      "       [ 1.0000000e+00,  1.0000000e+00],\n",
      "       [ 9.9999303e-01,  9.9999303e-01],\n",
      "       [ 1.5224874e+07,  1.5224874e+07],\n",
      "       [ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 9.9982500e-01,  9.9982500e-01],\n",
      "       [ 2.1648150e+04,  1.8326789e+04],\n",
      "       [ 9.9999303e-01,  9.9999303e-01],\n",
      "       [ 3.0490480e+04,  4.2354480e+04],\n",
      "       [ 9.9989498e-01,  9.9987602e-01],\n",
      "       [ 2.5356000e+04,  2.5357000e+04],\n",
      "       [-1.6959268e-01, -3.9596555e-01],\n",
      "       [-7.8856772e-01, -7.8856772e-01],\n",
      "       [-7.0896844e-04, -7.0896844e-04],\n",
      "       [ 0.0000000e+00, -1.0178117e-03],\n",
      "       [ 1.4032396e+00,  2.2893815e+00],\n",
      "       [ 1.4032396e+00,  2.2893815e+00],\n",
      "       [ 5.9027626e+01,  4.2493275e+01],\n",
      "       [ 1.1821317e-01,  1.1821317e-01],\n",
      "       [ 9.9994749e-01,  9.9992365e-01],\n",
      "       [ 0.0000000e+00,  9.9992365e-01],\n",
      "       [ 0.0000000e+00,  0.0000000e+00],\n",
      "       [ 0.0000000e+00,  0.0000000e+00]], dtype=float32)}\n",
      "sample dict keys: dict_keys(['start', 'target', 'item_id', 'feat_dynamic_real'])\n",
      "start: 2018-01-18 14:36 <class 'pandas._libs.tslibs.period.Period'>\n",
      "target shape: <class 'numpy.ndarray'> (1,)\n",
      "item id: 0\n",
      "feat_dynamic_real\": <class 'numpy.ndarray'> (26, 2) float32\n"
     ]
    }
   ],
   "source": [
    "test_input_sample = next(test_data_input_dataset_iter)\n",
    "print_data_sample(test_input_sample)\n",
    "test_label_sample = next(test_data_label_dataset_iter)\n",
    "print_data_sample(test_label_sample)\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "test_input_sample = next(test_data_input_dataset_iter)\n",
    "print_data_sample(test_input_sample)\n",
    "test_label_sample = next(test_data_label_dataset_iter)\n",
    "print_data_sample(test_label_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87bedd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5017580</th>\n",
       "      <td>-6.740093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017780</th>\n",
       "      <td>0.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017980</th>\n",
       "      <td>2.900362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018180</th>\n",
       "      <td>8.339882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target\n",
       "5017580 -6.740093\n",
       "5017780  0.610352\n",
       "5017980  2.900362\n",
       "5018180  8.339882"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df[\"stock_id\"] == 0].iloc[-validation_length - 2:-validation_length + 2][[\"target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efb119",
   "metadata": {
    "id": "50efb119"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "Next, let's instantiate a model. The model will be trained from scratch, hence we won't use the `from_pretrained` method here, but rather randomly initialize the model from a [`config`](https://huggingface.co/docs/transformers/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig).\n",
    "\n",
    "We specify a couple of additional parameters to the model:\n",
    "- `prediction_length` (in our case, `24` months): this is the horizon that the decoder of the Transformer will learn to predict for;\n",
    "- `context_length`: the model will set the `context_length` (input of the encoder) equal to the `prediction_length`, if no `context_length` is specified;\n",
    "- `lags` for a given frequency: these specify how much we \"look back\", to be added as additional features. e.g. for a `Daily` frequency we might consider a look back of `[1, 2, 7, 30, ...]` or in other words look back 1, 2, ... days while for `Minute` data we might consider `[1, 30, 60, 60*24, ...]` etc.;\n",
    "- the number of time features: in our case, this will be `2` as we'll add `MonthOfYear` and `Age` features;\n",
    "- the number of static categorical features: in our case, this will be just `1` as we'll add a single \"time series ID\" feature;\n",
    "- the cardinality: the number of values of each static categorical feature, as a list which for our case will be `[366]` as we have 366 different time series\n",
    "- the embedding dimension: the embedding dimension for each static categorical feature, as a list, for example `[3]` meaning the model will learn an embedding vector of size `3` for each of the `366` time series (regions).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0z4YFov8CNUu",
   "metadata": {
    "id": "0z4YFov8CNUu"
   },
   "source": [
    "Let's use the default lags provided by GluonTS for the given frequency (\"monthly\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6CF4M8Ms7W-q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1706407185061,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "6CF4M8Ms7W-q",
    "outputId": "47a3cbef-2fe0-4406-f1c1-51ce9525a2b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 58, 59, 60, 61, 62, 118, 119, 120, 121, 122, 178, 179, 180, 181, 182]\n"
     ]
    }
   ],
   "source": [
    "from gluonts.time_feature import get_lags_for_frequency\n",
    "\n",
    "lags_sequence = get_lags_for_frequency(freq)\n",
    "print(lags_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q6ZuFx8yCSAM",
   "metadata": {
    "id": "q6ZuFx8yCSAM"
   },
   "source": [
    "This means that we'll look back up to 37 months for each time step, as additional features.\n",
    "\n",
    "Let's also check the default time features which GluonTS provides us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "VlP_0E5I76lg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706407185061,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "VlP_0E5I76lg",
    "outputId": "76148769-24c1-470c-eb0e-3115b7d00320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function minute_of_hour at 0x1518224c8e00>, <function hour_of_day at 0x1518224c8f40>, <function day_of_week at 0x1518224c9080>, <function day_of_month at 0x1518224c91c0>, <function day_of_year at 0x1518224c9300>]\n"
     ]
    }
   ],
   "source": [
    "from gluonts.time_feature import time_features_from_frequency_str\n",
    "\n",
    "time_features = time_features_from_frequency_str(freq)\n",
    "print(time_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m0_f7lm9CbNG",
   "metadata": {
    "id": "m0_f7lm9CbNG"
   },
   "source": [
    "In this case, there's only a single feature, namely \"month of year\". This means that for each time step, we'll add the month as a scalar value (e.g. `1` in case the timestamp is \"january\", `2` in case the timestamp is \"february\", etc.).\n",
    "\n",
    "We now have everything to define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dadbf60-fdb9-4862-b13b-2f6ec921b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 55 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dda0e78",
   "metadata": {
    "executionInfo": {
     "elapsed": 2333,
     "status": "ok",
     "timestamp": 1706407187384,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "3dda0e78"
   },
   "outputs": [],
   "source": [
    "config = TimeSeriesTransformerConfig(\n",
    "    prediction_length=prediction_length,\n",
    "    # context length:\n",
    "    context_length=context_length,\n",
    "    # lags coming from helper given the freq:\n",
    "    # lags_sequence=lags_sequence,\n",
    "    # we'll add 1 time features (\"age\", see further):\n",
    "    num_time_features=0,\n",
    "    # we have a single static categorical feature, stock ID:\n",
    "    num_static_categorical_features=1,\n",
    "    # it has 200 possible values:\n",
    "    cardinality=[len(df_grouped)],\n",
    "    # the model will learn an embedding of size 2 for each of the 200 possible values:\n",
    "    embedding_dimension=[2],\n",
    "    num_dynamic_real_features=len(feat_dynamic_real),\n",
    "\n",
    "    # transformer params:\n",
    "    encoder_layers=4,\n",
    "    decoder_layers=4,\n",
    "    d_model=32,\n",
    ")\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec00de86-b30b-4146-acae-f3bcd1d361b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(config.num_static_categorical_features)\n",
    "print(config.num_static_real_features)\n",
    "print(config.num_dynamic_real_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T6rCeV4dsUnF",
   "metadata": {
    "id": "T6rCeV4dsUnF"
   },
   "source": [
    "Note that, similar to other models in the ðŸ¤— Transformers library, [`TimeSeriesTransformerModel`](https://huggingface.co/docs/transformers/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel) corresponds to the encoder-decoder Transformer without any head on top, and [`TimeSeriesTransformerForPrediction`](https://huggingface.co/docs/transformers/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction) corresponds to `TimeSeriesTransformerModel` with a **distribution head** on top. By default, the model uses a Student-t distribution (but this is configurable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "EaoKZyujsuIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1706407187385,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "EaoKZyujsuIA",
    "outputId": "4742745e-0ce4-462d-dfc8-e85399557245"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student_t'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.distribution_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feQYVhgus-yl",
   "metadata": {
    "id": "feQYVhgus-yl"
   },
   "source": [
    "This is an important difference with Transformers for NLP, where the head typically consists of a fixed categorical distribution implemented as an `nn.Linear` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82c60d",
   "metadata": {
    "id": "af82c60d"
   },
   "source": [
    "## Define Transformations\n",
    "\n",
    "Next, we define the transformations for the data, in particular for the creation of the time features (based on the dataset or universal ones).\n",
    "\n",
    "Again, we'll use the GluonTS library for this. We define a `Chain` of transformations (which is a bit comparable to `torchvision.transforms.Compose` for images). It allows us to combine several transformations into a single pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4Qql4CInFWO7",
   "metadata": {
    "id": "4Qql4CInFWO7"
   },
   "source": [
    "The transformations below are annotated with comments, to explain what they do. At a high level, we will iterate over the individual time series of our dataset and add/remove fields or features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20fe036e",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1706407187985,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "20fe036e"
   },
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "\n",
    "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
    "    remove_field_names = []\n",
    "    if config.num_static_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
    "    if config.num_dynamic_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
    "    if config.num_static_categorical_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
    "\n",
    "    # a bit like torchvision.transforms.Compose\n",
    "    return Chain(\n",
    "        []\n",
    "        # step 1: remove static/dynamic fields if not specified\n",
    "        # [RemoveFields(field_names=remove_field_names)]\n",
    "        # step 2: convert the data to NumPy (potentially not needed)\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.ITEM_ID,\n",
    "                    expected_ndim=0,\n",
    "                    dtype=int,\n",
    "                )\n",
    "            ]\n",
    "            # if config.num_static_categorical_features > 0\n",
    "            # else []\n",
    "        )\n",
    "        + (\n",
    "            # [\n",
    "            #     AsNumpyArray(\n",
    "            #         field=FieldName.FEAT_STATIC_REAL,\n",
    "            #         expected_ndim=1,\n",
    "            #     )\n",
    "            # ]\n",
    "            # if config.num_static_real_features > 0\n",
    "            # else []\n",
    "            []\n",
    "        )\n",
    "        + [\n",
    "            AsNumpyArray(\n",
    "                field=FieldName.TARGET,\n",
    "                # we expect an extra dim for the multivariate case:\n",
    "                expected_ndim=1,\n",
    "            ),\n",
    "            # step 3: handle the NaN's by filling in the target with zero\n",
    "            # and return the mask (which is in the observed values)\n",
    "            # true for observed values, false for nan's\n",
    "            # the decoder uses this mask (no loss is incurred for unobserved values)\n",
    "            # see loss_weights inside the xxxForPrediction model\n",
    "            AddObservedValuesIndicator(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.OBSERVED_VALUES,\n",
    "            ),\n",
    "            # step 4: add temporal features based on freq of the dataset\n",
    "            # month of year in the case when freq=\"M\"\n",
    "            # these serve as positional encodings\n",
    "            # AddTimeFeatures(\n",
    "            #     start_field=FieldName.START,\n",
    "            #     target_field=FieldName.TARGET,\n",
    "            #     output_field=FieldName.FEAT_TIME,\n",
    "            #     time_features=time_features_from_frequency_str(freq),\n",
    "            #     pred_length=config.prediction_length,\n",
    "            # ),\n",
    "            # step 5: add another temporal feature (just a single number)\n",
    "            # tells the model where in the life the value of the time series is\n",
    "            # sort of running counter\n",
    "            # AddAgeFeature(\n",
    "            #     target_field=FieldName.TARGET,\n",
    "            #     output_field=FieldName.FEAT_AGE,\n",
    "            #     pred_length=config.prediction_length,\n",
    "            #     log_scale=False,\n",
    "            # ),\n",
    "            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n",
    "            VstackFeatures(\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                input_fields=[]\n",
    "                + (\n",
    "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
    "                    if config.num_dynamic_real_features > 0\n",
    "                    else []\n",
    "                ),\n",
    "            ),\n",
    "            # step 7: rename to match HuggingFace names\n",
    "            RenameFields(\n",
    "                mapping={\n",
    "                    FieldName.ITEM_ID: \"static_categorical_features\",\n",
    "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
    "                    FieldName.FEAT_TIME: \"time_features\",\n",
    "                    FieldName.TARGET: \"values\",\n",
    "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab46d0",
   "metadata": {
    "id": "8bab46d0"
   },
   "source": [
    "## Define `InstanceSplitter`\n",
    "\n",
    "For training/validation/testing we next create an `InstanceSplitter` which is used to sample windows from the dataset (as, remember, we can't pass the entire history of values to the Transformer due to time- and memory constraints).\n",
    "\n",
    "The instance splitter samples random `context_length` sized and subsequent `prediction_length` sized windows from the data, and appends a `past_` or `future_` key to any temporal keys in `time_series_fields` for the respective windows. The instance splitter can be configured into three different modes:\n",
    "1. `mode=\"train\"`: Here we sample the context and prediction length windows randomly from the dataset given to it (the training dataset)\n",
    "2. `mode=\"validation\"`: Here we sample the very last context length window and prediction window from the dataset given to it (for the back-testing or validation likelihood calculations)\n",
    "3. `mode=\"test\"`: Here we sample the very last context length window only (for the prediction use case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cae7600d",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706407187985,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "cae7600d"
   },
   "outputs": [],
   "source": [
    "from gluonts.transform.sampler import InstanceSampler\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def create_instance_splitter(\n",
    "    config: PretrainedConfig,\n",
    "    mode: str,\n",
    "    train_sampler: Optional[InstanceSampler] = None,\n",
    "    validation_sampler: Optional[InstanceSampler] = None,\n",
    ") -> Transformation:\n",
    "    assert mode in [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    instance_sampler = {\n",
    "        \"train\": train_sampler\n",
    "        or ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0, min_future=config.prediction_length\n",
    "        ),\n",
    "        \"validation\": validation_sampler\n",
    "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
    "        \"test\": TestSplitSampler(),\n",
    "    }[mode]\n",
    "\n",
    "    return InstanceSplitter(\n",
    "        target_field=\"values\",\n",
    "        is_pad_field=FieldName.IS_PAD,\n",
    "        start_field=FieldName.START,\n",
    "        forecast_start_field=FieldName.FORECAST_START,\n",
    "        instance_sampler=instance_sampler,\n",
    "        past_length=config.context_length + max(config.lags_sequence),\n",
    "        future_length=config.prediction_length,\n",
    "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e050d",
   "metadata": {
    "id": "958e050d"
   },
   "source": [
    "## Create DataLoaders\n",
    "\n",
    "Next, it's time to create the DataLoaders, which allow us to have batches of (input, output pairs) - or in other words (`past_values`, `future_values`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6995101c",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706407187985,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "6995101c"
   },
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from gluonts.itertools import Cyclic, Cached\n",
    "from gluonts.dataset.loader import as_stacked_batches\n",
    "\n",
    "\n",
    "def create_train_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    num_batches_per_epoch: int,\n",
    "    shuffle_buffer_length: Optional[int] = None,\n",
    "    cache_data: bool = True,\n",
    "    **kwargs,\n",
    ") -> Iterable:\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
    "        \"future_values\",\n",
    "        \"future_observed_mask\",\n",
    "    ]\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=True)\n",
    "    if cache_data:\n",
    "        transformed_data = Cached(transformed_data)\n",
    "\n",
    "    # we initialize a Training instance\n",
    "    instance_splitter = create_instance_splitter(config, \"train\")\n",
    "\n",
    "    # the instance splitter will sample a window of\n",
    "    # context length + lags + prediction length (from the 200 possible transformed time series)\n",
    "    # randomly from within the target time series and return an iterator.\n",
    "    stream = Cyclic(transformed_data).stream()\n",
    "    training_instances = instance_splitter.apply(stream)\n",
    "\n",
    "    return as_stacked_batches(\n",
    "        training_instances,\n",
    "        batch_size=batch_size,\n",
    "        shuffle_buffer_length=shuffle_buffer_length,\n",
    "        field_names=TRAINING_INPUT_NAMES,\n",
    "        output_type=torch.tensor,\n",
    "        num_batches_per_epoch=num_batches_per_epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5d0d067-c65b-4116-998a-dd7cb53ae771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBackTestSampler(InstanceSampler):\n",
    "    back_test_size = 0\n",
    "    \n",
    "    def __init__(self, back_test_size):\n",
    "        super().__init__()\n",
    "        assert back_test_size > 0\n",
    "        self.back_test_size = back_test_size\n",
    "\n",
    "    def __call__(self, ts: np.ndarray) -> np.ndarray:\n",
    "        data_size = ts.shape[-1]\n",
    "        # TODO: do not use split offset -1 above\n",
    "        return np.arange(data_size - self.back_test_size + 1, data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10c55455",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706407187985,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "10c55455"
   },
   "outputs": [],
   "source": [
    "def create_backtest_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    cache_data: bool = True,\n",
    "    validation_sampler: Optional[InstanceSampler] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data)\n",
    "    if cache_data:\n",
    "        transformed_data = Cached(transformed_data)\n",
    "\n",
    "    # We create a Validation Instance splitter which will sample the very last\n",
    "    # context window seen during training only for the encoder.\n",
    "    instance_sampler = create_instance_splitter(config, \"validation\", validation_sampler=validation_sampler)\n",
    "\n",
    "    # we apply the transformations in train mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=True)\n",
    "\n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f257d8d-fcf2-4f9e-814e-63b82ece22e8",
   "metadata": {
    "id": "8f257d8d-fcf2-4f9e-814e-63b82ece22e8"
   },
   "source": [
    "We have a test dataloader helper for completion, even though we will not use it here. This is useful in a production setting where we want to start forecasting from the end of a given time series. Thus, the test dataloader will sample the very last context window from the dataset provided and pass it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71459c61-949b-4ff6-91af-5a636839aa60",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1706407187985,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "71459c61-949b-4ff6-91af-5a636839aa60"
   },
   "outputs": [],
   "source": [
    "def create_test_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=False)\n",
    "\n",
    "    # We create a test Instance splitter to sample the very last\n",
    "    # context window from the dataset provided.\n",
    "    instance_sampler = create_instance_splitter(config, \"test\")\n",
    "\n",
    "    # We apply the transformations in test mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=False)\n",
    "\n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20e2338b",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706407187986,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "20e2338b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gluonts.itertools.IterableSlice'> 9000 ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'iterable', 'length']\n",
      "<class '__main__.CustomBackTestSampler'> axis=-1 min_past=0 min_future=0 back_test_size=1100\n",
      "<class 'gluonts.itertools.IterableSlice'> None ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'iterable', 'length']\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = create_train_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=train_dataset,\n",
    "    batch_size=512,\n",
    "    num_batches_per_epoch=9000,\n",
    ")\n",
    "train_dataloader_iter = iter(train_dataloader)\n",
    "print(type(train_dataloader), train_dataloader.length, dir(train_dataloader))\n",
    "\n",
    "custom_back_test_sampler = CustomBackTestSampler(validation_length)\n",
    "print(type(custom_back_test_sampler), custom_back_test_sampler)\n",
    "test_dataloader = create_backtest_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=val_data,\n",
    "    batch_size=512,\n",
    "    validation_sampler=custom_back_test_sampler,\n",
    ")\n",
    "test_dataloader_iter = iter(test_dataloader)\n",
    "print(type(test_dataloader), test_dataloader.length, dir(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ES2U8g-2G2Jd",
   "metadata": {
    "id": "ES2U8g-2G2Jd"
   },
   "source": [
    "Let's check the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "YU2h9OOB5IsX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706407187986,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "YU2h9OOB5IsX",
    "outputId": "5a7f5e13-46d9-4c9c-d271-78da16b8e7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_time_features torch.Size([512, 117, 26]) torch.FloatTensor\n",
      "past_values torch.Size([512, 117]) torch.FloatTensor\n",
      "past_observed_mask torch.Size([512, 117]) torch.FloatTensor\n",
      "future_time_features torch.Size([512, 1, 26]) torch.FloatTensor\n",
      "static_categorical_features torch.Size([512]) torch.LongTensor\n",
      "future_values torch.Size([512, 1]) torch.FloatTensor\n",
      "future_observed_mask torch.Size([512, 1]) torch.FloatTensor\n",
      "1.4336998462677002\n"
     ]
    }
   ],
   "source": [
    "prev_time = time.time()\n",
    "batch = next(train_dataloader_iter)\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.type())\n",
    "curr_time = time.time()\n",
    "print(curr_time - prev_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a11c52e3-2507-4a83-b6aa-7c9d1ffa2e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_time_features torch.Size([1024, 117, 26]) torch.FloatTensor\n",
      "past_values torch.Size([1024, 117]) torch.FloatTensor\n",
      "past_observed_mask torch.Size([1024, 117]) torch.FloatTensor\n",
      "future_time_features torch.Size([1024, 1, 26]) torch.FloatTensor\n",
      "static_categorical_features torch.Size([1024]) torch.LongTensor\n",
      "0.0438079833984375\n"
     ]
    }
   ],
   "source": [
    "prev_time = time.time()\n",
    "test_sample_batch = next(test_dataloader_iter)\n",
    "for k, v in test_sample_batch.items():\n",
    "    print(k, v.shape, v.type())\n",
    "curr_time = time.time()\n",
    "print(curr_time - prev_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "586f44a9-4a8f-4ceb-924b-436de7aec5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_time_features torch.Size([1024, 117, 26]) torch.FloatTensor\n",
      "past_values torch.Size([1024, 117]) torch.FloatTensor\n",
      "past_observed_mask torch.Size([1024, 117]) torch.FloatTensor\n",
      "future_time_features torch.Size([1024, 1, 26]) torch.FloatTensor\n",
      "static_categorical_features torch.Size([1024]) torch.LongTensor\n",
      "past_time_features tensor([[460., 530.],\n",
      "        [460., 540.]])\n",
      "past_values tensor([  0.7796,  -2.5803,   1.3900,  -0.9400,   2.2900,   4.3797,  15.3399,\n",
      "        -11.1002,  -8.6898,  -8.9502,  -7.2002,  -5.1600,  -3.8302,  -2.4498,\n",
      "         -1.5998,  -0.0602,  -1.8102,  -1.3798,  -0.1401,   2.2995,   2.4498,\n",
      "          3.7801,   3.1805,   1.8799,   2.2697,   1.2398,   2.8706,   3.8195,\n",
      "          8.6999,   5.6803,   1.6999,   4.9996,   3.5799,  -1.4102,  -7.8201,\n",
      "         -9.1898,  -6.5798,  -9.6399,  -8.7398,  -5.1898,   0.0298,   2.9397,\n",
      "          0.2801,   2.3901,   4.4203,   2.1994,   1.7703,   3.7801,   4.8804,\n",
      "          6.3598,   0.7498,   1.3602,   1.2696,  -0.7099,   1.1504,  -2.8598,\n",
      "          2.2197,   1.4997,   0.5198,   1.5104,  -0.3898,  -0.4297,  -2.8300,\n",
      "          2.2995,   4.4298,   7.9703,  10.3605,  16.9504,  19.3799,  14.0703,\n",
      "          6.3205,   0.3004,  -0.9900,  -1.8603,  -1.9997,  -4.9400,  -0.0697,\n",
      "          0.7904,   0.2205,  -0.6098,  -1.1498,  -0.7701,   1.5497,   4.6003,\n",
      "          4.2200,   5.4896,   4.9698,   8.9002,   7.9501,   0.3195,   2.9302,\n",
      "         -1.6803,  -0.9799,  -3.6198,  -5.4997,  -2.2298,  -3.6597,  -1.6701,\n",
      "         -1.9199,  -2.1702,  -1.3101,   2.2101,   4.2105,   4.8399,   6.5804,\n",
      "          4.8494,   5.2595,   3.1698,   0.9406,   1.4699,  -1.8901,  -1.0598,\n",
      "         -0.5400,  -4.8298,  -4.5800,  -6.7401,   0.6104])\n",
      "future_time_features tensor([[ 4.6100e+02,  0.0000e+00,  1.0247e+06,  1.0000e+00,  1.0003e+00,\n",
      "          1.5223e+07,  0.0000e+00,  0.0000e+00,  9.9999e-01,  1.3050e+03,\n",
      "          1.0003e+00,  6.5927e+04,  1.0000e+00,  2.5355e+04, -9.6118e-01,\n",
      "         -8.7386e-01,  0.0000e+00,  0.0000e+00,  4.8313e+01,  4.8313e+01,\n",
      "          1.5543e+01,  6.7313e-02,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]])\n",
      "static_categorical_features tensor(0)\n",
      "past_time_features tensor([[460., 540.],\n",
      "        [461.,   0.]])\n",
      "past_values tensor([ -2.5803,   1.3900,  -0.9400,   2.2900,   4.3797,  15.3399, -11.1002,\n",
      "         -8.6898,  -8.9502,  -7.2002,  -5.1600,  -3.8302,  -2.4498,  -1.5998,\n",
      "         -0.0602,  -1.8102,  -1.3798,  -0.1401,   2.2995,   2.4498,   3.7801,\n",
      "          3.1805,   1.8799,   2.2697,   1.2398,   2.8706,   3.8195,   8.6999,\n",
      "          5.6803,   1.6999,   4.9996,   3.5799,  -1.4102,  -7.8201,  -9.1898,\n",
      "         -6.5798,  -9.6399,  -8.7398,  -5.1898,   0.0298,   2.9397,   0.2801,\n",
      "          2.3901,   4.4203,   2.1994,   1.7703,   3.7801,   4.8804,   6.3598,\n",
      "          0.7498,   1.3602,   1.2696,  -0.7099,   1.1504,  -2.8598,   2.2197,\n",
      "          1.4997,   0.5198,   1.5104,  -0.3898,  -0.4297,  -2.8300,   2.2995,\n",
      "          4.4298,   7.9703,  10.3605,  16.9504,  19.3799,  14.0703,   6.3205,\n",
      "          0.3004,  -0.9900,  -1.8603,  -1.9997,  -4.9400,  -0.0697,   0.7904,\n",
      "          0.2205,  -0.6098,  -1.1498,  -0.7701,   1.5497,   4.6003,   4.2200,\n",
      "          5.4896,   4.9698,   8.9002,   7.9501,   0.3195,   2.9302,  -1.6803,\n",
      "         -0.9799,  -3.6198,  -5.4997,  -2.2298,  -3.6597,  -1.6701,  -1.9199,\n",
      "         -2.1702,  -1.3101,   2.2101,   4.2105,   4.8399,   6.5804,   4.8494,\n",
      "          5.2595,   3.1698,   0.9406,   1.4699,  -1.8901,  -1.0598,  -0.5400,\n",
      "         -4.8298,  -4.5800,  -6.7401,   0.6104,   2.9004])\n",
      "future_time_features tensor([[ 4.6100e+02,  1.0000e+01,  1.7998e+06,  1.0000e+00,  9.9999e-01,\n",
      "          1.5225e+07,  0.0000e+00,  0.0000e+00,  9.9983e-01,  2.1648e+04,\n",
      "          9.9999e-01,  3.0490e+04,  9.9989e-01,  2.5356e+04, -1.6959e-01,\n",
      "         -7.8857e-01, -7.0897e-04,  0.0000e+00,  1.4032e+00,  1.4032e+00,\n",
      "          5.9028e+01,  1.1821e-01,  9.9995e-01,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00]])\n",
      "static_categorical_features tensor(0)\n",
      "past_time_features tensor([[461.,   0.],\n",
      "        [461.,  10.]])\n",
      "past_values tensor([  1.3900,  -0.9400,   2.2900,   4.3797,  15.3399, -11.1002,  -8.6898,\n",
      "         -8.9502,  -7.2002,  -5.1600,  -3.8302,  -2.4498,  -1.5998,  -0.0602,\n",
      "         -1.8102,  -1.3798,  -0.1401,   2.2995,   2.4498,   3.7801,   3.1805,\n",
      "          1.8799,   2.2697,   1.2398,   2.8706,   3.8195,   8.6999,   5.6803,\n",
      "          1.6999,   4.9996,   3.5799,  -1.4102,  -7.8201,  -9.1898,  -6.5798,\n",
      "         -9.6399,  -8.7398,  -5.1898,   0.0298,   2.9397,   0.2801,   2.3901,\n",
      "          4.4203,   2.1994,   1.7703,   3.7801,   4.8804,   6.3598,   0.7498,\n",
      "          1.3602,   1.2696,  -0.7099,   1.1504,  -2.8598,   2.2197,   1.4997,\n",
      "          0.5198,   1.5104,  -0.3898,  -0.4297,  -2.8300,   2.2995,   4.4298,\n",
      "          7.9703,  10.3605,  16.9504,  19.3799,  14.0703,   6.3205,   0.3004,\n",
      "         -0.9900,  -1.8603,  -1.9997,  -4.9400,  -0.0697,   0.7904,   0.2205,\n",
      "         -0.6098,  -1.1498,  -0.7701,   1.5497,   4.6003,   4.2200,   5.4896,\n",
      "          4.9698,   8.9002,   7.9501,   0.3195,   2.9302,  -1.6803,  -0.9799,\n",
      "         -3.6198,  -5.4997,  -2.2298,  -3.6597,  -1.6701,  -1.9199,  -2.1702,\n",
      "         -1.3101,   2.2101,   4.2105,   4.8399,   6.5804,   4.8494,   5.2595,\n",
      "          3.1698,   0.9406,   1.4699,  -1.8901,  -1.0598,  -0.5400,  -4.8298,\n",
      "         -4.5800,  -6.7401,   0.6104,   2.9004,   8.3399])\n",
      "future_time_features tensor([[ 4.6100e+02,  2.0000e+01,  1.7998e+06,  1.0000e+00,  9.9999e-01,\n",
      "          1.5225e+07,  0.0000e+00,  0.0000e+00,  9.9983e-01,  1.8327e+04,\n",
      "          9.9999e-01,  4.2354e+04,  9.9988e-01,  2.5357e+04, -3.9597e-01,\n",
      "         -7.8857e-01, -7.0897e-04, -1.0178e-03,  2.2894e+00,  2.2894e+00,\n",
      "          4.2493e+01,  1.1821e-01,  9.9992e-01,  9.9992e-01,  0.0000e+00,\n",
      "          0.0000e+00]])\n",
      "static_categorical_features tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:29</th>\n",
       "      <td>25349.0</td>\n",
       "      <td>-1.059771</td>\n",
       "      <td>490.0</td>\n",
       "      <td>3923400.750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:30</th>\n",
       "      <td>25350.0</td>\n",
       "      <td>-0.540018</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3485172.250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:31</th>\n",
       "      <td>25351.0</td>\n",
       "      <td>-4.829764</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3485172.250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:32</th>\n",
       "      <td>25352.0</td>\n",
       "      <td>-4.580021</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3337968.250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:33</th>\n",
       "      <td>25353.0</td>\n",
       "      <td>-6.740093</td>\n",
       "      <td>530.0</td>\n",
       "      <td>3336365.500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:34</th>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.610352</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3336365.500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:35</th>\n",
       "      <td>25355.0</td>\n",
       "      <td>2.900362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024700.375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:36</th>\n",
       "      <td>25356.0</td>\n",
       "      <td>8.339882</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1799780.625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:37</th>\n",
       "      <td>25357.0</td>\n",
       "      <td>5.810261</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1799780.625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:38</th>\n",
       "      <td>25358.0</td>\n",
       "      <td>3.770590</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1809924.375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time_id    target  seconds_in_bucket  imbalance_size  \\\n",
       "timestamp                                                                \n",
       "2018-01-18 14:29  25349.0 -1.059771              490.0     3923400.750   \n",
       "2018-01-18 14:30  25350.0 -0.540018              500.0     3485172.250   \n",
       "2018-01-18 14:31  25351.0 -4.829764              510.0     3485172.250   \n",
       "2018-01-18 14:32  25352.0 -4.580021              520.0     3337968.250   \n",
       "2018-01-18 14:33  25353.0 -6.740093              530.0     3336365.500   \n",
       "2018-01-18 14:34  25354.0  0.610352              540.0     3336365.500   \n",
       "2018-01-18 14:35  25355.0  2.900362                0.0     1024700.375   \n",
       "2018-01-18 14:36  25356.0  8.339882               10.0     1799780.625   \n",
       "2018-01-18 14:37  25357.0  5.810261               20.0     1799780.625   \n",
       "2018-01-18 14:38  25358.0  3.770590               30.0     1809924.375   \n",
       "\n",
       "                  imbalance_buy_sell_flag  \n",
       "timestamp                                  \n",
       "2018-01-18 14:29                      1.0  \n",
       "2018-01-18 14:30                      1.0  \n",
       "2018-01-18 14:31                      1.0  \n",
       "2018-01-18 14:32                      1.0  \n",
       "2018-01-18 14:33                      1.0  \n",
       "2018-01-18 14:34                      1.0  \n",
       "2018-01-18 14:35                      1.0  \n",
       "2018-01-18 14:36                      1.0  \n",
       "2018-01-18 14:37                      1.0  \n",
       "2018-01-18 14:38                      1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verify that custom_back_test_sampler and val_data are correct\n",
    "def verify_print_sample(sample_batch, sample_idx):\n",
    "    print(\"past_time_features\", sample_batch[\"past_time_features\"][sample_idx, -2:, 0:2])\n",
    "    print(\"past_values\", sample_batch[\"past_values\"][sample_idx])\n",
    "    print(\"future_time_features\", sample_batch[\"future_time_features\"][sample_idx])\n",
    "    print(\"static_categorical_features\", sample_batch[\"static_categorical_features\"][sample_idx])\n",
    "test_dataloader_iter_verify = iter(test_dataloader)\n",
    "test_sample_batch_verify = next(test_dataloader_iter_verify)\n",
    "for k, v in test_sample_batch_verify.items():\n",
    "    print(k, v.shape, v.type())\n",
    "verify_print_sample(test_sample_batch_verify, 0)\n",
    "verify_print_sample(test_sample_batch_verify, 1)\n",
    "verify_print_sample(test_sample_batch_verify, 2)\n",
    "display(df[df[\"stock_id\"] == 0][[\"time_id\", \"target\", 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag']].iloc[-validation_length-6:-validation_length+4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HvvPlSF8HBYd",
   "metadata": {
    "id": "HvvPlSF8HBYd"
   },
   "source": [
    "As can be seen, we don't feed `input_ids` and `attention_mask` to the encoder (as would be the case for NLP models), but rather `past_values`, along with `past_observed_mask`, `past_time_features`, and `static_categorical_features`.\n",
    "\n",
    "The decoder inputs consist of `future_values`, `future_observed_mask` and `future_time_features`. The `future_values` can be seen as the equivalent of `decoder_input_ids` in NLP.\n",
    "\n",
    "We refer to the [docs](https://huggingface.co/docs/transformers/model_doc/time_series_transformer#transformers.TimeSeriesTransformerForPrediction.forward.past_values) for a detailed explanation for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_cev4ufVv1yf",
   "metadata": {
    "id": "_cev4ufVv1yf"
   },
   "source": [
    "## Forward pass\n",
    "\n",
    "Let's perform a single forward pass with the batch we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sD8fav6qTApR",
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1706407188391,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "sD8fav6qTApR"
   },
   "outputs": [],
   "source": [
    "# perform forward pass\n",
    "# outputs = model(\n",
    "#     past_values=batch[\"past_values\"],\n",
    "#     past_time_features=batch[\"past_time_features\"],\n",
    "#     past_observed_mask=batch[\"past_observed_mask\"],\n",
    "#     static_categorical_features=batch[\"static_categorical_features\"]\n",
    "#     if config.num_static_categorical_features > 0\n",
    "#     else None,\n",
    "#     static_real_features=batch[\"static_real_features\"]\n",
    "#     if config.num_static_real_features > 0\n",
    "#     else None,\n",
    "#     future_values=batch[\"future_values\"],\n",
    "#     future_time_features=batch[\"future_time_features\"],\n",
    "#     future_observed_mask=batch[\"future_observed_mask\"],\n",
    "#     output_hidden_states=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "j2KnnHTCX4RC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706407188391,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "j2KnnHTCX4RC",
    "outputId": "0ca1ec79-3234-4b5f-d863-032c344eb593"
   },
   "outputs": [],
   "source": [
    "# print(\"Loss:\", outputs.loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V9K8s2j9y8x7",
   "metadata": {
    "id": "V9K8s2j9y8x7"
   },
   "source": [
    "Note that the model is returning a loss. This is possible as the decoder automatically shifts the `future_values` one position to the right in order to have the labels. This allows computing a loss between the predicted values and the labels.\n",
    "\n",
    "Also note that the decoder uses a causal mask to not look into the future as the values it needs to predict are in the `future_values` tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SxHDCa7vwPBF",
   "metadata": {
    "id": "SxHDCa7vwPBF"
   },
   "source": [
    "## Train the Model\n",
    "\n",
    "It's time to train the model! We'll use a standard PyTorch training loop.\n",
    "\n",
    "We will use the ðŸ¤— [Accelerate](https://huggingface.co/docs/accelerate/index) library here, which automatically places the model, optimizer and dataloader on the appropriate `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "86f83e92-1ff8-4891-b226-5c47a26ab6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from torch.optim import AdamW\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f47ad49f-0d66-4bb1-93b6-2ef65c885951",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b524e9b4-62ad-484d-88b6-fc7ab244db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "088930b7-1f51-4df3-a91f-91ccedb3ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93261b00-8f1c-4b1f-8ce0-0610bb89d2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219800,) 0.9635429382324219\n"
     ]
    }
   ],
   "source": [
    "prev_time = time.time()\n",
    "val_set_ground_truth = list(iter(val_data))\n",
    "# TODO: do not use offset split -1\n",
    "val_set_ground_truth = list(map(lambda stock_data: stock_data[\"target\"][-validation_length+1:], val_set_ground_truth))\n",
    "val_set_ground_truth = np.vstack(val_set_ground_truth).flatten()\n",
    "curr_time = time.time()\n",
    "print(val_set_ground_truth.shape, curr_time - prev_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8046ba9-ec5d-424a-9858-befc7225e972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.900362   8.339882   5.810261   3.7705898 -1.1897087]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:33</th>\n",
       "      <td>25353.0</td>\n",
       "      <td>-6.740093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:34</th>\n",
       "      <td>25354.0</td>\n",
       "      <td>0.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:35</th>\n",
       "      <td>25355.0</td>\n",
       "      <td>2.900362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:36</th>\n",
       "      <td>25356.0</td>\n",
       "      <td>8.339882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:37</th>\n",
       "      <td>25357.0</td>\n",
       "      <td>5.810261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:38</th>\n",
       "      <td>25358.0</td>\n",
       "      <td>3.770590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:39</th>\n",
       "      <td>25359.0</td>\n",
       "      <td>-1.189709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:40</th>\n",
       "      <td>25360.0</td>\n",
       "      <td>2.449751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:41</th>\n",
       "      <td>25361.0</td>\n",
       "      <td>-0.479817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18 14:42</th>\n",
       "      <td>25362.0</td>\n",
       "      <td>-4.979968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time_id    target\n",
       "timestamp                          \n",
       "2018-01-18 14:33  25353.0 -6.740093\n",
       "2018-01-18 14:34  25354.0  0.610352\n",
       "2018-01-18 14:35  25355.0  2.900362\n",
       "2018-01-18 14:36  25356.0  8.339882\n",
       "2018-01-18 14:37  25357.0  5.810261\n",
       "2018-01-18 14:38  25358.0  3.770590\n",
       "2018-01-18 14:39  25359.0 -1.189709\n",
       "2018-01-18 14:40  25360.0  2.449751\n",
       "2018-01-18 14:41  25361.0 -0.479817\n",
       "2018-01-18 14:42  25362.0 -4.979968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verify that val_set_ground_truth is correct\n",
    "print(val_set_ground_truth[:5])\n",
    "display(df[df[\"stock_id\"] == 0][[\"time_id\", \"target\"]].iloc[-validation_length-2:-validation_length+8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "589cf8d3-9787-42e5-86ba-452492e8e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline mae: {'mae': 5.791549497383958}\n"
     ]
    }
   ],
   "source": [
    "# baseline: predict all as 0\n",
    "baseline_predictions = np.zeros(val_set_ground_truth.shape[0])\n",
    "baseline_mae = mae_metric.compute(predictions=baseline_predictions, references=val_set_ground_truth)\n",
    "print(f\"baseline mae: {baseline_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b349fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model):\n",
    "    model.eval()\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    for idx, batch in enumerate(test_dataloader):\n",
    "        outputs = model.generate(\n",
    "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else None,\n",
    "            static_real_features=batch[\"static_real_features\"].to(device)\n",
    "            if config.num_static_real_features > 0\n",
    "            else None,\n",
    "            past_time_features=batch[\"past_time_features\"].to(device),\n",
    "            past_values=batch[\"past_values\"].to(device),\n",
    "            future_time_features=batch[\"future_time_features\"].to(device),\n",
    "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "        )\n",
    "        forecasts.append(outputs.sequences.cpu().numpy())\n",
    "    \n",
    "    # print(forecasts[0].shape)\n",
    "    forecasts = np.vstack(forecasts)\n",
    "    # print(forecasts.shape)\n",
    "\n",
    "    forecast_median = np.median(forecasts, 1)\n",
    "    mae = mae_metric.compute(predictions=forecast_median, references=val_set_ground_truth)\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"forecasts\": forecasts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b68065-6679-47d0-866a-3424b7d868ff",
   "metadata": {},
   "source": [
    "##### Initial MAE (random weights from model initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e48d7b22-82a3-4db3-8994-4fe29869ea18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacty of 10.91 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 9.88 GiB memory in use. Of the allocated memory 8.39 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prev_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43meval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m curr_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m], curr_time \u001b[38;5;241m-\u001b[39m prev_time)\n",
      "Cell \u001b[0;32mIn[74], line 7\u001b[0m, in \u001b[0;36meval_epoch\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_dataloader):\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic_categorical_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_static_categorical_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic_real_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_static_real_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_time_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfuture_time_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_observed_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     forecasts\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39msequences\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(forecasts[0].shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1816\u001b[0m, in \u001b[0;36mTimeSeriesTransformerForPrediction.generate\u001b[0;34m(self, past_values, past_time_features, future_time_features, past_observed_mask, static_categorical_features, static_real_features, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m   1812\u001b[0m reshaped_lagged_sequence \u001b[38;5;241m=\u001b[39m lagged_sequence\u001b[38;5;241m.\u001b[39mreshape(lags_shape[\u001b[38;5;241m0\u001b[39m], lags_shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1814\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((reshaped_lagged_sequence, repeated_features[:, : k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1816\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeated_enc_last_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1817\u001b[0m dec_last_hidden \u001b[38;5;241m=\u001b[39m dec_output\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m   1819\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter_projection(dec_last_hidden[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1185\u001b[0m, in \u001b[0;36mTimeSeriesTransformerDecoder.forward\u001b[0;34m(self, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1175\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1176\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1183\u001b[0m     )\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1185\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:612\u001b[0m, in \u001b[0;36mTimeSeriesTransformerDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    611\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 612\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    621\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:372\u001b[0m, in \u001b[0;36mTimeSeriesTransformerAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    369\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_cross_attention:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# cross_attentions\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(key_value_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# reuse k, v, self_attention\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:337\u001b[0m, in \u001b[0;36mTimeSeriesTransformerAttention._shape\u001b[0;34m(self, tensor, seq_len, bsz)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: torch\u001b[38;5;241m.\u001b[39mTensor, seq_len: \u001b[38;5;28mint\u001b[39m, bsz: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacty of 10.91 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 9.88 GiB memory in use. Of the allocated memory 8.39 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "prev_time = time.time()\n",
    "result = eval_epoch(model)\n",
    "curr_time = time.time()\n",
    "print(result[\"mae\"], curr_time - prev_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "gMLYvQaNHuXQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265016,
     "status": "ok",
     "timestamp": 1706407453404,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "gMLYvQaNHuXQ",
    "outputId": "c2fa4958-0b4e-402c-ce44-478b636a8e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - mae: ({'mae': 5.829283585395586}, array([[[-5.484554  ],\n",
      "        [ 0.20685096],\n",
      "        [ 3.9884708 ],\n",
      "        ...,\n",
      "        [-2.0582883 ],\n",
      "        [ 4.247922  ],\n",
      "        [ 1.8249645 ]],\n",
      "\n",
      "       [[-2.0568    ],\n",
      "        [-4.7415648 ],\n",
      "        [-4.482175  ],\n",
      "        ...,\n",
      "        [ 6.4402647 ],\n",
      "        [ 3.607108  ],\n",
      "        [-4.6230817 ]],\n",
      "\n",
      "       [[-0.96988344],\n",
      "        [ 4.369277  ],\n",
      "        [-1.537425  ],\n",
      "        ...,\n",
      "        [ 5.2483525 ],\n",
      "        [-3.5736525 ],\n",
      "        [ 8.782028  ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 2.272669  ],\n",
      "        [ 1.3874716 ],\n",
      "        [-3.109062  ],\n",
      "        ...,\n",
      "        [ 6.019227  ],\n",
      "        [-3.6321008 ],\n",
      "        [-0.45233074]],\n",
      "\n",
      "       [[ 0.2629752 ],\n",
      "        [-5.871475  ],\n",
      "        [ 5.365258  ],\n",
      "        ...,\n",
      "        [-3.29279   ],\n",
      "        [-4.0013046 ],\n",
      "        [ 0.21737514]],\n",
      "\n",
      "       [[-3.419569  ],\n",
      "        [-0.6138074 ],\n",
      "        [-2.2128332 ],\n",
      "        ...,\n",
      "        [-0.8041131 ],\n",
      "        [ 1.7199682 ],\n",
      "        [-3.7880201 ]]], dtype=float32)), loss: 3.5077872276306152, epoch train time: 1734.7558064460754, eval time: 33.81159162521362\n",
      "epoch: 1 - mae: ({'mae': 5.819309394168363}, array([[[  0.19306797],\n",
      "        [ -5.7252884 ],\n",
      "        [  3.0503106 ],\n",
      "        ...,\n",
      "        [  7.7559943 ],\n",
      "        [  0.7675607 ],\n",
      "        [ -3.7775142 ]],\n",
      "\n",
      "       [[ -4.445466  ],\n",
      "        [-12.156249  ],\n",
      "        [ -0.34379566],\n",
      "        ...,\n",
      "        [  2.070628  ],\n",
      "        [ -8.712938  ],\n",
      "        [ -1.1361033 ]],\n",
      "\n",
      "       [[ -1.2578648 ],\n",
      "        [  0.91131234],\n",
      "        [  4.1018033 ],\n",
      "        ...,\n",
      "        [  2.7780135 ],\n",
      "        [ -2.1186845 ],\n",
      "        [  0.7059876 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -7.450289  ],\n",
      "        [ -4.0137334 ],\n",
      "        [  1.1445876 ],\n",
      "        ...,\n",
      "        [  0.53055274],\n",
      "        [  3.7336419 ],\n",
      "        [  4.7578173 ]],\n",
      "\n",
      "       [[ -1.2577338 ],\n",
      "        [ -4.295129  ],\n",
      "        [ -3.4691143 ],\n",
      "        ...,\n",
      "        [  4.294612  ],\n",
      "        [ -0.49940306],\n",
      "        [ -5.4132843 ]],\n",
      "\n",
      "       [[ -0.85931486],\n",
      "        [  4.11875   ],\n",
      "        [ -4.323791  ],\n",
      "        ...,\n",
      "        [ -9.858329  ],\n",
      "        [  1.9103583 ],\n",
      "        [  5.647062  ]]], dtype=float32)), loss: 3.4924914836883545, epoch train time: 1667.2186760902405, eval time: 33.46510934829712\n",
      "epoch: 2 - mae: ({'mae': 5.823387668743387}, array([[[ 5.485653  ],\n",
      "        [ 5.701012  ],\n",
      "        [-1.1015565 ],\n",
      "        ...,\n",
      "        [-1.4825449 ],\n",
      "        [-1.5989584 ],\n",
      "        [ 2.9439793 ]],\n",
      "\n",
      "       [[-6.8494997 ],\n",
      "        [ 2.3728712 ],\n",
      "        [ 2.266477  ],\n",
      "        ...,\n",
      "        [ 1.093664  ],\n",
      "        [-2.2083936 ],\n",
      "        [-1.7138807 ]],\n",
      "\n",
      "       [[-2.9057522 ],\n",
      "        [ 0.17762089],\n",
      "        [-0.9173424 ],\n",
      "        ...,\n",
      "        [-1.4341692 ],\n",
      "        [-0.01252258],\n",
      "        [-0.8264537 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 3.096293  ],\n",
      "        [-6.3174663 ],\n",
      "        [-1.443926  ],\n",
      "        ...,\n",
      "        [ 0.07502311],\n",
      "        [ 1.4564995 ],\n",
      "        [-0.35284108]],\n",
      "\n",
      "       [[ 4.851471  ],\n",
      "        [-5.3778296 ],\n",
      "        [ 0.5770795 ],\n",
      "        ...,\n",
      "        [-5.490165  ],\n",
      "        [-4.059854  ],\n",
      "        [-2.3478742 ]],\n",
      "\n",
      "       [[-1.3243098 ],\n",
      "        [ 6.0719724 ],\n",
      "        [-3.9509156 ],\n",
      "        ...,\n",
      "        [ 4.2926188 ],\n",
      "        [ 0.9992272 ],\n",
      "        [ 0.91898924]]], dtype=float32)), loss: 3.464193820953369, epoch train time: 1669.1274073123932, eval time: 33.30026125907898\n",
      "epoch: 3 - mae: ({'mae': 5.820075976651713}, array([[[ -3.0744596 ],\n",
      "        [  2.0739322 ],\n",
      "        [ -6.234229  ],\n",
      "        ...,\n",
      "        [ 11.698319  ],\n",
      "        [  0.11947011],\n",
      "        [ -3.6631799 ]],\n",
      "\n",
      "       [[  2.8707387 ],\n",
      "        [-10.934408  ],\n",
      "        [  1.3798851 ],\n",
      "        ...,\n",
      "        [ -1.6996495 ],\n",
      "        [  2.5204084 ],\n",
      "        [ -2.3870676 ]],\n",
      "\n",
      "       [[ -9.627997  ],\n",
      "        [  5.9156055 ],\n",
      "        [ -4.0261393 ],\n",
      "        ...,\n",
      "        [ -1.7264677 ],\n",
      "        [  5.555607  ],\n",
      "        [ -1.3755785 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -4.985058  ],\n",
      "        [  2.0155709 ],\n",
      "        [ -2.0276675 ],\n",
      "        ...,\n",
      "        [ -6.3270516 ],\n",
      "        [  1.6970413 ],\n",
      "        [ -8.586678  ]],\n",
      "\n",
      "       [[  5.5752554 ],\n",
      "        [  0.341094  ],\n",
      "        [  3.9118786 ],\n",
      "        ...,\n",
      "        [ -9.588934  ],\n",
      "        [  0.28510502],\n",
      "        [  1.6061718 ]],\n",
      "\n",
      "       [[  3.543887  ],\n",
      "        [ -9.754344  ],\n",
      "        [  3.7798736 ],\n",
      "        ...,\n",
      "        [  1.8309352 ],\n",
      "        [ -3.4933102 ],\n",
      "        [  2.9889004 ]]], dtype=float32)), loss: 3.3864996433258057, epoch train time: 1638.1962130069733, eval time: 33.78758430480957\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic_categorical_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_static_categorical_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic_real_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_static_real_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_time_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfuture_time_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfuture_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_observed_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfuture_observed_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1610\u001b[0m, in \u001b[0;36mTimeSeriesTransformerForPrediction.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, future_observed_mask, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1608\u001b[0m     use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1610\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m prediction_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1459\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1453\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1454\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1455\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1456\u001b[0m     )\n\u001b[1;32m   1458\u001b[0m dec_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length :, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m-> 1459\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs \u001b[38;5;241m+\u001b[39m (loc, scale, static_feat)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:1185\u001b[0m, in \u001b[0;36mTimeSeriesTransformerDecoder.forward\u001b[0;34m(self, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1175\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1176\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1183\u001b[0m     )\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1185\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:612\u001b[0m, in \u001b[0;36mTimeSeriesTransformerDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    611\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 612\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    621\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:438\u001b[0m, in \u001b[0;36mTimeSeriesTransformerAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     attn_weights_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m attn_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attn_probs, value_states)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim):\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "            if config.num_static_categorical_features > 0 \n",
    "            else None,\n",
    "            static_real_features=batch[\"static_real_features\"].to(device)\n",
    "            if config.num_static_real_features > 0\n",
    "            else None,\n",
    "            past_time_features=batch[\"past_time_features\"].to(device),\n",
    "            past_values=batch[\"past_values\"].to(device),\n",
    "            future_time_features=batch[\"future_time_features\"].to(device),\n",
    "            future_values=batch[\"future_values\"].to(device),\n",
    "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "            future_observed_mask=batch[\"future_observed_mask\"].to(device),\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backpropagation\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_train_end_time = time.time()\n",
    "\n",
    "    eval_epoch_res = eval_epoch(model)\n",
    "    epoch_eval_end_time = time.time()\n",
    "\n",
    "    print(f\"epoch: {epoch} - mae: {eval_epoch_res[\"mae\"]}, loss: {loss.item()}, epoch train time: {epoch_train_end_time - epoch_start_time}, eval time: {epoch_eval_end_time - epoch_train_end_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q1U6YhaFXlSp",
   "metadata": {
    "id": "Q1U6YhaFXlSp"
   },
   "source": [
    "## Inference\n",
    "\n",
    "At inference time, it's recommended to use the `generate()` method for autoregressive generation, similar to NLP models.\n",
    "\n",
    "Forecasting involves getting data from the test instance sampler, which will sample the very last `context_length` sized window of values from each time series in the dataset, and pass it to the model. Note that we pass `future_time_features`, which are known ahead of time, to the decoder.\n",
    "\n",
    "The model will autoregressively sample a certain number of values from the predicted distribution and pass them back to the decoder to return the prediction outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7482c1",
   "metadata": {
    "executionInfo": {
     "elapsed": 7516,
     "status": "ok",
     "timestamp": 1706407460905,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "7c7482c1"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "forecasts = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    outputs = model.generate(\n",
    "        static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "        if config.num_static_categorical_features > 0\n",
    "        else None,\n",
    "        static_real_features=batch[\"static_real_features\"].to(device)\n",
    "        if config.num_static_real_features > 0\n",
    "        else None,\n",
    "        past_time_features=batch[\"past_time_features\"].to(device),\n",
    "        past_values=batch[\"past_values\"].to(device),\n",
    "        future_time_features=batch[\"future_time_features\"].to(device),\n",
    "        past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "    )\n",
    "    forecasts.append(outputs.sequences.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kPLiRcOeZR67",
   "metadata": {
    "id": "kPLiRcOeZR67"
   },
   "source": [
    "The model outputs a tensor of shape (`batch_size`, `number of samples`, `prediction length`).\n",
    "\n",
    "In this case, we get `100` possible values for the next `24` months (for each example in the batch which is of size `64`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DwAfSZitZNAQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1706407460905,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "DwAfSZitZNAQ",
    "outputId": "ba8cc83b-03a5-4b75-91ce-36893f2ed911"
   },
   "outputs": [],
   "source": [
    "forecasts[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fCTBw_t91xwH",
   "metadata": {
    "id": "fCTBw_t91xwH"
   },
   "source": [
    "We'll stack them vertically, to get forecasts for all time-series in the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "du1GyJVXlpHp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1706407460905,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "du1GyJVXlpHp",
    "outputId": "51cfca41-ff40-48aa-a620-7de1d80a245f"
   },
   "outputs": [],
   "source": [
    "forecasts = np.vstack(forecasts)\n",
    "print(forecasts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wlvFCdgiA9oy",
   "metadata": {
    "id": "wlvFCdgiA9oy"
   },
   "source": [
    "We can evaluate the resulting forecast with respect to the ground truth out of sample values present in the test set. For that, we'll use the ðŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) library, which includes the [MASE](https://huggingface.co/spaces/evaluate-metric/mase) and [sMAPE](https://huggingface.co/spaces/evaluate-metric/smape) metrics.\n",
    "\n",
    "We calculate both metrics for each time series in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0yb9RnczYE4z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "d8632bc54cc14c029608bd8817a5e486",
      "a224b67a73e145449494c15741f44d8c",
      "b656c307a1c241f69602e5cfa485515d",
      "ff4daef53da9486fb35c6dcc8e64edac",
      "fb8d3404682542f19e59f521742468c7",
      "e43bf3e7d1924faeb5047b17b95578ed",
      "d06ae6e87726460a9db8c1e9be81671a",
      "854144dc991e407bb08265efcc6bfcc3",
      "7580dccdcaee4a35bc1fb6051c36392d",
      "690c755855e54ffab2a07cbc4fa261b6",
      "feec376709ae476b931fc1faec6e2f27",
      "c38acf7e2a09451fa51f371587a33e0d",
      "86426e6643bf49e59e63860d3c7c9bff",
      "b0bcbac8516e4619a5331b10071679e8",
      "7a00ca0b924748ad961793c1987a3521",
      "5b5cf02f06e34560b079fa2f972a0c58",
      "0fba3b67658d47abb0810d89b557173c",
      "bd2e91aaeebd45688ea96afcb940e1be",
      "e6dffd9777674e379f60e3f15d5914f6",
      "a4b66fc19b2d425ebd3c0f7f2141094f",
      "e647cc4a8c8c47b980e33d11f08aca5f",
      "09f8dea27ff4453183956fcfcf6ba265"
     ]
    },
    "executionInfo": {
     "elapsed": 9141,
     "status": "ok",
     "timestamp": 1706407470029,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "0yb9RnczYE4z",
    "outputId": "748cdb3b-4fd8-4d1f-8a20-edcfea167b51"
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from gluonts.time_feature import get_seasonality\n",
    "\n",
    "mae_metric = load(\"evaluate-metric/mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f37483",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_median = np.median(forecasts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bbf6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [test_data['target'][-prediction_length:] for test_data in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mae_metric.compute(predictions=forecast_median,references=ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdcfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moksM2QmMACr",
   "metadata": {
    "id": "moksM2QmMACr"
   },
   "source": [
    "To plot the prediction for any time series with respect the ground truth test data we define the following helper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae05011",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1706407470030,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "3ae05011"
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "def plot(ts_index):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    index = pd.period_range(\n",
    "        start=test_dataset[ts_index][FieldName.START],\n",
    "        periods=len(test_dataset[ts_index][FieldName.TARGET]),\n",
    "        freq=freq,\n",
    "    ).to_timestamp()\n",
    "\n",
    "    # Major ticks every half year, minor ticks every month,\n",
    "    ax.xaxis.set_major_locator(mdates.MinuteLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MinuteLocator())\n",
    "\n",
    "    ax.plot(\n",
    "        index[-2 * prediction_length :],\n",
    "        test_dataset[ts_index][\"target\"][-2 * prediction_length :],\n",
    "        label=\"actual\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        index[-prediction_length:],\n",
    "        np.median(forecasts[ts_index], axis=0),\n",
    "        label=\"median\",\n",
    "    )\n",
    "\n",
    "    plt.fill_between(\n",
    "        index[-prediction_length:],\n",
    "        forecasts[ts_index].mean(0) - forecasts[ts_index].std(axis=0),\n",
    "        forecasts[ts_index].mean(0) + forecasts[ts_index].std(axis=0),\n",
    "        alpha=0.3,\n",
    "        interpolate=True,\n",
    "        label=\"+/- 1-std\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mwtksAcxMHoK",
   "metadata": {
    "id": "mwtksAcxMHoK"
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5N8fdnm_MKQP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1706407471503,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "5N8fdnm_MKQP",
    "outputId": "a1187681-cca4-4174-b929-3f1605834a66"
   },
   "outputs": [],
   "source": [
    "plot(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nf4Y8MvLMOi8",
   "metadata": {
    "id": "Nf4Y8MvLMOi8"
   },
   "source": [
    "How do we compare against other models? The [Monash Time Series Repository](https://forecastingdata.org/#results) has a comparison table of test set MASE metrics which we can add to:\n",
    "\n",
    "|Dataset | \tSES| \tTheta | \tTBATS| \tETS\t| (DHR-)ARIMA| \tPR|\tCatBoost |\tFFNN\t| DeepAR | \tN-BEATS | \tWaveNet| \t**Transformer** (Our) |\n",
    "|:------------------:|:-----------------:|:--:|:--:|:--:|:--:|:--:|:--:|:---:|:---:|:--:|:--:|:--:|\n",
    "|Tourism Monthly | \t3.306 |\t1.649 |\t1.751 |\t1.526|\t1.589|\t1.678\t|1.699|\t1.582\t| 1.409\t| 1.574|\t1.482\t|  **1.256**|\n",
    "\n",
    "Note that, with our model, we are beating all other models reported (see also table 2 in the corresponding [paper](https://openreview.net/pdf?id=wEc1mgAjU-)), and we didn't do any hyperparameter tuning. We just trained the Transformer for 40 epochs.\n",
    "\n",
    "Of course, we need to be careful with just claiming state-of-the-art results on time series with neural networks, as it seems [\"XGBoost is typically all you need\"](https://www.sciencedirect.com/science/article/pii/S0169207021001679).  We are just very curious to see how far neural networks can bring us, and whether Transformers are going to be useful in this domain. This particular dataset seems to indicate that it's definitely worth exploring.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "We would encourage the readers to try out the [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb) with other time series datasets from the [Hub](https://huggingface.co/datasets/monash_tsf) and replace the appropriate frequency and prediction length parameters. For your datasets, one would need to convert them to the convention used by GluonTS, which is explained nicely in their documentation [here](https://ts.gluon.ai/stable/tutorials/forecasting/extended_tutorial.html#What-is-in-a-dataset?). We have also prepared an example notebook showing you how to convert your dataset into the ðŸ¤— datasets format [here](https://github.com/huggingface/notebooks/blob/main/examples/time_series_datasets.ipynb).\n",
    "\n",
    "As time series researchers will know, there has been a lot of interest in applying Transformer based models to the time series problem. The vanilla Transformer is just one of many attention-based models and so there is a need to add more models to the library.\n",
    "\n",
    "At the moment there is nothing stopping us from modeling multivariate time series, however for that one would need to instantiate the model with a multivariate distribution head. Currently, diagonal independent distributions are supported, and other multivariate distributions will be added. Stay tuned for a future blog post which will include a tutorial.\n",
    "\n",
    "Another thing on the roadmap is time series classification. This entails adding a time series model with a classification head to the library, for the anomaly detection task for example.\n",
    "\n",
    "The current model assumes the presence of a date-time together with the time series values, which might not be the case for every time series in the wild. See for instance neuroscience datasets like the one from [WOODS](https://woods-benchmarks.github.io/). Thus, one would need to generalize the current model to make some inputs optional in the whole pipeline.\n",
    "\n",
    "Finally, the NLP/Vision domain has benefitted tremendously from [large pre-trained models](https://arxiv.org/abs/1810.04805), while this is not the case as far as we are aware for the time series domain. Transformer based models seem like the obvious choice in pursuing this avenue of research and we cannot wait to see what researchers and practitioners come up with!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CYtLcclMTs99",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1706407471503,
     "user": {
      "displayName": "Man Chau",
      "userId": "01327881085848547519"
     },
     "user_tz": -480
    },
    "id": "CYtLcclMTs99"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb",
     "timestamp": 1706407029241
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05617c58c2d6480e959ea86e062560a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0874ef98f4304178b87563ae848f14a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09f8dea27ff4453183956fcfcf6ba265": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a534a75abf644839b4445fb6bbb9044": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ec69f8a396f44a0ab6dc92e806b9933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0fba3b67658d47abb0810d89b557173c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1316e736de174cc6b404d5628c52e2b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "206df40c70de49288e50d7964202fcfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "212dd64a5b4d434dadc3c0571a0ab08e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9586c803b09a4542961132c54731f196",
       "IPY_MODEL_413f4508fcf24998834d4e99bb000778",
       "IPY_MODEL_b5d0c21244cc446e80e1bc5329bcfc06"
      ],
      "layout": "IPY_MODEL_d935711b9310481691564520f798d59c"
     }
    },
    "2164e34e1eff439fad87e4d5224d75cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e879f67cde1e4c9990f9dcafbd10f659",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_24e9bded7e8d40f392a9768bfd546ca4",
      "value": "Generating train split: 100%"
     }
    },
    "23516981e77d473d9d51c9b7fe1fba0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24e9bded7e8d40f392a9768bfd546ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32f261991e5744c8b8f795a459e3b32e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33847d2ee8ce43d59715d81707237c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a701795256a949eda47ddee5fa68fbc8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a8342515fed842e4b978734cf50d79a3",
      "value": "Downloading data: 100%"
     }
    },
    "35294501c4644d6da6ec1c1a41483e78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "390197f5b6d042c1a38708be02d9d19e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a159958b69747c386e5f25405ff2ea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "413f4508fcf24998834d4e99bb000778": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95f812e5d34f4439a037d4937ad43598",
      "max": 281265,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c600800c72948a3a33a24de421f1838",
      "value": 281265
     }
    },
    "429b983eb84c498a89afbbbb5f1873b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "444efaf421ef4ab9b32b75b82cd4dce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e0994c7197e411e9e0a13044bda290a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_742969659c374d6b92997f40c3f877a5",
       "IPY_MODEL_b28a38cebd2b48448af0b9f9f911ab09",
       "IPY_MODEL_c312591c679d402fa4764f0ad929a63c"
      ],
      "layout": "IPY_MODEL_23516981e77d473d9d51c9b7fe1fba0d"
     }
    },
    "502cda2a0417457e8fc8ee9cf7cb9ef3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55998e0512f54513aea2d9934deccc36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b64e67a6092244e688ccdaeeaf56164c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5b96ddb2041e467a94fd9dbd68c6f84d",
      "value": " 366/366 [00:00&lt;00:00, 5513.03 examples/s]"
     }
    },
    "5add64a717b5476595c2ea6abde02213": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b5cf02f06e34560b079fa2f972a0c58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b96ddb2041e467a94fd9dbd68c6f84d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "610e4e171ac54582bc171f8d6b4c3ab2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e32c17ad79754e539125124de55cbf0d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d74bd6f020804d1099c9155264cfbe81",
      "value": " 366/366 [00:00&lt;00:00, 3342.00 examples/s]"
     }
    },
    "690c755855e54ffab2a07cbc4fa261b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ed97b1cbcf54b30aee61246b0371644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bea4b08b97014c1095d07b8c02a7d41a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_70e6663791554b3d8f288c39a3b3c523",
      "value": " 366/366 [00:00&lt;00:00, 8418.93 examples/s]"
     }
    },
    "70e6663791554b3d8f288c39a3b3c523": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "742969659c374d6b92997f40c3f877a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa87bede459c43b485ab8cfe99e9fd6a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_db842c266e49439bb7d7ad1b971fa54c",
      "value": "Downloading data: 100%"
     }
    },
    "7580dccdcaee4a35bc1fb6051c36392d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "786a6368a2c94b6da4426f35a9caa63e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a00ca0b924748ad961793c1987a3521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e647cc4a8c8c47b980e33d11f08aca5f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_09f8dea27ff4453183956fcfcf6ba265",
      "value": " 6.65k/6.65k [00:00&lt;00:00, 393kB/s]"
     }
    },
    "7f794795634f4956b6a3b1327bb7425e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84718c8479074305b0466ca45bd1a301": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "854144dc991e407bb08265efcc6bfcc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86426e6643bf49e59e63860d3c7c9bff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fba3b67658d47abb0810d89b557173c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bd2e91aaeebd45688ea96afcb940e1be",
      "value": "Downloading builder script: 100%"
     }
    },
    "8a03bd9f5ff74b748d7ea45dd8097b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bcd9c18c2e04d3aa173840211b06935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0874ef98f4304178b87563ae848f14a0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_baf100d6adda4bd9bafd3bf9ac990090",
      "value": "Generating validation split: 100%"
     }
    },
    "8ea24543b68a467d82a29214109b4317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8efc4126072a40bfbdbc721db4a61db9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32f261991e5744c8b8f795a459e3b32e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_429b983eb84c498a89afbbbb5f1873b4",
      "value": "Generating test split: 100%"
     }
    },
    "902f66d029224a31af9127ca29a9ba69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94e3f522f2c54320b82b60bc22bce486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9586c803b09a4542961132c54731f196": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5add64a717b5476595c2ea6abde02213",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7f794795634f4956b6a3b1327bb7425e",
      "value": "Downloading data: 100%"
     }
    },
    "95f812e5d34f4439a037d4937ad43598": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99a63369dade4e06b2935a3dece3eea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bcd9c18c2e04d3aa173840211b06935",
       "IPY_MODEL_cd1f39d022cf47068fc891394f99aa8d",
       "IPY_MODEL_55998e0512f54513aea2d9934deccc36"
      ],
      "layout": "IPY_MODEL_e4a65c14a3854ad68485a805e6a17c23"
     }
    },
    "9c600800c72948a3a33a24de421f1838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d59e6563c114a409044a0d6cfcda49e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1971c03e1574365858df9440efc27a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2164e34e1eff439fad87e4d5224d75cd",
       "IPY_MODEL_e88e09b0c87a4e52ac69350cc8a1b32f",
       "IPY_MODEL_610e4e171ac54582bc171f8d6b4c3ab2"
      ],
      "layout": "IPY_MODEL_786a6368a2c94b6da4426f35a9caa63e"
     }
    },
    "a224b67a73e145449494c15741f44d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e43bf3e7d1924faeb5047b17b95578ed",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d06ae6e87726460a9db8c1e9be81671a",
      "value": "Downloading builder script: 100%"
     }
    },
    "a4b66fc19b2d425ebd3c0f7f2141094f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5d9de1890754312bfcf6ea27066b33e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a534a75abf644839b4445fb6bbb9044",
      "max": 257534,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1316e736de174cc6b404d5628c52e2b5",
      "value": 257534
     }
    },
    "a701795256a949eda47ddee5fa68fbc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8342515fed842e4b978734cf50d79a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac943f7a8e1f4f95ad0cd99837414fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dce901c3f04d4caa8cb562488f248429",
      "max": 366,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94e3f522f2c54320b82b60bc22bce486",
      "value": 366
     }
    },
    "b0bcbac8516e4619a5331b10071679e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6dffd9777674e379f60e3f15d5914f6",
      "max": 6651,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4b66fc19b2d425ebd3c0f7f2141094f",
      "value": 6651
     }
    },
    "b28a38cebd2b48448af0b9f9f911ab09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_206df40c70de49288e50d7964202fcfd",
      "max": 304634,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_902f66d029224a31af9127ca29a9ba69",
      "value": 304634
     }
    },
    "b5d0c21244cc446e80e1bc5329bcfc06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05617c58c2d6480e959ea86e062560a5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3a159958b69747c386e5f25405ff2ea0",
      "value": " 281k/281k [00:00&lt;00:00, 307kB/s]"
     }
    },
    "b64e67a6092244e688ccdaeeaf56164c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b656c307a1c241f69602e5cfa485515d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_854144dc991e407bb08265efcc6bfcc3",
      "max": 5504,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7580dccdcaee4a35bc1fb6051c36392d",
      "value": 5504
     }
    },
    "baf100d6adda4bd9bafd3bf9ac990090": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd2e91aaeebd45688ea96afcb940e1be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bdf49b47735b490390d00d5b00c17715": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33847d2ee8ce43d59715d81707237c76",
       "IPY_MODEL_a5d9de1890754312bfcf6ea27066b33e",
       "IPY_MODEL_c007cee8385d424c8077d56b17da4743"
      ],
      "layout": "IPY_MODEL_d741693348944f719af7c6093b356976"
     }
    },
    "bea4b08b97014c1095d07b8c02a7d41a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c007cee8385d424c8077d56b17da4743": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_502cda2a0417457e8fc8ee9cf7cb9ef3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8a03bd9f5ff74b748d7ea45dd8097b78",
      "value": " 258k/258k [00:01&lt;00:00, 228kB/s]"
     }
    },
    "c0a4df9f3bca430f8e608e9b2fd9acec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8efc4126072a40bfbdbc721db4a61db9",
       "IPY_MODEL_ac943f7a8e1f4f95ad0cd99837414fa6",
       "IPY_MODEL_6ed97b1cbcf54b30aee61246b0371644"
      ],
      "layout": "IPY_MODEL_390197f5b6d042c1a38708be02d9d19e"
     }
    },
    "c312591c679d402fa4764f0ad929a63c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35294501c4644d6da6ec1c1a41483e78",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_444efaf421ef4ab9b32b75b82cd4dce8",
      "value": " 305k/305k [00:00&lt;00:00, 332kB/s]"
     }
    },
    "c38acf7e2a09451fa51f371587a33e0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86426e6643bf49e59e63860d3c7c9bff",
       "IPY_MODEL_b0bcbac8516e4619a5331b10071679e8",
       "IPY_MODEL_7a00ca0b924748ad961793c1987a3521"
      ],
      "layout": "IPY_MODEL_5b5cf02f06e34560b079fa2f972a0c58"
     }
    },
    "cd1f39d022cf47068fc891394f99aa8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84718c8479074305b0466ca45bd1a301",
      "max": 366,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ec69f8a396f44a0ab6dc92e806b9933",
      "value": 366
     }
    },
    "d06ae6e87726460a9db8c1e9be81671a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d741693348944f719af7c6093b356976": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d74bd6f020804d1099c9155264cfbe81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8632bc54cc14c029608bd8817a5e486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a224b67a73e145449494c15741f44d8c",
       "IPY_MODEL_b656c307a1c241f69602e5cfa485515d",
       "IPY_MODEL_ff4daef53da9486fb35c6dcc8e64edac"
      ],
      "layout": "IPY_MODEL_fb8d3404682542f19e59f521742468c7"
     }
    },
    "d935711b9310481691564520f798d59c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db842c266e49439bb7d7ad1b971fa54c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dce901c3f04d4caa8cb562488f248429": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e32c17ad79754e539125124de55cbf0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e43bf3e7d1924faeb5047b17b95578ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4a65c14a3854ad68485a805e6a17c23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e647cc4a8c8c47b980e33d11f08aca5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6dffd9777674e379f60e3f15d5914f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e879f67cde1e4c9990f9dcafbd10f659": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e88e09b0c87a4e52ac69350cc8a1b32f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ea24543b68a467d82a29214109b4317",
      "max": 366,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d59e6563c114a409044a0d6cfcda49e",
      "value": 366
     }
    },
    "fa87bede459c43b485ab8cfe99e9fd6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb8d3404682542f19e59f521742468c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feec376709ae476b931fc1faec6e2f27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff4daef53da9486fb35c6dcc8e64edac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_690c755855e54ffab2a07cbc4fa261b6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_feec376709ae476b931fc1faec6e2f27",
      "value": " 5.50k/5.50k [00:00&lt;00:00, 362kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
