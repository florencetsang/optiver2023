{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x1518535c2fc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_data_from_csv\n",
    "from data_preprocessor.data_preprocessor import CompositeDataPreprocessor, ReduceMemUsageDataPreprocessor, FillNaPreProcessor\n",
    "from data_preprocessor.feature_engineering import (\n",
    "    BasicFeaturesPreprocessor,\n",
    "    DupletsTripletsPreprocessor,\n",
    "    MovingAvgPreProcessor,\n",
    "    RemoveIrrelevantFeaturesDataPreprocessor,\n",
    "    DropTargetNADataPreprocessor,\n",
    "    FarNearPriceFillNaPreprocessor,\n",
    "    MovingAvgFillNaPreprocessor,\n",
    "    RemoveRecordsByStockDateIdPreprocessor,\n",
    ")\n",
    "from data_preprocessor.stock_feature_engineering import (\n",
    "    StockNormalizeFeaturesPreprocessor,\n",
    ")\n",
    "from data_preprocessor.polynomial_features import PolynomialFeaturesPreProcessor\n",
    "from data_preprocessor.stockid_features import StockIdFeaturesPreProcessor\n",
    "# from data_preprocessor.deep_feature_synthesis import DfsPreProcessor\n",
    "from data_generator.data_generator import DefaultTrainEvalDataGenerator, ManualKFoldDataGenerator, TimeSeriesKFoldDataGenerator\n",
    "\n",
    "from model_post_processor.model_post_processor import CompositeModelPostProcessor, SaveModelPostProcessor, KerasSaveModelPostProcessor\n",
    "\n",
    "from train_pipeline.train_pipeline import DefaultTrainPipeline\n",
    "\n",
    "from train_pipeline.train_pipeline_callbacks import MAECallback\n",
    "from utils.scoring_utils import ScoringUtils\n",
    "from model_pipeline.dummy_models import BaselineEstimator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from model_pipeline.mlp_pipeline import MLPModelPipelineFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_fold = 5\n",
    "model_save_dir = './models'\n",
    "\n",
    "processors = [    \n",
    "    ReduceMemUsageDataPreprocessor(verbose=True),\n",
    "    RemoveRecordsByStockDateIdPreprocessor([\n",
    "        {\"stock_id\": 19, \"date_id\": 438},\n",
    "        {\"stock_id\": 101, \"date_id\": 328},\n",
    "        {\"stock_id\": 131, \"date_id\": 35},\n",
    "        {\"stock_id\": 158, \"date_id\": 388},\n",
    "    ]),\n",
    "    FarNearPriceFillNaPreprocessor(),\n",
    "    # BasicFeaturesPreprocessor(),\n",
    "    # DupletsTripletsPreprocessor(),\n",
    "    # MovingAvgPreProcessor(\"wap\"),\n",
    "    # MovingAvgFillNaPreprocessor(\"wap\", 1.0),\n",
    "    # StockIdFeaturesPreProcessor(),   \n",
    "    # DTWKMeansPreprocessor(),\n",
    "    # DfsPreProcessor(),\n",
    "    # DropTargetNADataPreprocessor(),    \n",
    "    RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id', 'row_id']),\n",
    "    # FillNaPreProcessor(1.0),\n",
    "    # PolynomialFeaturesPreProcessor(),\n",
    "]\n",
    "\n",
    "\n",
    "processor = CompositeDataPreprocessor(processors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
      "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
      "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
      "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# DATA_PATH = '/kaggle/input'\n",
    "DATA_PATH = '..'\n",
    "df_train, df_test, revealed_targets, sample_submission = load_data_from_csv(DATA_PATH)\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = df_train.copy(deep=True)\n",
    "# df_train = df_train[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompositeDataPreprocessor - original df shape: (5237980, 17)\n",
      "Processing ReduceMemUsageDataPreprocessor...\n",
      "Memory usage of dataframe is 679.36 MB\n",
      "Memory usage after optimization is: 304.72 MB\n",
      "Decreased by 55.15%\n",
      "dtypes:\n",
      "stock_id                     int16\n",
      "date_id                      int16\n",
      "seconds_in_bucket            int16\n",
      "imbalance_size             float32\n",
      "imbalance_buy_sell_flag       int8\n",
      "reference_price            float32\n",
      "matched_size               float32\n",
      "far_price                  float32\n",
      "near_price                 float32\n",
      "bid_price                  float32\n",
      "bid_size                   float32\n",
      "ask_price                  float32\n",
      "ask_size                   float32\n",
      "wap                        float32\n",
      "target                     float32\n",
      "time_id                      int16\n",
      "row_id                      object\n",
      "dtype: object\n",
      "ReduceMemUsageDataPreprocessor took 0.57s. New df shape: (5237980, 17).\n",
      "Processing RemoveRecordsByStockDateIdPreprocessor...\n",
      "RemoveRecordsByStockDateIdPreprocessor - removing 220 records\n",
      "RemoveRecordsByStockDateIdPreprocessor took 0.55s. New df shape: (5237760, 17).\n",
      "Processing FarNearPriceFillNaPreprocessor...\n",
      "FarNearPriceFillNaPreprocessor took 0.04s. New df shape: (5237760, 17).\n",
      "Processing RemoveIrrelevantFeaturesDataPreprocessor...\n",
      "RemoveIrrelevantFeaturesDataPreprocessor took 0.17s. New df shape: (5237760, 13).\n",
      "CompositeDataPreprocessor - final df shape: (5237760, 13)\n"
     ]
    }
   ],
   "source": [
    "df_train = processor.apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
      "       'reference_price', 'matched_size', 'far_price', 'near_price',\n",
      "       'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380277.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.500000</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.030273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.666039e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.040039</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.089844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.519986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.028799e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.000000</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.389950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191768e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389746.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.899902</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.406250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.010201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.475500e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.539062</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.100006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.349849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237975</th>\n",
       "      <td>540</td>\n",
       "      <td>2.440723e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>28280362.00</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>32257.039062</td>\n",
       "      <td>1.000434</td>\n",
       "      <td>319862.406250</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>2.310276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237976</th>\n",
       "      <td>540</td>\n",
       "      <td>3.495105e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>9187699.00</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>205108.406250</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>93393.070312</td>\n",
       "      <td>1.000819</td>\n",
       "      <td>-8.220077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237977</th>\n",
       "      <td>540</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>12725436.00</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>16790.660156</td>\n",
       "      <td>0.995883</td>\n",
       "      <td>180038.312500</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>1.169443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237978</th>\n",
       "      <td>540</td>\n",
       "      <td>1.000899e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>94773272.00</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>125631.718750</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>669893.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>-1.540184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237979</th>\n",
       "      <td>540</td>\n",
       "      <td>1.884286e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>24073678.00</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>250081.437500</td>\n",
       "      <td>1.002447</td>\n",
       "      <td>300167.562500</td>\n",
       "      <td>1.002274</td>\n",
       "      <td>-6.530285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5237760 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         seconds_in_bucket  imbalance_size  imbalance_buy_sell_flag  \\\n",
       "0                        0    3.180603e+06                        1   \n",
       "1                        0    1.666039e+05                       -1   \n",
       "2                        0    3.028799e+05                       -1   \n",
       "3                        0    1.191768e+07                       -1   \n",
       "4                        0    4.475500e+05                       -1   \n",
       "...                    ...             ...                      ...   \n",
       "5237975                540    2.440723e+06                       -1   \n",
       "5237976                540    3.495105e+05                       -1   \n",
       "5237977                540    0.000000e+00                        0   \n",
       "5237978                540    1.000899e+06                        1   \n",
       "5237979                540    1.884286e+06                       -1   \n",
       "\n",
       "         reference_price  matched_size  far_price  near_price  bid_price  \\\n",
       "0               0.999812   13380277.00   1.000000    1.000000   0.999812   \n",
       "1               0.999896    1642214.25   1.000000    1.000000   0.999896   \n",
       "2               0.999561    1819368.00   1.000000    1.000000   0.999403   \n",
       "3               1.000171   18389746.00   1.000000    1.000000   0.999999   \n",
       "4               0.999532   17860614.00   1.000000    1.000000   0.999394   \n",
       "...                  ...           ...        ...         ...        ...   \n",
       "5237975         1.000317   28280362.00   0.999734    0.999734   1.000317   \n",
       "5237976         1.000643    9187699.00   1.000129    1.000386   1.000643   \n",
       "5237977         0.995789   12725436.00   0.995789    0.995789   0.995789   \n",
       "5237978         0.999210   94773272.00   0.999210    0.999210   0.998970   \n",
       "5237979         1.002129   24073678.00   1.000859    1.001494   1.002129   \n",
       "\n",
       "              bid_size  ask_price       ask_size       wap    target  \n",
       "0         60651.500000   1.000026    8493.030273  1.000000 -3.029704  \n",
       "1          3233.040039   1.000660   20605.089844  1.000000 -5.519986  \n",
       "2         37956.000000   1.000298   18995.000000  1.000000 -8.389950  \n",
       "3          2324.899902   1.000214  479032.406250  1.000000 -4.010201  \n",
       "4         16485.539062   1.000016     434.100006  1.000000 -7.349849  \n",
       "...                ...        ...            ...       ...       ...  \n",
       "5237975   32257.039062   1.000434  319862.406250  1.000328  2.310276  \n",
       "5237976  205108.406250   1.000900   93393.070312  1.000819 -8.220077  \n",
       "5237977   16790.660156   0.995883  180038.312500  0.995797  1.169443  \n",
       "5237978  125631.718750   0.999210  669893.000000  0.999008 -1.540184  \n",
       "5237979  250081.437500   1.002447  300167.562500  1.002274 -6.530285  \n",
       "\n",
       "[5237760 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n"
     ]
    }
   ],
   "source": [
    "feat_dynamic_real = df_train.columns.tolist()\n",
    "feat_dynamic_real.remove(\"target\")\n",
    "num_input_features = len(feat_dynamic_real)\n",
    "print(num_input_features, feat_dynamic_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5237760,) (0,)\n"
     ]
    }
   ],
   "source": [
    "# should not have any na features\n",
    "any_na_values_mask = df_train[feat_dynamic_real].isna().any(axis=1)\n",
    "print(any_na_values_mask.shape, any_na_values_mask[any_na_values_mask].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize features (TODO: normalize by group? stock id?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matched_size', 'bid_size', 'ask_size', 'imbalance_size']\n"
     ]
    }
   ],
   "source": [
    "normalize_columns = set([\n",
    "    \"imbalance_size\",\n",
    "    \"matched_size\",\n",
    "    \"bid_size\",\n",
    "    \"ask_size\",\n",
    "])\n",
    "normalize_columns = list(normalize_columns.intersection(set(feat_dynamic_real)))\n",
    "print(normalize_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"20240422_mlp_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data_generator = DefaultTrainEvalDataGenerator()\n",
    "k_fold_data_generator = TimeSeriesKFoldDataGenerator(n_fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_post_processor = CompositeModelPostProcessor([\n",
    "    KerasSaveModelPostProcessor(save_dir=model_save_dir)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate data\n",
      "Start train and tune, num_train_eval_sets: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generate data\")\n",
    "train_dfs, eval_dfs, num_train_eval_sets = k_fold_data_generator.generate(df_train)\n",
    "\n",
    "models = []\n",
    "model_res = []\n",
    "\n",
    "print(f\"Start train and tune, num_train_eval_sets: {num_train_eval_sets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_pipeline_factory = MLPModelPipelineFactory(model_name, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"layers\": 0,\n",
    "    'learning_rate': 0.00001,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4 - {\n",
      "  \"layers\": 0,\n",
      "  \"learning_rate\": 1e-05,\n",
      "  \"epochs\": 5,\n",
      "  \"batch_size\": 256\n",
      "}\n",
      "Training fold 4 - start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,217</span> (36.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,217\u001b[0m (36.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,217</span> (36.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,217\u001b[0m (36.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training fold 4 - initialized\n",
      "Training fold 4 - train size: (4364800, 13), eval size: (872960, 13)\n",
      "\u001b[1m17050/17050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step\n",
      "\u001b[1m3410/3410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "Training fold 4 - before training - train_manual_mae: 7.574123859405518, eval_manual_mae: 7.200293064117432\n",
      "Training fold 4 - start training\n",
      "Epoch 1/5\n",
      "\u001b[1m17050/17050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 9ms/step - loss: 6.4943 - mae: 6.4943 - val_loss: 5.9842 - val_mae: 5.9842\n",
      "Epoch 2/5\n",
      "\u001b[1m 5260/17050\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 9ms/step - loss: 6.4831 - mae: 6.4831"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - before training - train_manual_mae: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_manual_mae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, eval_manual_mae: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_manual_mae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - start training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m train_res \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mtrain(X_train_fold, y_train_fold, X_val_fold, y_val_fold, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m fold_model \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mget_model()\n\u001b[1;32m     33\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(fold_model)\n",
      "File \u001b[0;32m~/optiver2023/florence/model_pipeline/mlp_pipeline.py:73\u001b[0m, in \u001b[0;36mMLPModelPipeline.train\u001b[0;34m(self, train_X, train_Y, eval_X, eval_Y, eval_res)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_X, train_Y, eval_X, eval_Y, eval_res):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m         history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     74\u001b[0m             train_X,\n\u001b[1;32m     75\u001b[0m             train_Y,\n\u001b[1;32m     76\u001b[0m             validation_data\u001b[38;5;241m=\u001b[39m(eval_X, eval_Y),\n\u001b[1;32m     77\u001b[0m             epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     78\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit exception\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/trainer.py:254\u001b[0m, in \u001b[0;36mTorchTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 254\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(data)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs))\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/trainer.py:117\u001b[0m, in \u001b[0;36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(data)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/trainer.py:72\u001b[0m, in \u001b[0;36mTorchTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply(gradients, trainable_weights)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model does not have any trainable weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:340\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_apply_gradients(grads, trainable_variables)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:390\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    383\u001b[0m     ops\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m    384\u001b[0m         is_update_step,\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: _update_step_fn(\u001b[38;5;28mself\u001b[39m, grads, trainable_variables),\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: _grad_accumulation_fn(\u001b[38;5;28mself\u001b[39m, grads),\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# Run udpate step.\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_update_step(\n\u001b[1;32m    391\u001b[0m         grads, trainable_variables, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    397\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/optimizers/torch_parallel_optimizer.py:10\u001b[0m, in \u001b[0;36mTorchParallelOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@torch_utils\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backend_update_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads, trainable_variables, learning_rate):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_update_step(\n\u001b[1;32m     11\u001b[0m         grads,\n\u001b[1;32m     12\u001b[0m         trainable_variables,\n\u001b[1;32m     13\u001b[0m         learning_rate,\n\u001b[1;32m     14\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/optimizers/torch_adam.py:20\u001b[0m, in \u001b[0;36mAdam._parallel_update_step\u001b[0;34m(self, grads, variables, learning_rate)\u001b[0m\n\u001b[1;32m     18\u001b[0m dtype \u001b[38;5;241m=\u001b[39m variables[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     19\u001b[0m lr \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(learning_rate, dtype)\n\u001b[0;32m---> 20\u001b[0m local_step \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype)\n\u001b[1;32m     22\u001b[0m beta_1_power \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mpower(ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1, dtype), local_step)\n\u001b[1;32m     23\u001b[0m beta_2_power \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mpower(ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2, dtype), local_step)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/common/variables.py:364\u001b[0m, in \u001b[0;36mKerasVariable.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    363\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_tensor(other, dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype))\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/core.py:108\u001b[0m, in \u001b[0;36mVariable._convert_to_tensor\u001b[0;34m(self, value, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_tensor(value, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/core.py:203\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m result_type(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mgetattr\u001b[39m(item, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(item)) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(x)]\n\u001b[1;32m    202\u001b[0m     )\n\u001b[0;32m--> 203\u001b[0m dtype \u001b[38;5;241m=\u001b[39m to_torch_dtype(dtype)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mas_tensor(x, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mget_device())\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/torch/core.py:86\u001b[0m, in \u001b[0;36mto_torch_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_torch_dtype\u001b[39m(dtype):\n\u001b[0;32m---> 86\u001b[0m     standardized_dtype \u001b[38;5;241m=\u001b[39m TORCH_DTYPES\u001b[38;5;241m.\u001b[39mget(standardize_dtype(dtype), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m standardized_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported dtype for PyTorch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/keras/src/backend/common/variables.py:490\u001b[0m, in \u001b[0;36mstandardize_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    486\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(dtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(dtype)\n\u001b[1;32m    489\u001b[0m ):\n\u001b[0;32m--> 490\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(dtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    492\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for fold in range(num_train_eval_sets):\n",
    "for fold in range(4, 5):\n",
    "    print(f\"Training fold {fold} - {json.dumps(param, indent=2)}\")\n",
    "    \n",
    "    print(f\"Training fold {fold} - start\")\n",
    "\n",
    "    model_pipeline = mlp_model_pipeline_factory.create_model_pipeline()\n",
    "    model_pipeline.init_model(\n",
    "        param = param,\n",
    "        fold=fold,\n",
    "    )\n",
    "    print(f\"Training fold {fold} - initialized\")\n",
    "\n",
    "    fold_df_train = train_dfs[fold]\n",
    "    fold_df_eval = eval_dfs[fold]\n",
    "    print(f\"Training fold {fold} - train size: {fold_df_train.shape}, eval size: {fold_df_eval.shape}\")\n",
    "\n",
    "    # normalize features, scaler per fold, fit on training set, transform both training and validation set\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(fold_df_train[normalize_columns])\n",
    "    fold_df_train[normalize_columns] = scaler.transform(fold_df_train[normalize_columns])\n",
    "    fold_df_eval[normalize_columns] = scaler.transform(fold_df_eval[normalize_columns])\n",
    "\n",
    "    X_train_fold, y_train_fold, X_val_fold, y_val_fold = model_pipeline.create_XY(fold_df_train, fold_df_eval)\n",
    "\n",
    "    train_manual_mae = model_pipeline.eval_once(X_train_fold, y_train_fold)\n",
    "    eval_manual_mae = model_pipeline.eval_once(X_val_fold, y_val_fold)\n",
    "    print(f\"Training fold {fold} - before training - train_manual_mae: {train_manual_mae}, eval_manual_mae: {eval_manual_mae}\")\n",
    "\n",
    "    print(f\"Training fold {fold} - start training\")\n",
    "    train_res = model_pipeline.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold, None)\n",
    "    fold_model = model_pipeline.get_model()\n",
    "    models.append(fold_model)\n",
    "    model_res.append(train_res)\n",
    "    print(f\"Training fold {fold} - finished training\")\n",
    "\n",
    "    train_manual_mae = model_pipeline.eval_once(X_train_fold, y_train_fold)\n",
    "    eval_manual_mae = model_pipeline.eval_once(X_val_fold, y_val_fold)\n",
    "    print(f\"Training fold {fold} - after training - train_manual_mae: {train_manual_mae}, eval_manual_mae: {eval_manual_mae}\")\n",
    "    \n",
    "    model_post_processor.process(fold_model, model_pipeline, fold)\n",
    "    print(f\"Training fold {fold} - finished post processing\")\n",
    "\n",
    "    print(f\"Training fold {fold} - end\")\n",
    "\n",
    "print(f\"finished training, num_train_eval_sets: {num_train_eval_sets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
