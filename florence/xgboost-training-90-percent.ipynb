{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f8bf90",
   "metadata": {},
   "source": [
    "# Load the last fold of time-series K Fold (i.e. 90% data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6caadf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_data_from_csv\n",
    "from data_generator.data_generator import TimeSeriesKFoldDataGenerator\n",
    "from data_preprocessor.data_preprocessor import ReduceMemUsageDataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5578573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
      "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
      "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
      "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '..'\n",
    "df_train, df_test, revealed_targets, sample_submission = load_data_from_csv(DATA_PATH)\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911abb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_k_fold_data_generator = TimeSeriesKFoldDataGenerator(n_fold=5, test_set_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fac37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, eval_dfs, num_train_eval_sets = time_series_k_fold_data_generator.generate(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9e34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
      "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
      "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
      "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = train_dfs[-1].copy(deep=True)\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed84b296-ddc4-409b-97c8-17d926e279ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ReduceMemUsageDataPreprocessor().apply(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c47c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4714182, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99057e-f684-4e42-9155-a6cb1f843a93",
   "metadata": {},
   "source": [
    "# local cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bcefaec-d520-48b7-8c41-ebe58a309c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T16:12:32.500683Z",
     "start_time": "2024-03-26T16:12:22.027101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4714095, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "import polars as pl\n",
    "pl.__version__\n",
    "# train = pd.read_pickle(\"../raw_data/train.pkl\")\n",
    "train = train[~train['target'].isna()]\n",
    "print(train.shape)\n",
    "\n",
    "size_col = ['imbalance_size','matched_size','bid_size','ask_size']\n",
    "for _ in size_col:\n",
    "    train[f\"scale_{_}\"] = train[_] / train.groupby(['stock_id'])[_].transform('median')\n",
    "    \n",
    "#buy-side imbalance; 1\n",
    "#sell-side imbalance; -1\n",
    "#no imbalance; 0\n",
    "train['auc_bid_size'] = train['matched_size']\n",
    "train['auc_ask_size'] = train['matched_size']\n",
    "train.loc[train['imbalance_buy_sell_flag']==1,'auc_bid_size'] += train.loc[train['imbalance_buy_sell_flag']==1,'imbalance_size']\n",
    "train.loc[train['imbalance_buy_sell_flag']==-1,'auc_ask_size'] += train.loc[train['imbalance_buy_sell_flag']==-1,'imbalance_size']\n",
    "\n",
    "\n",
    "weight_df = pd.DataFrame()\n",
    "weight_df['stock_id'] = list(range(200))\n",
    "weight_df['weight'] =  [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "train = train.merge(weight_df,how='left',on=['stock_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdba70ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T16:12:33.838795Z",
     "start_time": "2024-03-26T16:12:32.502683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>...</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>scale_imbalance_size</th>\n",
       "      <th>scale_matched_size</th>\n",
       "      <th>scale_bid_size</th>\n",
       "      <th>scale_ask_size</th>\n",
       "      <th>auc_bid_size</th>\n",
       "      <th>auc_ask_size</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380277.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "      <td>1.678769</td>\n",
       "      <td>0.650845</td>\n",
       "      <td>3.240762</td>\n",
       "      <td>0.411688</td>\n",
       "      <td>16560880.00</td>\n",
       "      <td>1.338028e+07</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666039e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "      <td>1.132052</td>\n",
       "      <td>0.623041</td>\n",
       "      <td>0.257151</td>\n",
       "      <td>1.546081</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.808818e+06</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.028799e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "      <td>1.150879</td>\n",
       "      <td>0.501647</td>\n",
       "      <td>3.119786</td>\n",
       "      <td>1.441319</td>\n",
       "      <td>1819368.00</td>\n",
       "      <td>2.122248e+06</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.191768e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389746.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.010201</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "      <td>2.222158</td>\n",
       "      <td>0.307411</td>\n",
       "      <td>0.115296</td>\n",
       "      <td>22.696073</td>\n",
       "      <td>18389746.00</td>\n",
       "      <td>3.030743e+07</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.475500e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "      <td>0.227054</td>\n",
       "      <td>0.799698</td>\n",
       "      <td>0.992451</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>17860614.00</td>\n",
       "      <td>1.830816e+07</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714090</th>\n",
       "      <td>197</td>\n",
       "      <td>433</td>\n",
       "      <td>200</td>\n",
       "      <td>1.025122e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.001338</td>\n",
       "      <td>5150943.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001338</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.719828</td>\n",
       "      <td>23835</td>\n",
       "      <td>433_200_197</td>\n",
       "      <td>12.831796</td>\n",
       "      <td>0.517210</td>\n",
       "      <td>2.275128</td>\n",
       "      <td>0.971532</td>\n",
       "      <td>5150943.00</td>\n",
       "      <td>1.540217e+07</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714091</th>\n",
       "      <td>198</td>\n",
       "      <td>433</td>\n",
       "      <td>200</td>\n",
       "      <td>2.284637e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000486</td>\n",
       "      <td>91819888.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000486</td>\n",
       "      <td>...</td>\n",
       "      <td>4.969835</td>\n",
       "      <td>23835</td>\n",
       "      <td>433_200_198</td>\n",
       "      <td>2.954231</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>0.466223</td>\n",
       "      <td>0.716778</td>\n",
       "      <td>91819888.00</td>\n",
       "      <td>1.146663e+08</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714092</th>\n",
       "      <td>199</td>\n",
       "      <td>433</td>\n",
       "      <td>200</td>\n",
       "      <td>7.199116e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>8853477.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>...</td>\n",
       "      <td>15.560389</td>\n",
       "      <td>23835</td>\n",
       "      <td>433_200_199</td>\n",
       "      <td>5.571772</td>\n",
       "      <td>0.554376</td>\n",
       "      <td>0.560998</td>\n",
       "      <td>1.600156</td>\n",
       "      <td>8853477.00</td>\n",
       "      <td>1.605259e+07</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714093</th>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "      <td>210</td>\n",
       "      <td>5.022506e+06</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998591</td>\n",
       "      <td>15355458.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998591</td>\n",
       "      <td>...</td>\n",
       "      <td>2.729893</td>\n",
       "      <td>23836</td>\n",
       "      <td>433_210_0</td>\n",
       "      <td>2.650952</td>\n",
       "      <td>0.746923</td>\n",
       "      <td>0.604714</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>15355458.00</td>\n",
       "      <td>2.037796e+07</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714094</th>\n",
       "      <td>1</td>\n",
       "      <td>433</td>\n",
       "      <td>210</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999463</td>\n",
       "      <td>3955523.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.350248</td>\n",
       "      <td>23836</td>\n",
       "      <td>433_210_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500689</td>\n",
       "      <td>0.591555</td>\n",
       "      <td>0.044091</td>\n",
       "      <td>3955523.25</td>\n",
       "      <td>3.955523e+06</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4714095 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0               0        0                  0    3.180603e+06   \n",
       "1               1        0                  0    1.666039e+05   \n",
       "2               2        0                  0    3.028799e+05   \n",
       "3               3        0                  0    1.191768e+07   \n",
       "4               4        0                  0    4.475500e+05   \n",
       "...           ...      ...                ...             ...   \n",
       "4714090       197      433                200    1.025122e+07   \n",
       "4714091       198      433                200    2.284637e+07   \n",
       "4714092       199      433                200    7.199116e+06   \n",
       "4714093         0      433                210    5.022506e+06   \n",
       "4714094         1      433                210    0.000000e+00   \n",
       "\n",
       "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                              1         0.999812   13380277.00        NaN   \n",
       "1                             -1         0.999896    1642214.25        NaN   \n",
       "2                             -1         0.999561    1819368.00        NaN   \n",
       "3                             -1         1.000171   18389746.00        NaN   \n",
       "4                             -1         0.999532   17860614.00        NaN   \n",
       "...                          ...              ...           ...        ...   \n",
       "4714090                       -1         1.001338    5150943.00        NaN   \n",
       "4714091                       -1         1.000486   91819888.00        NaN   \n",
       "4714092                       -1         0.998956    8853477.00        NaN   \n",
       "4714093                       -1         0.998591   15355458.00        NaN   \n",
       "4714094                        0         0.999463    3955523.25        NaN   \n",
       "\n",
       "         near_price  bid_price  ...     target  time_id       row_id  \\\n",
       "0               NaN   0.999812  ...  -3.029704        0        0_0_0   \n",
       "1               NaN   0.999896  ...  -5.519986        0        0_0_1   \n",
       "2               NaN   0.999403  ...  -8.389950        0        0_0_2   \n",
       "3               NaN   0.999999  ...  -4.010201        0        0_0_3   \n",
       "4               NaN   0.999394  ...  -7.349849        0        0_0_4   \n",
       "...             ...        ...  ...        ...      ...          ...   \n",
       "4714090         NaN   1.001338  ...  -6.719828    23835  433_200_197   \n",
       "4714091         NaN   1.000486  ...   4.969835    23835  433_200_198   \n",
       "4714092         NaN   0.998956  ...  15.560389    23835  433_200_199   \n",
       "4714093         NaN   0.998591  ...   2.729893    23836    433_210_0   \n",
       "4714094         NaN   0.999054  ... -13.350248    23836    433_210_1   \n",
       "\n",
       "         scale_imbalance_size  scale_matched_size  scale_bid_size  \\\n",
       "0                    1.678769            0.650845        3.240762   \n",
       "1                    1.132052            0.623041        0.257151   \n",
       "2                    1.150879            0.501647        3.119786   \n",
       "3                    2.222158            0.307411        0.115296   \n",
       "4                    0.227054            0.799698        0.992451   \n",
       "...                       ...                 ...             ...   \n",
       "4714090             12.831796            0.517210        2.275128   \n",
       "4714091              2.954231            1.067103        0.466223   \n",
       "4714092              5.571772            0.554376        0.560998   \n",
       "4714093              2.650952            0.746923        0.604714   \n",
       "4714094              0.000000            1.500689        0.591555   \n",
       "\n",
       "        scale_ask_size  auc_bid_size  auc_ask_size  weight  \n",
       "0             0.411688   16560880.00  1.338028e+07   0.004  \n",
       "1             1.546081    1642214.25  1.808818e+06   0.001  \n",
       "2             1.441319    1819368.00  2.122248e+06   0.002  \n",
       "3            22.696073   18389746.00  3.030743e+07   0.006  \n",
       "4             0.025825   17860614.00  1.830816e+07   0.004  \n",
       "...                ...           ...           ...     ...  \n",
       "4714090       0.971532    5150943.00  1.540217e+07   0.004  \n",
       "4714091       0.716778   91819888.00  1.146663e+08   0.006  \n",
       "4714092       1.600156    8853477.00  1.605259e+07   0.004  \n",
       "4714093       0.897864   15355458.00  2.037796e+07   0.004  \n",
       "4714094       0.044091    3955523.25  3.955523e+06   0.001  \n",
       "\n",
       "[4714095 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6d8ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T17:57:56.097478Z",
     "start_time": "2023-12-19T17:57:56.075479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['date_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1603bf6a-5c9b-4903-975f-59541acb80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_no_hist_polars(df):\n",
    "    # 加一个ask_size - bid_size的特征 然后Rolling\n",
    "    df = pl.from_pandas(df)\n",
    "    feas_list = ['stock_id','seconds_in_bucket','imbalance_size','imbalance_buy_sell_flag',\n",
    "               'reference_price','matched_size','far_price','near_price','bid_price','bid_size',\n",
    "                'ask_price','ask_size','wap','scale_imbalance_size','scale_matched_size','scale_bid_size','scale_ask_size'\n",
    "                 ,'auc_bid_size','auc_ask_size']\n",
    "    # 基础特征\n",
    "    df = df.with_columns([\n",
    "        # 阶段1\n",
    "        (pl.col('ask_size') * pl.col('ask_price')).alias(\"ask_money\"),\n",
    "        (pl.col('bid_size') * pl.col('bid_price')).alias(\"bid_money\"),\n",
    "        (pl.col('ask_size') + pl.col(\"auc_ask_size\")).alias(\"ask_size_all\"),\n",
    "        (pl.col('bid_size') + pl.col(\"auc_bid_size\")).alias(\"bid_size_all\"),\n",
    "        (pl.col('ask_size') + pl.col(\"auc_ask_size\") + pl.col('bid_size') + pl.col(\"auc_bid_size\")).alias(\"volumn_size_all\"),\n",
    "        (pl.col('reference_price') * pl.col('auc_ask_size')).alias(\"ask_auc_money\"),\n",
    "        (pl.col('reference_price') * pl.col('auc_bid_size')).alias(\"bid_auc_money\"),\n",
    "        (pl.col('ask_size') * pl.col('ask_price') + pl.col('bid_size') * pl.col('bid_price')).alias(\"volumn_money\"),\n",
    "        (pl.col('ask_size') + pl.col('bid_size')).alias('volume_cont'),\n",
    "        (pl.col('ask_size') - pl.col('bid_size')).alias('diff_ask_bid_size'),\n",
    "        (pl.col('imbalance_size') + 2 * pl.col('matched_size')).alias('volumn_auc'),\n",
    "        ((pl.col('imbalance_size') + 2 * pl.col('matched_size')) * pl.col(\"reference_price\")).alias('volumn_auc_money'),\n",
    "        ((pl.col('ask_price') + pl.col('bid_price'))/2).alias('mid_price'),\n",
    "        ((pl.col('near_price') + pl.col('far_price'))/2).alias('mid_price_near_far'),\n",
    "        (pl.col('ask_price') - pl.col('bid_price')).alias('price_diff_ask_bid'),\n",
    "        (pl.col('ask_price') / pl.col('bid_price')).alias('price_div_ask_bid'),\n",
    "        (pl.col('imbalance_buy_sell_flag') * pl.col('scale_imbalance_size')).alias('flag_scale_imbalance_size'),\n",
    "        (pl.col('imbalance_buy_sell_flag') * pl.col('imbalance_size')).alias('flag_imbalance_size'),\n",
    "        (pl.col('imbalance_size') / pl.col('matched_size') * pl.col('imbalance_buy_sell_flag')).alias(\"div_flag_imbalance_size_2_balance\"),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * pl.col('imbalance_size')).alias('price_pressure'),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * pl.col('imbalance_size') * pl.col('imbalance_buy_sell_flag')).alias('price_pressure_v2'),\n",
    "        ((pl.col(\"ask_size\") - pl.col(\"bid_size\")) / (pl.col(\"far_price\") - pl.col(\"near_price\"))).alias(\"depth_pressure\"),\n",
    "        (pl.col(\"bid_size\") / pl.col(\"ask_size\")).alias(\"div_bid_size_ask_size\"),\n",
    "    ])\n",
    "    feas_list.extend(['ask_money', 'bid_money', 'ask_auc_money','bid_auc_money',\"ask_size_all\",\"bid_size_all\",\"volumn_size_all\",\n",
    "                      'volumn_money','volume_cont',\"volumn_auc\",\"volumn_auc_money\",\"mid_price\",\n",
    "                      'mid_price_near_far','price_diff_ask_bid',\"price_div_ask_bid\",\"flag_imbalance_size\",\"div_flag_imbalance_size_2_balance\",\n",
    "                     \"price_pressure\",\"price_pressure_v2\",\"depth_pressure\",\"flag_scale_imbalance_size\",\"diff_ask_bid_size\"])        \n",
    "\n",
    "    # 各种ratio\n",
    "    # 提升微忽几微\n",
    "    add_cols = []\n",
    "    for col1, col2 in [\n",
    "        (\"imbalance_size\",\"bid_size\"),\n",
    "        (\"imbalance_size\",\"ask_size\"),\n",
    "        (\"matched_size\",\"bid_size\"),\n",
    "        (\"matched_size\",\"ask_size\"),\n",
    "        (\"imbalance_size\",\"volume_cont\"),\n",
    "        (\"matched_size\",\"volume_cont\"),\n",
    "        (\"auc_bid_size\",\"bid_size\"),\n",
    "        (\"auc_ask_size\",\"ask_size\"),\n",
    "        (\"bid_auc_money\",\"bid_money\"),\n",
    "        (\"ask_auc_money\",\"ask_money\"),\n",
    "    ]:\n",
    "        add_cols.append((pl.col(col1) / pl.col(col2)).alias(f\"div_{col1}_2_{col2}\"))\n",
    "        feas_list.append(f\"div_{col1}_2_{col2}\")        \n",
    "    df = df.with_columns(add_cols)\n",
    "\n",
    "    # 阶段2 不平衡特征\n",
    "    # 除了price相关\n",
    "    # 没加auc的ask/bid的 构造price以及不平衡进去\n",
    "    add_cols = []\n",
    "    for pair1,pair2 in [\n",
    "        ('ask_size','bid_size'),\n",
    "        ('ask_money','bid_money'),\n",
    "        ('volumn_money','volumn_auc_money'),\n",
    "        ('volume_cont','volumn_auc'),\n",
    "        ('imbalance_size','matched_size'),\n",
    "        ('auc_ask_size','auc_bid_size'),\n",
    "        (\"ask_size_all\",'bid_size_all')\n",
    "    ]:\n",
    "        col_imb = f\"imb1_{pair1}_{pair2}\"\n",
    "        add_cols.extend([\n",
    "            ((pl.col(pair1) - pl.col(pair2)) / (pl.col(pair1) + pl.col(pair2))).alias(col_imb),\n",
    "        ])\n",
    "        feas_list.extend([col_imb])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    # price侧的imb1\n",
    "    fea_append_list = []\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\",\"mid_price\"]\n",
    "    for c in combinations(prices, 2):\n",
    "        fea_append_list.append(((pl.col(c[0]) - pl.col(c[1])) / (pl.col(c[0]) + pl.col(c[1]))).alias(f\"imb1_{c[0]}_{c[1]}\"))\n",
    "        # fea_append_list.append((pl.col(c[0]) - pl.col(c[1])).alias(f\"diff_{c[0]}_{c[1]}\"))\n",
    "        feas_list.extend([f\"imb1_{c[0]}_{c[1]}\"])\n",
    "    df = df.with_columns(fea_append_list)\n",
    "    \n",
    "    \n",
    "    # 不平衡特征 累计乘\n",
    "    df = df.with_columns([\n",
    "        ((pl.col(\"imb1_ask_size_bid_size\") + 2) * (pl.col(\"imb1_ask_price_bid_price\") + 2) * (pl.col(\"imb1_auc_ask_size_auc_bid_size\")+2)).alias(\"market_urgency_v2\"),\n",
    "        (pl.col('price_diff_ask_bid') * (pl.col('imb1_ask_size_bid_size'))).alias('market_urgency'),\n",
    "        (pl.col('imb1_ask_price_bid_price') * (pl.col('imb1_ask_size_bid_size'))).alias('market_urgency_v3'),\n",
    "    ])\n",
    "    feas_list.extend([f\"market_urgency_v3\",'market_urgency','market_urgency_v2'])\n",
    "    \n",
    "    feas_list = ['imb1_wap_mid_price', 'imb1_ask_money_bid_money', 'imb1_volume_cont_volumn_auc', 'imb1_reference_price_ask_price', \n",
    "                 'imb1_reference_price_mid_price', 'seconds_in_bucket', 'div_flag_imbalance_size_2_balance', 'ask_price', \n",
    "                 'imb1_reference_price_bid_price', 'scale_matched_size', 'imb1_near_price_wap', 'volumn_auc_money', 'imb1_far_price_wap', \n",
    "                 'bid_size', 'scale_bid_size', 'bid_size_all']\n",
    "    # 隔离\n",
    "    add_cols = []\n",
    "    for col in [\"bid_auc_money\",\"imb1_reference_price_wap\",\"bid_size_all\",\n",
    "                \"imb1_auc_ask_size_auc_bid_size\",\"div_flag_imbalance_size_2_balance\",\n",
    "                \"imb1_ask_size_all_bid_size_all\",\"flag_imbalance_size\",\"imb1_reference_price_mid_price\"]:\n",
    "        for window in [3,6,18,36,60]:\n",
    "            add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
    "            add_cols.append(pl.col(col).rolling_std(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_std_{col}'))\n",
    "            feas_list.extend([f'rolling{window}_mean_{col}',f'rolling{window}_std_{col}'])\n",
    "    feas_list = ['imb1_wap_mid_price', 'imb1_ask_money_bid_money', 'imb1_volume_cont_volumn_auc', \n",
    "                     'imb1_reference_price_ask_price', 'imb1_reference_price_mid_price', \n",
    "                     'seconds_in_bucket', 'div_flag_imbalance_size_2_balance', 'ask_price', \n",
    "                     'imb1_reference_price_bid_price', 'scale_matched_size', 'imb1_near_price_wap', \n",
    "                     'volumn_auc_money', 'imb1_far_price_wap', 'bid_size', 'scale_bid_size', 'bid_size_all', \n",
    "                     'rolling18_mean_imb1_auc_ask_size_auc_bid_size', 'rolling3_mean_div_flag_imbalance_size_2_balance', \n",
    "                     'rolling60_std_div_flag_imbalance_size_2_balance', 'rolling36_mean_flag_imbalance_size', \n",
    "                     'rolling3_std_imb1_auc_ask_size_auc_bid_size', 'rolling18_mean_imb1_ask_size_all_bid_size_all', \n",
    "                     'rolling6_mean_div_flag_imbalance_size_2_balance', 'rolling6_std_imb1_auc_ask_size_auc_bid_size', \n",
    "                     'rolling3_mean_imb1_auc_ask_size_auc_bid_size', 'rolling60_std_imb1_auc_ask_size_auc_bid_size', \n",
    "                     'rolling6_std_bid_size_all', 'rolling3_std_bid_size_all', 'rolling3_mean_bid_size_all', \n",
    "                     'rolling18_std_bid_auc_money', 'rolling36_mean_bid_auc_money',\"rolling60_mean_imb1_reference_price_wap\",\n",
    "                    'rolling18_mean_imb1_reference_price_wap', 'rolling3_mean_imb1_reference_price_mid_price']\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "#     for col in [\"flag_imbalance_size\",\"imb1_reference_price_wap\",\"imb1_reference_price_mid_price\",\"mid_price\",\"imb1_far_price_wap\",\n",
    "#                'matched_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "#         add_cols = []\n",
    "#         for window_size in [1,2,4,6,12]:\n",
    "#             add_cols.append(pl.col(col).shift(window_size).over('stock_id','date_id').alias(f'shift{window_size}_{col}'))\n",
    "#             add_cols.append((pl.col(col) / pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'div_shift{window_size}_{col}'))\n",
    "#             add_cols.append((pl.col(col) - pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'diff_shift{window_size}_{col}'))\n",
    "#             feas_list.extend([f'shift{window_size}_{col}',f'div_shift{window_size}_{col}',f'diff_shift{window_size}_{col}'])\n",
    "#         df = df.with_columns(add_cols)\n",
    "    ### 杂七杂八\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"flag_imbalance_size\").diff().over('stock_id','date_id').alias(\"imbalance_momentum_unscaled\"),\n",
    "        pl.col(\"price_diff_ask_bid\").diff().over('stock_id','date_id').alias(\"spread_intensity\"),\n",
    "    ])\n",
    "    feas_list.extend([\"imbalance_momentum_unscaled\",\"spread_intensity\"])\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"imbalance_momentum_unscaled\")/pl.col(\"matched_size\")).alias(\"imbalance_momentum\")\n",
    "    ])\n",
    "    feas_list.extend([\"imbalance_momentum\"])\n",
    "\n",
    "    #Calculate diff features for specific columns\n",
    "    add_cols = []\n",
    "    for col in ['ask_price',\n",
    " 'bid_price',\n",
    " 'imb1_reference_price_near_price',\n",
    " 'bid_size',\n",
    " 'scale_bid_size',\n",
    " 'mid_price',\n",
    " 'ask_size',\n",
    " 'price_div_ask_bid',\n",
    " 'div_bid_size_ask_size',\n",
    " 'market_urgency',\n",
    " 'wap',\n",
    " 'imbalance_momentum']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            add_cols.append((pl.col(col).diff(window).over('stock_id','date_id')).alias(f\"{col}_diff_{window}\"))\n",
    "            feas_list.append(f\"{col}_diff_{window}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    ### target mock系列\n",
    "    for mock_period in [1,3,12,6]:\n",
    "    \n",
    "        df = df.with_columns([\n",
    "            pl.col(\"wap\").shift(-mock_period).over(\"stock_id\",\"date_id\").alias(f\"wap_shift_n{mock_period}\")\n",
    "        ])\n",
    "        df = df.with_columns([\n",
    "            (pl.col(f\"wap_shift_n{mock_period}\")/pl.col(\"wap\")).alias(\"target_single\")\n",
    "        ])\n",
    "\n",
    "        tmp_df = df.select(pl.col(\"target_single\"),pl.col(\"weight\")).to_pandas()\n",
    "        tmp_df.loc[tmp_df[\"target_single\"].isna(),\"weight\"] = 0\n",
    "        df = df.with_columns([\n",
    "            pl.lit(np.array(tmp_df[\"weight\"])).alias(\"weight_tmp\")\n",
    "        ])\n",
    "\n",
    "        df = df.with_columns([\n",
    "            (((pl.col(\"weight_tmp\") * pl.col(\"target_single\")).sum().over(\"date_id\",\"seconds_in_bucket\")) / ((pl.col(\"weight_tmp\")).sum().over(\"date_id\",\"seconds_in_bucket\"))).alias(\"index_target_mock\")\n",
    "        ])\n",
    "\n",
    "        df = df.with_columns([\n",
    "            ((pl.col(\"target_single\") - pl.col(\"index_target_mock\"))*10000).alias(\"target_mock\")\n",
    "        ])\n",
    "\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"target_mock\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"target_mock_shift{mock_period}\"),\n",
    "            #pl.col(\"index_target_mock\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"index_target_mock_shift{mock_period}\"),\n",
    "            #pl.col(\"target_single\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"target_single_shift{mock_period}\")\n",
    "        ])\n",
    "    # df.drop_in_place(\"wap_shift_6\")\n",
    "    # df.drop_in_place(\"target_single_shift6\")\n",
    "    # df.drop_in_place(\"indexwap_shift6\")\n",
    "    # add_cols_new = []\n",
    "    add_cols = []\n",
    "    for col in ['target_mock_shift6','target_mock_shift1','target_mock_shift3','target_mock_shift12']:\n",
    "        for window in [1, 3,6,12,24,48]:\n",
    "            add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
    "            #add_cols.append(pl.col(col).rolling_std(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_std_{col}'))\n",
    "            # add_cols_new.extend([f'rolling{window}_mean_{col}'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    keep_cols_new = ['rolling48_mean_target_mock_shift3', 'rolling48_mean_target_mock_shift1', 'rolling48_mean_target_mock_shift12',\n",
    "'rolling1_mean_target_mock_shift6', 'rolling24_mean_target_mock_shift6','rolling24_mean_target_mock_shift12',]\n",
    "    feas_list.extend(keep_cols_new)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in [\"imb1_auc_ask_size_auc_bid_size\",\"flag_imbalance_size\",\"price_pressure_v2\",\"scale_matched_size\"]:\n",
    "        for window_size in [1,2,3,6,12]:\n",
    "            add_cols.append(pl.col(col).shift(window_size).over('stock_id','date_id').alias(f'shift{window_size}_{col}'))\n",
    "            add_cols.append((pl.col(col) / pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'div_shift{window_size}_{col}'))\n",
    "            add_cols.append((pl.col(col) - pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'diff_shift{window_size}_{col}'))\n",
    "            #feas_list.extend([f'shift{window_size}_{col}',f'div_shift{window_size}_{col}',f'diff_shift{window_size}_{col}'])\n",
    "    feas_list.extend(['div_shift6_imb1_auc_ask_size_auc_bid_size',\n",
    " 'diff_shift6_price_pressure_v2',\n",
    " 'shift1_price_pressure_v2',\n",
    " 'div_shift3_flag_imbalance_size',\n",
    " 'div_shift12_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift3_scale_matched_size',\n",
    " 'diff_shift6_flag_imbalance_size',\n",
    " 'shift12_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift12_price_pressure_v2',\n",
    " 'shift6_flag_imbalance_size',\n",
    " 'diff_shift3_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift12_flag_imbalance_size',\n",
    " 'shift12_flag_imbalance_size'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in ['imb1_ask_price_mid_price',\n",
    " 'market_urgency',\n",
    " 'market_urgency_diff_1',\n",
    " 'imb1_ask_money_bid_money',\n",
    " 'rolling18_mean_imb1_ask_size_all_bid_size_all',\n",
    " 'rolling18_mean_imb1_auc_ask_size_auc_bid_size',\n",
    " 'rolling18_mean_imb1_reference_price_wap',\n",
    " 'ask_price_diff_3',\n",
    " 'diff_shift1_price_pressure_v2',\n",
    " 'diff_shift12_scale_matched_size',\n",
    " 'diff_shift1_flag_imbalance_size',\n",
    " 'imb1_ask_size_bid_size',\n",
    " 'imb1_bid_price_mid_price',\n",
    " 'rolling48_mean_target_mock_shift6']:\n",
    "        add_cols.append((((pl.col(col) * pl.col(\"weight\")).sum().over(\"date_id\",\"seconds_in_bucket\"))/(((pl.col(\"weight\")).sum().over(\"date_id\",\"seconds_in_bucket\")))).alias(f\"global_{col}\"))\n",
    "        feas_list.append(f\"global_{col}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    \n",
    "    # MACD\n",
    "    rsi_cols = [\"mid_price_near_far\",\"imb1_reference_price_wap\",\"near_price\",]\n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for window_size in [3,6,12,24,48]:\n",
    "            add_cols.append(pl.col(col).ewm_mean(span=window_size, adjust=False).over('stock_id','date_id').alias(f\"rolling_ewm_{window_size}_{col}\"))\n",
    "            #feas_list.append(f\"rolling_ewm_{window_size}_{col}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            add_cols.append((pl.col(f\"rolling_ewm_{w1}_{col}\") - pl.col(f\"rolling_ewm_{w2}_{col}\")).alias(f\"dif_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"dif_{col}_{w1}_{w2}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            add_cols.append(pl.col(f\"dif_{col}_{w1}_{w2}\").ewm_mean(span=9, adjust=False).over('stock_id','date_id').alias(f\"dea_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"dea_{col}_{w1}_{w2}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            add_cols.append((pl.col(f\"dif_{col}_{w1}_{w2}\") - pl.col(f\"dea_{col}_{w1}_{w2}\")).alias(f\"macd_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"macd_{col}_{w1}_{w2}\")\n",
    "    \n",
    "    feas_list.extend(['macd_imb1_reference_price_wap_12_24',\n",
    " 'dif_imb1_reference_price_wap_3_6',\n",
    " 'macd_mid_price_near_far_12_24',\n",
    " 'dif_near_price_3_6',\n",
    " 'macd_near_price_24_48',\n",
    " 'dea_imb1_reference_price_wap_12_24',\n",
    " 'macd_near_price_12_24',\n",
    " 'rolling_ewm_24_imb1_reference_price_wap',\n",
    " 'dif_near_price_6_12',\n",
    " 'dea_mid_price_near_far_6_12',\n",
    " 'dea_near_price_24_48',\n",
    " 'rolling_ewm_12_imb1_reference_price_wap',\n",
    " 'dif_imb1_reference_price_wap_12_24'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in [\"target\"]:\n",
    "        # 176 1,2,3,5,10,15,20,25,30\n",
    "        # [1,2,3,5,10,15,20,25,30,35,40,45,60] 5.8704926 157\n",
    "        # [1,2,3,5,10,15,20,30,45,60] 5.8708683137\n",
    "        for window_size in [1,2,3,5,10,15,20,25,30,35,40,45,60]:\n",
    "            add_cols.append(pl.col(col).shift(1).rolling_mean(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_mean_{window_size}_{col}_second'))\n",
    "            add_cols.append(pl.col(col).shift(1).rolling_std(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_std_{window_size}_{col}_second'))\n",
    "\n",
    "            \n",
    "            feas_list.extend([f'rolling_mean_{window_size}_{col}_second',f'rolling_std_{window_size}_{col}_second',])\n",
    "\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    \n",
    "    return df.to_pandas(), feas_list\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ff4f1c-d3d7-4a6f-b52a-0db599e956a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/.tsangsyf/ipykernel_2606370/3087588357.py:255: DeprecationWarning: The default value for `ignore_nulls` for `ewm` methods will change from True to False in the next breaking release. Explicitly set `ignore_nulls=True` to keep the existing behavior and silence this warning.\n",
      "  add_cols.append(pl.col(col).ewm_mean(span=window_size, adjust=False).over('stock_id','date_id').alias(f\"rolling_ewm_{window_size}_{col}\"))\n",
      "/tmp/.tsangsyf/ipykernel_2606370/3087588357.py:269: DeprecationWarning: The default value for `ignore_nulls` for `ewm` methods will change from True to False in the next breaking release. Explicitly set `ignore_nulls=True` to keep the existing behavior and silence this warning.\n",
      "  add_cols.append(pl.col(f\"dif_{col}_{w1}_{w2}\").ewm_mean(span=9, adjust=False).over('stock_id','date_id').alias(f\"dea_{col}_{w1}_{w2}\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4236893, 157)\n"
     ]
    }
   ],
   "source": [
    "train_feas_all, feas_list = generate_features_no_hist_polars(train)\n",
    "valid_feas = train_feas_all[train_feas_all['date_id'] >= 390]\n",
    "train_feas = train_feas_all[train_feas_all['date_id'] < 390]\n",
    "# train_feas = train_feas[train_feas['fold']==0]\n",
    "print(train_feas[feas_list].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc1eb8-18e2-458e-8159-e28a889fbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feas = train_feas.fillna(-9e10)\n",
    "valid_feas = valid_feas.fillna(-9e10)\n",
    "from tqdm.auto import tqdm\n",
    "for _ in tqdm(feas_list):\n",
    "    train_feas[_] = train_feas[_].clip(lower=-9e9,upper=9e9)\n",
    "    valid_feas[_] = valid_feas[_].clip(lower=-9e9,upper=9e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b83db-bcf4-428d-a16c-f33ff5a461f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfec20-3dd0-41ee-a3f4-7f9dad7fe672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'random_state': 47,\n",
    "    'learning_rate':0.01,\n",
    "    'n_estimators':10000,\n",
    "    'n_jobs':-1,\n",
    "    'objective':'reg:absoluteerror',\n",
    "    \"device\": \"gpu\",\n",
    "    'max_depth': 10,\n",
    "     'min_child_weight': 8.860379669551103,\n",
    "     'subsample': 0.7711820080525443,\n",
    "     'colsample_bytree': 0.5348780216605801,\n",
    "     'reg_alpha': 0.12854342791716195,\n",
    "     'reg_lambda': 0.39326076062073634,\n",
    "     'gamma': 0.24378704040107024\n",
    "}\n",
    "\n",
    "clf = xgb.XGBRegressor(**params)\n",
    "clf.fit(train_feas[feas_list],train_feas['target'],\n",
    "        eval_set = [(train_feas[feas_list],train_feas['target']),(valid_feas[feas_list],valid_feas['target'])]\n",
    "        ,early_stopping_rounds=200,verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9be27-f431-420f-b36f-f6e932072aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1aaca1-c754-498c-a746-689d868627ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae201acb-d615-46db-b723-dcecdf9ea33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model(\"../save/xgboost_157.pkl\")\n",
    "pred_cat = clf.predict(valid_feas[feas_list])\n",
    "valid_feas[\"pred\"] = pred_cat\n",
    "valid_feas[['stock_id','date_id','seconds_in_bucket','target','pred']].to_pickle(\"../save/xgboost_157_oof.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d12780-e128-41ac-a035-71a0ec451503",
   "metadata": {},
   "source": [
    "## full data 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc00d6-cc4e-4ddc-b4e1-bd14367ca1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "pl.__version__\n",
    "train = pd.read_pickle(\"../raw_data/train.pkl\")\n",
    "train = train[~train['target'].isna()]\n",
    "print(train.shape)\n",
    "\n",
    "size_col = ['imbalance_size','matched_size','bid_size','ask_size']\n",
    "for _ in size_col:\n",
    "    train[f\"scale_{_}\"] = train[_] / train.groupby(['stock_id'])[_].transform('median')\n",
    "    \n",
    "#buy-side imbalance; 1\n",
    "#sell-side imbalance; -1\n",
    "#no imbalance; 0\n",
    "train['auc_bid_size'] = train['matched_size']\n",
    "train['auc_ask_size'] = train['matched_size']\n",
    "train.loc[train['imbalance_buy_sell_flag']==1,'auc_bid_size'] += train.loc[train['imbalance_buy_sell_flag']==1,'imbalance_size']\n",
    "train.loc[train['imbalance_buy_sell_flag']==-1,'auc_ask_size'] += train.loc[train['imbalance_buy_sell_flag']==-1,'imbalance_size']\n",
    "\n",
    "\n",
    "weight_df = pd.DataFrame()\n",
    "weight_df['stock_id'] = list(range(200))\n",
    "weight_df['weight'] =  [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "train = train.merge(weight_df,how='left',on=['stock_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32ebe3-457f-4bb3-bab3-a2784c37d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_no_hist_polars(df):\n",
    "    # 加一个ask_size - bid_size的特征 然后Rolling\n",
    "    df = pl.from_pandas(df)\n",
    "    feas_list = ['stock_id','seconds_in_bucket','imbalance_size','imbalance_buy_sell_flag',\n",
    "               'reference_price','matched_size','far_price','near_price','bid_price','bid_size',\n",
    "                'ask_price','ask_size','wap','scale_imbalance_size','scale_matched_size','scale_bid_size','scale_ask_size'\n",
    "                 ,'auc_bid_size','auc_ask_size']\n",
    "    # 基础特征\n",
    "    df = df.with_columns([\n",
    "        # 阶段1\n",
    "        (pl.col('ask_size') * pl.col('ask_price')).alias(\"ask_money\"),\n",
    "        (pl.col('bid_size') * pl.col('bid_price')).alias(\"bid_money\"),\n",
    "        (pl.col('ask_size') + pl.col(\"auc_ask_size\")).alias(\"ask_size_all\"),\n",
    "        (pl.col('bid_size') + pl.col(\"auc_bid_size\")).alias(\"bid_size_all\"),\n",
    "        (pl.col('ask_size') + pl.col(\"auc_ask_size\") + pl.col('bid_size') + pl.col(\"auc_bid_size\")).alias(\"volumn_size_all\"),\n",
    "        (pl.col('reference_price') * pl.col('auc_ask_size')).alias(\"ask_auc_money\"),\n",
    "        (pl.col('reference_price') * pl.col('auc_bid_size')).alias(\"bid_auc_money\"),\n",
    "        (pl.col('ask_size') * pl.col('ask_price') + pl.col('bid_size') * pl.col('bid_price')).alias(\"volumn_money\"),\n",
    "        (pl.col('ask_size') + pl.col('bid_size')).alias('volume_cont'),\n",
    "        (pl.col('ask_size') - pl.col('bid_size')).alias('diff_ask_bid_size'),\n",
    "        (pl.col('imbalance_size') + 2 * pl.col('matched_size')).alias('volumn_auc'),\n",
    "        ((pl.col('imbalance_size') + 2 * pl.col('matched_size')) * pl.col(\"reference_price\")).alias('volumn_auc_money'),\n",
    "        ((pl.col('ask_price') + pl.col('bid_price'))/2).alias('mid_price'),\n",
    "        ((pl.col('near_price') + pl.col('far_price'))/2).alias('mid_price_near_far'),\n",
    "        (pl.col('ask_price') - pl.col('bid_price')).alias('price_diff_ask_bid'),\n",
    "        (pl.col('ask_price') / pl.col('bid_price')).alias('price_div_ask_bid'),\n",
    "        (pl.col('imbalance_buy_sell_flag') * pl.col('scale_imbalance_size')).alias('flag_scale_imbalance_size'),\n",
    "        (pl.col('imbalance_buy_sell_flag') * pl.col('imbalance_size')).alias('flag_imbalance_size'),\n",
    "        (pl.col('imbalance_size') / pl.col('matched_size') * pl.col('imbalance_buy_sell_flag')).alias(\"div_flag_imbalance_size_2_balance\"),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * pl.col('imbalance_size')).alias('price_pressure'),\n",
    "        ((pl.col('ask_price') - pl.col('bid_price')) * pl.col('imbalance_size') * pl.col('imbalance_buy_sell_flag')).alias('price_pressure_v2'),\n",
    "        ((pl.col(\"ask_size\") - pl.col(\"bid_size\")) / (pl.col(\"far_price\") - pl.col(\"near_price\"))).alias(\"depth_pressure\"),\n",
    "        (pl.col(\"bid_size\") / pl.col(\"ask_size\")).alias(\"div_bid_size_ask_size\"),\n",
    "    ])\n",
    "    feas_list.extend(['ask_money', 'bid_money', 'ask_auc_money','bid_auc_money',\"ask_size_all\",\"bid_size_all\",\"volumn_size_all\",\n",
    "                      'volumn_money','volume_cont',\"volumn_auc\",\"volumn_auc_money\",\"mid_price\",\n",
    "                      'mid_price_near_far','price_diff_ask_bid',\"price_div_ask_bid\",\"flag_imbalance_size\",\"div_flag_imbalance_size_2_balance\",\n",
    "                     \"price_pressure\",\"price_pressure_v2\",\"depth_pressure\",\"flag_scale_imbalance_size\",\"diff_ask_bid_size\"])        \n",
    "\n",
    "    # 各种ratio\n",
    "    # 提升微忽几微\n",
    "    add_cols = []\n",
    "    for col1, col2 in [\n",
    "        (\"imbalance_size\",\"bid_size\"),\n",
    "        (\"imbalance_size\",\"ask_size\"),\n",
    "        (\"matched_size\",\"bid_size\"),\n",
    "        (\"matched_size\",\"ask_size\"),\n",
    "        (\"imbalance_size\",\"volume_cont\"),\n",
    "        (\"matched_size\",\"volume_cont\"),\n",
    "        (\"auc_bid_size\",\"bid_size\"),\n",
    "        (\"auc_ask_size\",\"ask_size\"),\n",
    "        (\"bid_auc_money\",\"bid_money\"),\n",
    "        (\"ask_auc_money\",\"ask_money\"),\n",
    "    ]:\n",
    "        add_cols.append((pl.col(col1) / pl.col(col2)).alias(f\"div_{col1}_2_{col2}\"))\n",
    "        feas_list.append(f\"div_{col1}_2_{col2}\")        \n",
    "    df = df.with_columns(add_cols)\n",
    "\n",
    "    # 阶段2 不平衡特征\n",
    "    # 除了price相关\n",
    "    # 没加auc的ask/bid的 构造price以及不平衡进去\n",
    "    add_cols = []\n",
    "    for pair1,pair2 in [\n",
    "        ('ask_size','bid_size'),\n",
    "        ('ask_money','bid_money'),\n",
    "        ('volumn_money','volumn_auc_money'),\n",
    "        ('volume_cont','volumn_auc'),\n",
    "        ('imbalance_size','matched_size'),\n",
    "        ('auc_ask_size','auc_bid_size'),\n",
    "        (\"ask_size_all\",'bid_size_all')\n",
    "    ]:\n",
    "        col_imb = f\"imb1_{pair1}_{pair2}\"\n",
    "        add_cols.extend([\n",
    "            ((pl.col(pair1) - pl.col(pair2)) / (pl.col(pair1) + pl.col(pair2))).alias(col_imb),\n",
    "        ])\n",
    "        feas_list.extend([col_imb])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    # price侧的imb1\n",
    "    fea_append_list = []\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\",\"mid_price\"]\n",
    "    for c in combinations(prices, 2):\n",
    "        fea_append_list.append(((pl.col(c[0]) - pl.col(c[1])) / (pl.col(c[0]) + pl.col(c[1]))).alias(f\"imb1_{c[0]}_{c[1]}\"))\n",
    "        # fea_append_list.append((pl.col(c[0]) - pl.col(c[1])).alias(f\"diff_{c[0]}_{c[1]}\"))\n",
    "        feas_list.extend([f\"imb1_{c[0]}_{c[1]}\"])\n",
    "    df = df.with_columns(fea_append_list)\n",
    "    \n",
    "    \n",
    "    # 不平衡特征 累计乘\n",
    "    df = df.with_columns([\n",
    "        ((pl.col(\"imb1_ask_size_bid_size\") + 2) * (pl.col(\"imb1_ask_price_bid_price\") + 2) * (pl.col(\"imb1_auc_ask_size_auc_bid_size\")+2)).alias(\"market_urgency_v2\"),\n",
    "        (pl.col('price_diff_ask_bid') * (pl.col('imb1_ask_size_bid_size'))).alias('market_urgency'),\n",
    "        (pl.col('imb1_ask_price_bid_price') * (pl.col('imb1_ask_size_bid_size'))).alias('market_urgency_v3'),\n",
    "    ])\n",
    "    feas_list.extend([f\"market_urgency_v3\",'market_urgency','market_urgency_v2'])\n",
    "    \n",
    "    feas_list = ['imb1_wap_mid_price', 'imb1_ask_money_bid_money', 'imb1_volume_cont_volumn_auc', 'imb1_reference_price_ask_price', \n",
    "                 'imb1_reference_price_mid_price', 'seconds_in_bucket', 'div_flag_imbalance_size_2_balance', 'ask_price', \n",
    "                 'imb1_reference_price_bid_price', 'scale_matched_size', 'imb1_near_price_wap', 'volumn_auc_money', 'imb1_far_price_wap', \n",
    "                 'bid_size', 'scale_bid_size', 'bid_size_all']\n",
    "    # 隔离\n",
    "    add_cols = []\n",
    "    for col in [\"bid_auc_money\",\"imb1_reference_price_wap\",\"bid_size_all\",\n",
    "                \"imb1_auc_ask_size_auc_bid_size\",\"div_flag_imbalance_size_2_balance\",\n",
    "                \"imb1_ask_size_all_bid_size_all\",\"flag_imbalance_size\",\"imb1_reference_price_mid_price\"]:\n",
    "        for window in [3,6,18,36,60]:\n",
    "            add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
    "            add_cols.append(pl.col(col).rolling_std(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_std_{col}'))\n",
    "            feas_list.extend([f'rolling{window}_mean_{col}',f'rolling{window}_std_{col}'])\n",
    "    feas_list = ['imb1_wap_mid_price', 'imb1_ask_money_bid_money', 'imb1_volume_cont_volumn_auc', \n",
    "                     'imb1_reference_price_ask_price', 'imb1_reference_price_mid_price', \n",
    "                     'seconds_in_bucket', 'div_flag_imbalance_size_2_balance', 'ask_price', \n",
    "                     'imb1_reference_price_bid_price', 'scale_matched_size', 'imb1_near_price_wap', \n",
    "                     'volumn_auc_money', 'imb1_far_price_wap', 'bid_size', 'scale_bid_size', 'bid_size_all', \n",
    "                     'rolling18_mean_imb1_auc_ask_size_auc_bid_size', 'rolling3_mean_div_flag_imbalance_size_2_balance', \n",
    "                     'rolling60_std_div_flag_imbalance_size_2_balance', 'rolling36_mean_flag_imbalance_size', \n",
    "                     'rolling3_std_imb1_auc_ask_size_auc_bid_size', 'rolling18_mean_imb1_ask_size_all_bid_size_all', \n",
    "                     'rolling6_mean_div_flag_imbalance_size_2_balance', 'rolling6_std_imb1_auc_ask_size_auc_bid_size', \n",
    "                     'rolling3_mean_imb1_auc_ask_size_auc_bid_size', 'rolling60_std_imb1_auc_ask_size_auc_bid_size', \n",
    "                     'rolling6_std_bid_size_all', 'rolling3_std_bid_size_all', 'rolling3_mean_bid_size_all', \n",
    "                     'rolling18_std_bid_auc_money', 'rolling36_mean_bid_auc_money',\"rolling60_mean_imb1_reference_price_wap\",\n",
    "                    'rolling18_mean_imb1_reference_price_wap', 'rolling3_mean_imb1_reference_price_mid_price']\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "#     for col in [\"flag_imbalance_size\",\"imb1_reference_price_wap\",\"imb1_reference_price_mid_price\",\"mid_price\",\"imb1_far_price_wap\",\n",
    "#                'matched_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "#         add_cols = []\n",
    "#         for window_size in [1,2,4,6,12]:\n",
    "#             add_cols.append(pl.col(col).shift(window_size).over('stock_id','date_id').alias(f'shift{window_size}_{col}'))\n",
    "#             add_cols.append((pl.col(col) / pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'div_shift{window_size}_{col}'))\n",
    "#             add_cols.append((pl.col(col) - pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'diff_shift{window_size}_{col}'))\n",
    "#             feas_list.extend([f'shift{window_size}_{col}',f'div_shift{window_size}_{col}',f'diff_shift{window_size}_{col}'])\n",
    "#         df = df.with_columns(add_cols)\n",
    "    ### 杂七杂八\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"flag_imbalance_size\").diff().over('stock_id','date_id').alias(\"imbalance_momentum_unscaled\"),\n",
    "        pl.col(\"price_diff_ask_bid\").diff().over('stock_id','date_id').alias(\"spread_intensity\"),\n",
    "    ])\n",
    "    feas_list.extend([\"imbalance_momentum_unscaled\",\"spread_intensity\"])\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"imbalance_momentum_unscaled\")/pl.col(\"matched_size\")).alias(\"imbalance_momentum\")\n",
    "    ])\n",
    "    feas_list.extend([\"imbalance_momentum\"])\n",
    "\n",
    "    #Calculate diff features for specific columns\n",
    "    add_cols = []\n",
    "    for col in ['ask_price',\n",
    " 'bid_price',\n",
    " 'imb1_reference_price_near_price',\n",
    " 'bid_size',\n",
    " 'scale_bid_size',\n",
    " 'mid_price',\n",
    " 'ask_size',\n",
    " 'price_div_ask_bid',\n",
    " 'div_bid_size_ask_size',\n",
    " 'market_urgency',\n",
    " 'wap',\n",
    " 'imbalance_momentum']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            add_cols.append((pl.col(col).diff(window).over('stock_id','date_id')).alias(f\"{col}_diff_{window}\"))\n",
    "            feas_list.append(f\"{col}_diff_{window}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    ### target mock系列\n",
    "    for mock_period in [1,3,12,6]:\n",
    "    \n",
    "        df = df.with_columns([\n",
    "            pl.col(\"wap\").shift(-mock_period).over(\"stock_id\",\"date_id\").alias(f\"wap_shift_n{mock_period}\")\n",
    "        ])\n",
    "        df = df.with_columns([\n",
    "            (pl.col(f\"wap_shift_n{mock_period}\")/pl.col(\"wap\")).alias(\"target_single\")\n",
    "        ])\n",
    "\n",
    "        tmp_df = df.select(pl.col(\"target_single\"),pl.col(\"weight\")).to_pandas()\n",
    "        tmp_df.loc[tmp_df[\"target_single\"].isna(),\"weight\"] = 0\n",
    "        df = df.with_columns([\n",
    "            pl.lit(np.array(tmp_df[\"weight\"])).alias(\"weight_tmp\")\n",
    "        ])\n",
    "\n",
    "        df = df.with_columns([\n",
    "            (((pl.col(\"weight_tmp\") * pl.col(\"target_single\")).sum().over(\"date_id\",\"seconds_in_bucket\")) / ((pl.col(\"weight_tmp\")).sum().over(\"date_id\",\"seconds_in_bucket\"))).alias(\"index_target_mock\")\n",
    "        ])\n",
    "\n",
    "        df = df.with_columns([\n",
    "            ((pl.col(\"target_single\") - pl.col(\"index_target_mock\"))*10000).alias(\"target_mock\")\n",
    "        ])\n",
    "\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"target_mock\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"target_mock_shift{mock_period}\"),\n",
    "            #pl.col(\"index_target_mock\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"index_target_mock_shift{mock_period}\"),\n",
    "            #pl.col(\"target_single\").shift(mock_period).over(\"stock_id\",\"date_id\").alias(f\"target_single_shift{mock_period}\")\n",
    "        ])\n",
    "    # df.drop_in_place(\"wap_shift_6\")\n",
    "    # df.drop_in_place(\"target_single_shift6\")\n",
    "    # df.drop_in_place(\"indexwap_shift6\")\n",
    "    # add_cols_new = []\n",
    "    add_cols = []\n",
    "    for col in ['target_mock_shift6','target_mock_shift1','target_mock_shift3','target_mock_shift12']:\n",
    "        for window in [1, 3,6,12,24,48]:\n",
    "            add_cols.append(pl.col(col).rolling_mean(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_mean_{col}'))\n",
    "            #add_cols.append(pl.col(col).rolling_std(window_size=window,min_periods=1).over('stock_id','date_id').alias(f'rolling{window}_std_{col}'))\n",
    "            # add_cols_new.extend([f'rolling{window}_mean_{col}'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    keep_cols_new = ['rolling48_mean_target_mock_shift3', 'rolling48_mean_target_mock_shift1', 'rolling48_mean_target_mock_shift12',\n",
    "'rolling1_mean_target_mock_shift6', 'rolling24_mean_target_mock_shift6','rolling24_mean_target_mock_shift12',]\n",
    "    feas_list.extend(keep_cols_new)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in [\"imb1_auc_ask_size_auc_bid_size\",\"flag_imbalance_size\",\"price_pressure_v2\",\"scale_matched_size\"]:\n",
    "        for window_size in [1,2,3,6,12]:\n",
    "            add_cols.append(pl.col(col).shift(window_size).over('stock_id','date_id').alias(f'shift{window_size}_{col}'))\n",
    "            add_cols.append((pl.col(col) / pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'div_shift{window_size}_{col}'))\n",
    "            add_cols.append((pl.col(col) - pl.col(col).shift(window_size).over('stock_id','date_id')).alias(f'diff_shift{window_size}_{col}'))\n",
    "            #feas_list.extend([f'shift{window_size}_{col}',f'div_shift{window_size}_{col}',f'diff_shift{window_size}_{col}'])\n",
    "    feas_list.extend(['div_shift6_imb1_auc_ask_size_auc_bid_size',\n",
    " 'diff_shift6_price_pressure_v2',\n",
    " 'shift1_price_pressure_v2',\n",
    " 'div_shift3_flag_imbalance_size',\n",
    " 'div_shift12_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift3_scale_matched_size',\n",
    " 'diff_shift6_flag_imbalance_size',\n",
    " 'shift12_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift12_price_pressure_v2',\n",
    " 'shift6_flag_imbalance_size',\n",
    " 'diff_shift3_imb1_auc_ask_size_auc_bid_size',\n",
    " 'div_shift12_flag_imbalance_size',\n",
    " 'shift12_flag_imbalance_size'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in ['imb1_ask_price_mid_price',\n",
    " 'market_urgency',\n",
    " 'market_urgency_diff_1',\n",
    " 'imb1_ask_money_bid_money',\n",
    " 'rolling18_mean_imb1_ask_size_all_bid_size_all',\n",
    " 'rolling18_mean_imb1_auc_ask_size_auc_bid_size',\n",
    " 'rolling18_mean_imb1_reference_price_wap',\n",
    " 'ask_price_diff_3',\n",
    " 'diff_shift1_price_pressure_v2',\n",
    " 'diff_shift12_scale_matched_size',\n",
    " 'diff_shift1_flag_imbalance_size',\n",
    " 'imb1_ask_size_bid_size',\n",
    " 'imb1_bid_price_mid_price',\n",
    " 'rolling48_mean_target_mock_shift6']:\n",
    "        add_cols.append((((pl.col(col) * pl.col(\"weight\")).sum().over(\"date_id\",\"seconds_in_bucket\"))/(((pl.col(\"weight\")).sum().over(\"date_id\",\"seconds_in_bucket\")))).alias(f\"global_{col}\"))\n",
    "        feas_list.append(f\"global_{col}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    \n",
    "    # MACD\n",
    "    rsi_cols = [\"mid_price_near_far\",\"imb1_reference_price_wap\",\"near_price\",]\n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for window_size in [3,6,12,24,48]:\n",
    "            add_cols.append(pl.col(col).ewm_mean(span=window_size, adjust=False).over('stock_id','date_id').alias(f\"rolling_ewm_{window_size}_{col}\"))\n",
    "            #feas_list.append(f\"rolling_ewm_{window_size}_{col}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            add_cols.append((pl.col(f\"rolling_ewm_{w1}_{col}\") - pl.col(f\"rolling_ewm_{w2}_{col}\")).alias(f\"dif_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"dif_{col}_{w1}_{w2}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            add_cols.append(pl.col(f\"dif_{col}_{w1}_{w2}\").ewm_mean(span=9, adjust=False).over('stock_id','date_id').alias(f\"dea_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"dea_{col}_{w1}_{w2}\")\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in rsi_cols:\n",
    "        for w1,w2 in zip((3,6,12,24),(6,12,24,48)):\n",
    "            add_cols.append((pl.col(f\"dif_{col}_{w1}_{w2}\") - pl.col(f\"dea_{col}_{w1}_{w2}\")).alias(f\"macd_{col}_{w1}_{w2}\"))\n",
    "            #feas_list.append(f\"macd_{col}_{w1}_{w2}\")\n",
    "    \n",
    "    feas_list.extend(['macd_imb1_reference_price_wap_12_24',\n",
    " 'dif_imb1_reference_price_wap_3_6',\n",
    " 'macd_mid_price_near_far_12_24',\n",
    " 'dif_near_price_3_6',\n",
    " 'macd_near_price_24_48',\n",
    " 'dea_imb1_reference_price_wap_12_24',\n",
    " 'macd_near_price_12_24',\n",
    " 'rolling_ewm_24_imb1_reference_price_wap',\n",
    " 'dif_near_price_6_12',\n",
    " 'dea_mid_price_near_far_6_12',\n",
    " 'dea_near_price_24_48',\n",
    " 'rolling_ewm_12_imb1_reference_price_wap',\n",
    " 'dif_imb1_reference_price_wap_12_24'])\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    add_cols = []\n",
    "    for col in [\"target\"]:\n",
    "        # 176 1,2,3,5,10,15,20,25,30\n",
    "        # [1,2,3,5,10,15,20,25,30,35,40,45,60] 5.8704926 157\n",
    "        # [1,2,3,5,10,15,20,30,45,60] 5.8708683137\n",
    "        for window_size in [1,2,3,5,10,15,20,25,30,35,40,45,60]:\n",
    "            add_cols.append(pl.col(col).shift(1).rolling_mean(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_mean_{window_size}_{col}_second'))\n",
    "            add_cols.append(pl.col(col).shift(1).rolling_std(window_size=window_size,min_periods=1).over('stock_id','seconds_in_bucket').alias(f'rolling_std_{window_size}_{col}_second'))\n",
    "\n",
    "            \n",
    "            feas_list.extend([f'rolling_mean_{window_size}_{col}_second',f'rolling_std_{window_size}_{col}_second',])\n",
    "\n",
    "    df = df.with_columns(add_cols)\n",
    "    \n",
    "    \n",
    "    return df.to_pandas(), feas_list\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56d724-6d1e-4bbb-bb08-fcf6f9300917",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feas, feas_list = generate_features_no_hist_polars(train)\n",
    "print(train_feas.shape)\n",
    "print(len(feas_list))\n",
    "feas_dict = {}\n",
    "feas_dict['selected_feas'] = feas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba7ba8-d23d-4321-9e42-397210dfe2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feas = train_feas.fillna(-9e10)\n",
    "#valid_feas = valid_feas.fillna(-9e10)\n",
    "from tqdm.auto import tqdm\n",
    "for _ in tqdm(feas_list):\n",
    "    train_feas[_] = train_feas[_].clip(lower=-9e9,upper=9e9)\n",
    "    #valid_feas[_] = valid_feas[_].clip(lower=-9e9,upper=9e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e95d4-6ecb-485a-975a-bbd64461cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664c9da-eee9-4e34-ac83-e97981e7ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../save/xgb3_feas_v7_157.json\",'w') as f:\n",
    "    json.dump(feas_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcde1a7-4750-49fb-8240-5f5c45bc501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,shuffle=True,random_state=47)\n",
    "k = 0\n",
    "for train_index,test_index in kf.split(train_feas):\n",
    "    k+=1\n",
    "    print(f'{k}folds begins******************************')\n",
    "    params = {\n",
    "        'random_state': 47,\n",
    "        'learning_rate':0.01,\n",
    "        'n_estimators':2978,\n",
    "        'n_jobs':-1,\n",
    "        'objective':'reg:absoluteerror',\n",
    "        \"device\": \"gpu\",\n",
    "        'max_depth': 10,\n",
    "         'min_child_weight': 8.860379669551103,\n",
    "         'subsample': 0.7711820080525443,\n",
    "         'colsample_bytree': 0.5348780216605801,\n",
    "         'reg_alpha': 0.12854342791716195,\n",
    "         'reg_lambda': 0.39326076062073634,\n",
    "         'gamma': 0.24378704040107024\n",
    "    }\n",
    "    date_ids = np.array(train_feas.iloc[train_index,:][\"date_id\"])\n",
    "    weights_date = np.ones_like(date_ids).astype(float)\n",
    "    weights_date[date_ids>=435] = 1.5\n",
    "    \n",
    "    clf = xgb.XGBRegressor(**params)\n",
    "    clf.fit(train_feas.iloc[train_index,:][feas_list],train_feas.iloc[train_index,:]['target'],\n",
    "            eval_set = [(train_feas.iloc[train_index,:][feas_list],train_feas.iloc[train_index,:]['target'])]\n",
    "            ,verbose=50,sample_weight=weights_date)\n",
    "    clf.save_model(f\"../save/xgb3_v7_k{k}_weight15_debug.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c9e96-bd13-4308-9300-5f8f8d64b32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002058e4-202a-4228-8cfa-1ae03e1aa18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a9f27-b86b-41bd-bd48-c02881e68390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "327.68px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
