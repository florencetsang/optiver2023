{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x145b7771b920>\n",
      "Traceback (most recent call last):\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_data_from_csv\n",
    "from data_preprocessor.data_preprocessor import CompositeDataPreprocessor, ReduceMemUsageDataPreprocessor, FillNaPreProcessor\n",
    "from data_preprocessor.feature_engineering import BasicFeaturesPreprocessor, DupletsTripletsPreprocessor, MovingAvgPreProcessor, RemoveIrrelevantFeaturesDataPreprocessor, DropTargetNADataPreprocessor, DTWKMeansPreprocessor\n",
    "from data_preprocessor.polynomial_features import PolynomialFeaturesPreProcessor\n",
    "from data_preprocessor.stockid_features import StockIdFeaturesPreProcessor\n",
    "from data_preprocessor.deep_feature_synthesis import DfsPreProcessor\n",
    "from data_generator.data_generator import DefaultTrainEvalDataGenerator, ManualKFoldDataGenerator, TimeSeriesKFoldDataGenerator\n",
    "\n",
    "from model_pipeline.lgb_pipeline import LGBModelPipelineFactory\n",
    "\n",
    "from model_post_processor.model_post_processor import CompositeModelPostProcessor, SaveModelPostProcessor\n",
    "\n",
    "from train_pipeline.train_pipeline import DefaultTrainPipeline\n",
    "from train_pipeline.train_optuna_pipeline import DefaultOptunaTrainPipeline\n",
    "\n",
    "from train_pipeline.train_pipeline_callbacks import MAECallback\n",
    "from utils.scoring_utils import ScoringUtils\n",
    "from model_pipeline.dummy_models import BaselineEstimator\n",
    "\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_fold = 5\n",
    "model_save_dir = './models/'\n",
    "\n",
    "processors = [    \n",
    "    ReduceMemUsageDataPreprocessor(verbose=True),\n",
    "    # BasicFeaturesPreprocessor(),\n",
    "    # DupletsTripletsPreprocessor(),\n",
    "    # MovingAvgPreProcessor(\"wap\"),   \n",
    "    # StockIdFeaturesPreProcessor(),   \n",
    "    # DTWKMeansPreprocessor(),    \n",
    "    DropTargetNADataPreprocessor(),    \n",
    "    RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id']),\n",
    "    # DfsPreProcessor(),\n",
    "    # FillNaPreProcessor(),\n",
    "    # PolynomialFeaturesPreProcessor(),\n",
    "]\n",
    "\n",
    "\n",
    "processor = CompositeDataPreprocessor(processors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
      "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
      "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
      "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# DATA_PATH = '/kaggle/input'\n",
    "DATA_PATH = '..'\n",
    "df_train, df_test, revealed_targets, sample_submission = load_data_from_csv(DATA_PATH)\n",
    "print(df_train.columns)\n",
    "\n",
    "raw_data = df_train\n",
    "# df_train = df_train[:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompositeDataPreprocessor - original df shape: (5237980, 17)\n",
      "Processing ReduceMemUsageDataPreprocessor...\n",
      "Memory usage of dataframe is 679.36 MB\n",
      "Memory usage after optimization is: 304.72 MB\n",
      "Decreased by 55.15%\n",
      "dtypes:\n",
      "stock_id                     int16\n",
      "date_id                      int16\n",
      "seconds_in_bucket            int16\n",
      "imbalance_size             float32\n",
      "imbalance_buy_sell_flag       int8\n",
      "reference_price            float32\n",
      "matched_size               float32\n",
      "far_price                  float32\n",
      "near_price                 float32\n",
      "bid_price                  float32\n",
      "bid_size                   float32\n",
      "ask_price                  float32\n",
      "ask_size                   float32\n",
      "wap                        float32\n",
      "target                     float32\n",
      "time_id                      int16\n",
      "row_id                      object\n",
      "dtype: object\n",
      "ReduceMemUsageDataPreprocessor took 0.38s. New df shape: (5237980, 17).\n",
      "Processing DropTargetNADataPreprocessor...\n",
      "DropTargetNADataPreprocessor took 0.44s. New df shape: (5237892, 17).\n",
      "Processing RemoveIrrelevantFeaturesDataPreprocessor...\n",
      "RemoveIrrelevantFeaturesDataPreprocessor took 0.32s. New df shape: (5237892, 14).\n",
      "CompositeDataPreprocessor - final df shape: (5237892, 14)\n"
     ]
    }
   ],
   "source": [
    "# df_train = ReduceMemUsageDataPreprocessor(verbose=True).apply(df_train)\n",
    "df_train = processor.apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_train.copy()\n",
    "\n",
    "es = ft.EntitySet(id = 'closing_movements_data')\n",
    "# es = es.entity_from_dataframe(entity_id = 'df', dataframe = df_, index = 'row_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from woodwork.logical_types import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    }
   ],
   "source": [
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"closing_movements\",\n",
    "    dataframe=df_,\n",
    "    index=\"row_id\",\n",
    "    # time_index=\"time_id\",\n",
    "    logical_types={\n",
    "        \"imbalance_buy_sell_flag\": Categorical,\n",
    "        # \"zip_code\": PostalCode,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: closing_movements_data\n",
       "  DataFrames:\n",
       "    closing_movements [Rows: 5237892, Columns: 14]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logical Type</th>\n",
       "      <th>Semantic Tag(s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <td>Integer</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_size</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <td>Categorical</td>\n",
       "      <td>['category']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matched_size</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_price</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_size</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_size</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wap</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Double</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <td>Integer</td>\n",
       "      <td>['index']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                        Logical Type Semantic Tag(s)\n",
       "Column                                              \n",
       "seconds_in_bucket            Integer     ['numeric']\n",
       "imbalance_size                Double     ['numeric']\n",
       "imbalance_buy_sell_flag  Categorical    ['category']\n",
       "reference_price               Double     ['numeric']\n",
       "matched_size                  Double     ['numeric']\n",
       "far_price                     Double     ['numeric']\n",
       "near_price                    Double     ['numeric']\n",
       "bid_price                     Double     ['numeric']\n",
       "bid_size                      Double     ['numeric']\n",
       "ask_price                     Double     ['numeric']\n",
       "ask_size                      Double     ['numeric']\n",
       "wap                           Double     ['numeric']\n",
       "target                        Double     ['numeric']\n",
       "row_id                       Integer       ['index']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es[\"closing_movements\"].ww.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only one dataframe in entityset, changing max_depth to 1 since deeper features cannot be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 79 features\n",
      "Elapsed: 00:19 | Progress:  95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       "
     ]
    }
   ],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(entityset = es, \n",
    "                                      target_dataframe_name = 'closing_movements',\n",
    "                                      trans_primitives = ['add_numeric',],\n",
    "                                                          # 'multiply_numeric',\n",
    "                                      verbose=True,\n",
    "                                      chunk_size=.05)\n",
    "\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = pd.DataFrame()\n",
    "stocks_df[\"stock_id\"] = pd.Series(pd.unique(df_[\"stock_id\"]))\n",
    "stocks_df[\"dummy\"] = pd.Series(pd.unique(df_[\"stock_id\"]))\n",
    "stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"stocks\", dataframe=stocks_df, index=\"stock_id\"\n",
    ")\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.add_relationship(\"stocks\", \"stock_id\", \"closing_movements\", \"stock_id\")\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es[\"closing_movements\"].ww.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_agg_primitives =  [\"sum\", \"std\", \"max\", \"skew\", \"min\", \"mean\"]\n",
    "default_trans_primitives =  [\"day\", \"year\", \"month\", \"weekday\", \"haversine\", \"numwords\", \"characters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(entityset=es, \n",
    "                                    target_dataframe_name=\"stocks\",\n",
    "                                    # trans_primitives = default_trans_primitives,\n",
    "                                    agg_primitives=default_agg_primitives, \n",
    "                                    max_depth = 2)\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.selection.remove_highly_null_features(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.selection import (\n",
    "    remove_highly_correlated_features,\n",
    "    remove_highly_null_features,\n",
    "    remove_single_value_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fm, new_features = remove_single_value_features(feature_matrix, features=feature_defs)\n",
    "new_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fm2, new_features2 = remove_highly_correlated_features(new_fm, features=new_features)\n",
    "new_fm2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fm2.drop(['dummy'], axis = 1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.merge(new_fm2, left_on = \"stock_id\", right_on = \"stock_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix2, feature_defs2 = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name=\"stocks\",\n",
    "    agg_primitives=[\"mean\", \"sum\", \"mode\"],\n",
    "    # trans_primitives=[\"month\", \"hour\"],\n",
    "    max_depth=2,\n",
    ")\n",
    "feature_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_matrix, feature_defs = ft.dfs(entityset=es, \n",
    "#                                     target_dataframe_name=\"stocks\")\n",
    "# feature_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "from data_preprocessor.data_preprocessor import DataPreprocessor\n",
    "\n",
    "class DfsPreProcessor(DataPreprocessor):\n",
    "    def apply(self, df):\n",
    "\n",
    "        df_ = df.copy()\n",
    "\n",
    "        es = ft.EntitySet(id = 'train_df')\n",
    "        # es = es.entity_from_dataframe(entity_id = 'df', dataframe = df_, index = 'row_id')\n",
    "        es = es.add_dataframe(\n",
    "            dataframe_name=\"closing_movements\",\n",
    "            dataframe=df_,\n",
    "            index=\"row_id\",\n",
    "            time_index=\"time_id\",\n",
    "            # logical_types={\n",
    "            #     \"product_id\": Categorical,\n",
    "            #     \"zip_code\": PostalCode,\n",
    "            # },\n",
    "        )\n",
    "\n",
    "        print(es[\"closing_movements\"].ww.schema)\n",
    "\n",
    "        default_agg_primitives =  [\"sum\", \"std\", \"max\", \"skew\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "        default_trans_primitives =  [\"day\", \"year\", \"month\", \"weekday\", \"haversine\", \"numwords\", \"characters\"]\n",
    "\n",
    "        feature_names = ft.dfs(entityset = es, \n",
    "                            #    target_entity = 'df',\n",
    "                       trans_primitives = default_trans_primitives,\n",
    "                       agg_primitives=default_agg_primitives, \n",
    "                       max_depth = 2, features_only=True)\n",
    "        \n",
    "        print(feature_names)        \n",
    "\n",
    "        return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = DfsPreProcessor().apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
