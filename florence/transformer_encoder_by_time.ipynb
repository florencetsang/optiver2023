{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd47b81-4823-488e-b9d4-b6d03d67d84d",
   "metadata": {},
   "source": [
    "# Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba5f06-d483-4625-8b0e-101f05afcb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d284441-83ea-4b5e-bbc2-df7b7f23e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df76665-28a9-4213-8151-02415806dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessor.data_preprocessor import CompositeDataPreprocessor, CompositeGroupedDataPreprocessor, ReduceMemUsageDataPreprocessor, FillNaPreProcessor\n",
    "from data_preprocessor.feature_engineering import (\n",
    "    BasicFeaturesPreprocessor,\n",
    "    DupletsTripletsPreprocessor,\n",
    "    MovingAvgPreProcessor,\n",
    "    RemoveIrrelevantFeaturesDataPreprocessor,\n",
    "    DropTargetNADataPreprocessor,\n",
    "    FarNearPriceFillNaPreprocessor,\n",
    "    MovingAvgFillNaPreprocessor,\n",
    "    RemoveRecordsByStockDateIdPreprocessor,\n",
    "    RemoveIrrelevantFeaturesDataTransformer,\n",
    "    EWMAPreProcessor, \n",
    "    EWMAFillNaPreprocessor\n",
    ")\n",
    "from data_preprocessor.stock_feature_engineering import (\n",
    "    StockNormalizeFeaturesPreprocessor,\n",
    ")\n",
    "from data_preprocessor.deep_feature_synthesis import StockDateIdPreprocessor, FeatureToolsDFSTransformer\n",
    "from data_preprocessor.normalization import NormalizationDataTransformer\n",
    "from data_preprocessor.polynomial_features import PolynomialFeaturesPreProcessor\n",
    "from data_preprocessor.stockid_features import StockIdFeaturesPreProcessor, StockIdFeaturesDataTransformer\n",
    "from data_preprocessor.deep_feature_synthesis import DfsPreProcessor\n",
    "from data_preprocessor.stocks_pca_preprocessor import StocksPcaPreProcessor\n",
    "\n",
    "from data_generator.data_generator import DefaultTrainEvalDataGenerator, ManualKFoldDataGenerator, TimeSeriesKFoldDataGenerator\n",
    "from utils.dataframe_utils import get_df_summary_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6c959-8bcf-4068-8a9b-4aab7477111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c80e32-91dc-4ffd-adbc-c179629764d1",
   "metadata": {},
   "source": [
    "# Hyperparameters / Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0360f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"transformer_encoder_by_time_checkpoints/20240430_transformer_stockid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14e856-bb8f-4468-bb9c-e7b3cbfb04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_version_name = None\n",
    "# change to a string for a specific name\n",
    "# model_folder_version_name = \"test\"\n",
    "\n",
    "# https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.tensorboard.html\n",
    "# https://lightning.ai/docs/pytorch/stable/extensions/logging.html\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\".\", version=model_folder_version_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c2882-c5a3-484a-8b03-065acd7228f7",
   "metadata": {},
   "source": [
    "## Train-validation split (align with LightGBM experiment/setup for fair comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf3509-5e51-4521-abaa-ba629f708922",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_fold = 5\n",
    "time_series_k_fold_data_generator = TimeSeriesKFoldDataGenerator(n_fold=N_fold, test_set_ratio=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a91ce5-2b78-4283-96d8-bd63a79e3b79",
   "metadata": {},
   "source": [
    "## Data hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d32ac-2f16-47a8-804f-9a99c7f3bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 1\n",
    "seq_len = 55 * 2\n",
    "\n",
    "training_batch_size = 256\n",
    "validation_batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8d4d0-7b06-43df-ab37-39dc626ea32f",
   "metadata": {},
   "source": [
    "## Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795a422-fa6a-4195-961b-2c0b9e712f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 4\n",
    "d_model = 32\n",
    "nhead = 4\n",
    "d_hid = 32\n",
    "nlayers = 2\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d5186-c564-42e9-98c7-900ed8a898de",
   "metadata": {},
   "source": [
    "## Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d79ddb-b6aa-4f3c-a930-265549a10ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "limit_train_batches = 1.0\n",
    "# limit_train_batches = 2\n",
    "learning_rate = 1e-3\n",
    "gradient_clip_val = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8b75b-6d45-48ad-9930-16263cafbabe",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "TODO:\n",
    "1. use input_ff_sigmoid?\n",
    "2. any further model enhancement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc303388-ea46-4812-808d-9ffd9984fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_features: int,\n",
    "        num_classes: int,\n",
    "        embedding_dim: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embedding = nn.Embedding(num_classes, embedding_dim)\n",
    "        self.input_ff = nn.Linear(num_input_features + embedding_dim, d_model)\n",
    "        self.input_ff_sigmoid = nn.Sigmoid()\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.d_model = d_model\n",
    "        self.final_linear = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: Tensor,\n",
    "        item_ids: Tensor,\n",
    "        src_mask: Tensor = None,\n",
    "    ) -> Tensor:\n",
    "        # src: [batch_size b, seq_len k 200, features 27]\n",
    "        # item_ids: [batch_size b, seq_len 200]\n",
    "        batch_size = src.size(dim=0)\n",
    "        seq_len = src.size(dim=1)\n",
    "        num_input_features = src.size(dim=2)\n",
    "        output = src\n",
    "        embedded = self.embedding(item_ids)\n",
    "        # embedded: [batch_size b, seq_len 200, embedding_dim]\n",
    "        # idea from https://github.com/huggingface/transformers/blob/v4.38.2/src/transformers/models/time_series_transformer/modeling_time_series_transformer.py#L1290\n",
    "        # embedded = embedded.unsqueeze(dim=1)\n",
    "        # embedded: [batch_size b, 1, embedding_dim]\n",
    "        # embedded = embedded.expand(-1, seq_len, -1)\n",
    "        # embedded: [batch_size b, seq_len k 55, embedding_dim]\n",
    "\n",
    "        output = torch.cat((src, embedded), dim=-1)\n",
    "        # [batch_size b, seq_len k 55, features 27 + embedding_dim]\n",
    "\n",
    "        output = self.input_ff(output)\n",
    "        # [batch_size b, seq_len k 55, d_model]\n",
    "\n",
    "        # TODO: do we need sigmoid?\n",
    "        output = self.input_ff_sigmoid(output)\n",
    "\n",
    "        # if src_mask is None:\n",
    "        #     \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "        #     Unmasked positions are filled with float(0.0).\n",
    "        #     \"\"\"\n",
    "        #     src_mask = nn.Transformer.generate_square_subsequent_mask(seq_len)\n",
    "        #     # no \"to device\" for lightning\n",
    "        #     # https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to\n",
    "        #     src_mask = src_mask.to(output)\n",
    "        #     # src_mask = squared (triangle matrix) matrix [seq_len k 55, seq_len k 55]\n",
    "\n",
    "        output = self.transformer_encoder(output, src_mask)\n",
    "        # [batch_size b, seq_len k 200, d_model]\n",
    "\n",
    "        output = self.final_linear(output)\n",
    "        # [batch_size b, seq_len k 200, 1]\n",
    "\n",
    "        # # take the \"last\" prediction, which includes all previous information\n",
    "        # output = output[:, -1, :]\n",
    "        # # [batch_size b, 1]\n",
    "        output = output.squeeze(dim=2)\n",
    "        # [batch_size b, , seq_len k 200]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad7341-2919-4623-9c05-47057d950bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/49433936/how-do-i-initialize-weights-in-pytorch\n",
    "# https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b71edd-ebc9-41f5-8f80-984b55e48674",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316823f-0a3f-4dfd-ad2e-21944357b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../optiver-trading-at-the-close/train.csv\",\n",
    "    dtype={\n",
    "        # stock_id should be int64 / long for embedding\n",
    "        \"date_id\": np.float32,\n",
    "        \"seconds_in_bucket\": np.float32,\n",
    "        \"imbalance_size\": np.float32,\n",
    "        \"imbalance_buy_sell_flag\": np.float32,\n",
    "        \"reference_price\": np.float32,\n",
    "        \"matched_size\": np.float32,\n",
    "        \"far_price\": np.float32,\n",
    "        \"near_price\": np.float32,\n",
    "        \"bid_price\": np.float32,\n",
    "        \"bid_size\": np.float32,\n",
    "        \"ask_price\": np.float32,\n",
    "        \"ask_size\": np.float32,\n",
    "        \"wap\": np.float32,\n",
    "        \"target\": np.float32,\n",
    "        \"time_id\": np.int64,\n",
    "    },\n",
    "    usecols=[\n",
    "        \"stock_id\",\n",
    "        \"date_id\",\n",
    "        \"seconds_in_bucket\",\n",
    "        \"imbalance_size\",\n",
    "        \"imbalance_buy_sell_flag\",\n",
    "        \"reference_price\",\n",
    "        \"matched_size\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"bid_price\",\n",
    "        \"bid_size\",\n",
    "        \"ask_price\",\n",
    "        \"ask_size\",\n",
    "        \"wap\",\n",
    "        \"target\",\n",
    "        \"time_id\",\n",
    "    ]\n",
    ")\n",
    "raw_df = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294ef50-c777-4ace-8624-8e966ba0f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep copy for easy reference to raw df without reloading from csv\n",
    "df = raw_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6efd1-8e47-4daa-a597-dda8fd29abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a64d87-d298-4760-97ff-9804ce255eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_train_dfs, k_fold_val_dfs, k_fold_num_train_val_sets = time_series_k_fold_data_generator.generate(df)\n",
    "k_fold_train_df = k_fold_train_dfs[-1]\n",
    "k_fold_val_df = k_fold_val_dfs[-1]\n",
    "k_fold_train_df_index = k_fold_train_df.index\n",
    "k_fold_val_df_index = k_fold_val_df.index\n",
    "print(len(k_fold_train_dfs), len(k_fold_val_dfs), k_fold_num_train_val_sets, N_fold)\n",
    "assert k_fold_num_train_val_sets == N_fold and len(k_fold_train_dfs) == N_fold and len(k_fold_val_dfs) == N_fold\n",
    "print(k_fold_train_df.shape, k_fold_val_df.shape, df.shape)\n",
    "assert k_fold_train_df.shape[0] + k_fold_val_df.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f86ef-d1a7-4fd9-b4fb-51317ad6aa43",
   "metadata": {},
   "source": [
    "## Data pre-processing and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b55231-1237-441f-a6e0-ef0c846e592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [    \n",
    "    ReduceMemUsageDataPreprocessor(verbose=True),\n",
    "    RemoveRecordsByStockDateIdPreprocessor([\n",
    "        {\"stock_id\": 19, \"date_id\": 438},\n",
    "        {\"stock_id\": 101, \"date_id\": 328},\n",
    "        {\"stock_id\": 131, \"date_id\": 35},\n",
    "        {\"stock_id\": 158, \"date_id\": 388},\n",
    "    ]),\n",
    "    FarNearPriceFillNaPreprocessor(),\n",
    "    # BasicFeaturesPreprocessor(),\n",
    "    # DupletsTripletsPreprocessor(enable_triplets=False),\n",
    "    # MovingAvgPreProcessor(\"wap\"),\n",
    "    # MovingAvgFillNaPreprocessor(\"wap\", 1.0),\n",
    "    # EWMAPreProcessor(\"wap\", 10),\n",
    "    # EWMAFillNaPreprocessor(\"wap\", 1.0),\n",
    "    # StockIdFeaturesPreProcessor(),   \n",
    "    # StocksPcaPreProcessor(),\n",
    "    # DTWKMeansPreprocessor(),\n",
    "    # DfsPreProcessor(),\n",
    "    # StockDateIdPreprocessor(), \n",
    "    # FeatureToolsDFSPreprocessor(),\n",
    "    # DropTargetNADataPreprocessor(),    \n",
    "    # RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id', 'row_id']),\n",
    "    # FillNaPreProcessor(1.0),\n",
    "    # PolynomialFeaturesPreProcessor(),\n",
    "]\n",
    "processor = CompositeDataPreprocessor(processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0187ad1-6a4f-46f3-92bc-47973e0250dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processor.apply(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974f358-9e3b-437b-856d-b60559107eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd29601-3a01-47bf-93ec-1cd63325cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_include_in_feat = ['stock_id', 'target', 'time_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e8b4c-0a37-4291-9c8b-cd167bb2ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dynamic_real = [item for item in df.columns if item not in not_include_in_feat]\n",
    "feat_dynamic_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3c19b-0507-41c6-883b-f494a8f33f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_dynamic_real = [\n",
    "#     \"date_id\",\n",
    "#     \"seconds_in_bucket\",\n",
    "#     \"imbalance_size\",\n",
    "#     \"reference_price\",\n",
    "#     \"matched_size\",\n",
    "#     \"far_price\",\n",
    "#     \"near_price\",\n",
    "#     \"bid_price\",\n",
    "#     \"bid_size\",\n",
    "#     \"ask_price\",\n",
    "#     \"ask_size\",\n",
    "#     \"wap\",\n",
    "#     # \"wap_mov_avg_3_1\",\n",
    "#     # \"wap_mov_avg_6_3\",\n",
    "#     # \"wap_mov_avg_12_6\",\n",
    "#     # \"wap_mov_avg_24_12\",\n",
    "# ]\n",
    "num_input_features = len(feat_dynamic_real)\n",
    "num_classes = 200\n",
    "print(num_input_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c95c3-5603-4ec7-86a5-b0ed38d74a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should not have any na features\n",
    "any_na_values_mask = df[feat_dynamic_real].isna().any(axis=1)\n",
    "print(any_na_values_mask.shape, any_na_values_mask[any_na_values_mask].shape)\n",
    "assert any_na_values_mask[any_na_values_mask].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7294ec1-c78e-477c-9f72-6aea69557aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[any_na_values_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"stock_id\", \"time_id\"])\n",
    "stock_id_list = np.arange(200, dtype=np.int64)\n",
    "time_id_list = np.arange(26455, dtype=np.int64)\n",
    "pd_multiindex = pd.MultiIndex.from_product([stock_id_list, time_id_list], names=(\"stock_id\", \"time_id\"))\n",
    "df = df.reindex(pd_multiindex, fill_value=0.0)\n",
    "df = df.reset_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca31a49-8986-44e6-973b-1142edc97979",
   "metadata": {},
   "source": [
    "## Group by stock_id\n",
    "\n",
    "TODO: group by date_id too? or use embedding for date_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7bd99-3e4b-4c1a-9fc2-07ccd9bf641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped = df.groupby(\"date_id\")\n",
    "# num_classes = len(df_grouped)\n",
    "# print(num_classes)\n",
    "# print(df_grouped.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a8f6c-e938-414a-81f6-1e1227978dfe",
   "metadata": {},
   "source": [
    "### Separate df_grouped into training and validation set by time-series k-fold index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7693d34-051b-4e81-a3f6-b05b4de342cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped_train_map = {}\n",
    "# df_grouped_val_map = {}\n",
    "# df_grouped_train_map_sizes_sum = 0\n",
    "# df_grouped_val_map_sizes_sum = 0\n",
    "\n",
    "# for item_id, gdf in df_grouped:\n",
    "#     training_k_fold_idx_filter_mask = gdf.index.isin(k_fold_train_df_index)\n",
    "\n",
    "#     training_df = gdf[training_k_fold_idx_filter_mask]\n",
    "#     df_grouped_train_map[item_id] = training_df\n",
    "#     df_grouped_train_map_sizes_sum += training_df.shape[0]\n",
    "\n",
    "#     validation_df = gdf[~training_k_fold_idx_filter_mask]\n",
    "#     df_grouped_val_map[item_id] = validation_df\n",
    "#     df_grouped_val_map_sizes_sum += validation_df.shape[0]\n",
    "\n",
    "#     assert training_df.shape[0] > 0 \\\n",
    "#         and validation_df.shape[0] > 0 \\\n",
    "#         and training_df.shape[0] + validation_df.shape[0] == gdf.shape[0], f\"{item_id} invalid shape, training_df: {training_df.shape}, validation_df: {validation_df.shape}\"\n",
    "\n",
    "# print(df_grouped_train_map_sizes_sum, df_grouped_val_map_sizes_sum, k_fold_train_df_index.shape, k_fold_val_df_index.shape)\n",
    "# print(df_grouped_train_map_sizes_sum + df_grouped_val_map_sizes_sum - k_fold_train_df_index.shape[0] - k_fold_val_df_index.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e948553c-a509-458c-83d8-58c287fc969a",
   "metadata": {},
   "source": [
    "## Stock-based feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622a8fc-e6df-4815-bd91-03deef379328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize_columns = set([\n",
    "#     \"imbalance_size\",\n",
    "#     \"matched_size\",\n",
    "#     \"bid_size\",\n",
    "#     \"ask_size\",\n",
    "# ])\n",
    "# normalize_columns = list(normalize_columns.intersection(set(feat_dynamic_real)))\n",
    "# print(normalize_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab1363-c381-4536-828c-07677832b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_processors = [\n",
    "#     StockNormalizeFeaturesPreprocessor(normalize_columns),\n",
    "# ]\n",
    "# stock_processor = CompositeGroupedDataPreprocessor(stock_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab482fa7-d725-4c7b-bd94-22120909b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_processor.fit(df_grouped_train_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382e9bc-10e9-48b2-aca2-d779e8421daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped_train_map = stock_processor.apply(df_grouped_train_map)\n",
    "# df_grouped_val_map = stock_processor.apply(df_grouped_val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec7e23-9222-47e0-b6de-e415056de2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_grouped_train_map[0])\n",
    "# display(df_grouped_val_map[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6db38a-e0f8-4d95-9c1f-3bf70fe1e7b3",
   "metadata": {},
   "source": [
    "## Final features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3c33d-4649-464b-9e7a-5c70a9e94561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update feat_dynamic_real if needed after per-stock feature engineering\n",
    "feat_dynamic_real = feat_dynamic_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687dde16-8a06-40cd-b849-060c3eb9b727",
   "metadata": {},
   "source": [
    "## Prepare Pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00037e5-af83-4f4b-9e89-b60accf6d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptiverDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, feature_names, category_cols, target_col, time_idx_col, num_time_pts, time_idx_offset):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.features = df[feature_names]\n",
    "        self.categories = df[category_cols]\n",
    "        self.targets = df[target_col]\n",
    "        self.time_idx = df[time_idx_col]\n",
    "        self.num_time_pts = num_time_pts\n",
    "        self.time_idx_offset = time_idx_offset\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_time_pts\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        time_idx_mask = self.time_idx == self.time_idx_offset + idx\n",
    "        features = self.features[time_idx_mask]\n",
    "        categories = self.categories[time_idx_mask]\n",
    "        targets = self.targets[time_idx_mask]\n",
    "        return features.values, categories.values, targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf94625c-b4d2-4c11-9baa-b9a1f9f635fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_training_datasets = []\n",
    "# for item_id, gdf in df_grouped_train_map.items():\n",
    "#     stock_training_datasets.append(StockTrainingDataset(gdf, feat_dynamic_real, \"target\", item_id, seq_len))\n",
    "\n",
    "# stock_validation_datasets = []\n",
    "# for item_id, gdf in df_grouped_val_map.items():\n",
    "#     stock_validation_datasets.append(StockTrainingDataset(gdf, feat_dynamic_real, \"target\", item_id, seq_len))\n",
    "\n",
    "# print(len(stock_training_datasets), len(stock_validation_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daff433-f66a-45c6-800a-1b23bb97bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_training_dataset = torch.utils.data.ConcatDataset(stock_training_datasets)\n",
    "# full_validation_dataset = torch.utils.data.ConcatDataset(stock_validation_datasets)\n",
    "# print(len(full_training_dataset), len(full_validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca936bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cutoff_time_id = math.floor(26455 * 0.9)\n",
    "df_train = df[df[\"time_id\"] < val_cutoff_time_id]\n",
    "df_eval = df[df[\"time_id\"] >= val_cutoff_time_id]\n",
    "print(df_train.shape, df_eval.shape, val_cutoff_time_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456412af-1bab-4b0d-a531-8cbe7454c155",
   "metadata": {},
   "source": [
    "### DFS, normalize, and other fit-transform pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7055fa1-a93a-4adc-9052-258092190992",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = make_pipeline(\n",
    "    # FeatureToolsDFSTransformer(\n",
    "    #     group_by_stock=True,\n",
    "    #     group_by_date=False,\n",
    "    #     group_by_stock_date=False,\n",
    "    # ),\n",
    "    StockIdFeaturesDataTransformer(),\n",
    "    NormalizationDataTransformer(\n",
    "        [\n",
    "            \"imbalance_size\",\n",
    "            \"matched_size\",\n",
    "            \"bid_size\",\n",
    "            \"ask_size\",\n",
    "        ],\n",
    "        \"closing_movements\",\n",
    "    ),\n",
    "    # do not remove columns, use feat_dynamic_real white-list\n",
    "    RemoveIrrelevantFeaturesDataTransformer(['stock_id', 'date_id','time_id', 'row_id', \"stock_date_id\"]),\n",
    "    verbose=True,\n",
    ")\n",
    "# transform_pipeline = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f42fdf-cb10-4513-919b-80c5ab4d8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"before transform_pipeline - df_train: {get_df_summary_str(df_train)}, df_eval: {get_df_summary_str(df_eval)}\")\n",
    "if transform_pipeline is not None:\n",
    "    df_train = transform_pipeline.fit_transform(df_train)\n",
    "    print(f\"fit_transform df_train - df_train: {get_df_summary_str(df_train)}\")\n",
    "    df_eval = transform_pipeline.transform(df_eval)\n",
    "    print(f\"transform df_eval - df_eval: {get_df_summary_str(df_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21867be1-717d-4868-bcfe-ad158f6b7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train)\n",
    "display(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fc4b7-ea08-4447-961f-e7e8e46e3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp solution to add dfs features to feat_dynamic_real, dfs feature columns will contain \"closing_movements\"\n",
    "for col in df_train.columns.tolist():\n",
    "    if col.find(\"closing_movements\") != -1:\n",
    "        feat_dynamic_real.append(col)\n",
    "num_input_features = len(feat_dynamic_real)\n",
    "print(num_input_features, feat_dynamic_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80acea66-6702-45c5-a095-e65241620b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp solution to force cast data types for pytorch model\n",
    "df_train = df_train.astype(np.float32)\n",
    "df_eval = df_eval.astype(np.float32)\n",
    "df_train = df_train.astype({\n",
    "    \"stock_id\": np.int64,\n",
    "    \"time_id\": np.int64\n",
    "})\n",
    "df_eval = df_eval.astype({\n",
    "    \"stock_id\": np.int64,\n",
    "    \"time_id\": np.int64\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02627b-23db-4474-8c6a-60984b2cc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train)\n",
    "display(df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a61adb-bcba-4c6b-9bb0-e53dfcf536b3",
   "metadata": {},
   "source": [
    "### Create Pytorch datasets from final dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8471d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_dataset = OptiverDataset(df_train, feat_dynamic_real, \"stock_id\", \"target\", \"time_id\", val_cutoff_time_id, 0)\n",
    "full_validation_dataset = OptiverDataset(df_eval, feat_dynamic_real, \"stock_id\", \"target\", \"time_id\", 26455 - val_cutoff_time_id, val_cutoff_time_id)\n",
    "print(len(full_training_dataset), len(full_validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f648120-a83d-4f5c-b53e-f31851fb80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sampler = torch.utils.data.RandomSampler(full_training_dataset)\n",
    "validation_sampler = torch.utils.data.SequentialSampler(full_validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607398d-2f29-4866-addb-e8b8a5053458",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = torch.utils.data.DataLoader(\n",
    "    full_training_dataset,\n",
    "    batch_size=training_batch_size,\n",
    "    sampler=training_sampler,\n",
    "    # https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\n",
    "    # num_workers=4,\n",
    "    # https://pytorch.org/docs/stable/data.html#memory-pinning\n",
    "    # pin_memory=True,\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    full_validation_dataset,\n",
    "    batch_size=validation_batch_size,\n",
    "    sampler=validation_sampler,\n",
    "    # num_workers=4,\n",
    "    # pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a822b02-69a4-4c33-8774-30890ab313f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample_batch = next(iter(training_dataloader))\n",
    "print(\"training_sample_batch\", training_sample_batch[0].size(), training_sample_batch[1].size())\n",
    "print(\"training_sample_batch\", training_sample_batch[0].type(), training_sample_batch[1].type())\n",
    "validation_sample_batch = next(iter(validation_dataloader))\n",
    "print(\"validation_sample_batch\", validation_sample_batch[0].size(), validation_sample_batch[1].size())\n",
    "print(\"validation_sample_batch\", validation_sample_batch[0].type(), validation_sample_batch[1].type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98310dcf-a011-472d-a79a-e7738cb71c06",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4374a57-0a89-45d8-9adb-e3ccbc2eb918",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(\n",
    "    num_input_features=num_input_features,\n",
    "    num_classes=num_classes,\n",
    "    embedding_dim=embedding_dim,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    nlayers=nlayers,\n",
    "    dropout=dropout,\n",
    ")\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca2b6f-b702-4f41-b720-58cbb99ed5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "validation_criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04dbf4e-5eef-47a5-bb65-009723f0c8ed",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "Start with `tensorboard --logdir=lightning_logs/` cmd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f05d4-34fd-45e9-8a1a-0f9f6257c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997092df-606f-4be2-acf8-04b42c004265",
   "metadata": {},
   "source": [
    "## Module and trainer (lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b16ac6-fef9-4d94-b17b-6545e290e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModelModule(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        validation_criterion: nn.Module,\n",
    "        lr,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.validation_criterion = validation_criterion\n",
    "        self.lr = lr\n",
    "        self.validation_step_outputs = []\n",
    "        self.validation_step_actual_targets = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, item_id, targets = batch[0], batch[1], batch[2]\n",
    "        actual_targets = targets\n",
    "        output = self.model(features, item_id)\n",
    "        loss = self.criterion(output, actual_targets)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        features, item_id, targets = batch[0], batch[1], batch[2]\n",
    "        actual_targets = targets\n",
    "        output = self.model(features, item_id)\n",
    "        # TODO: is loss being averaged based on batch size\n",
    "        loss = self.validation_criterion(output, actual_targets)\n",
    "        # lightning will take weighted-average on loss per step based on batch size\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.validation_step_outputs.append(output)\n",
    "        self.validation_step_actual_targets.append(actual_targets)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # TODO: remove manual calculation of validation loss if we can confirm lightning will take weighted average\n",
    "        # cat is used instead of stack, last step may have different batch size\n",
    "        all_preds = torch.cat(self.validation_step_outputs)\n",
    "        all_actual_targets = torch.cat(self.validation_step_actual_targets)\n",
    "        manual_loss = self.validation_criterion(all_preds, all_actual_targets)\n",
    "        self.log(\"val_loss_manual\", manual_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "        self.validation_step_actual_targets.clear()  # free memory\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.95),\n",
    "            weight_decay=1e-1,\n",
    "        )\n",
    "        return [optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22350a63-76bd-47cb-baf5-8ec579fafb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModelModule(\n",
    "    model,\n",
    "    criterion,\n",
    "    validation_criterion,\n",
    "    learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    save_top_k=2,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"transformer-{epoch:02d}-{val_loss:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1e0dc-77a4-48f2-b456-d65938de92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    limit_train_batches=limit_train_batches,\n",
    "    # https://lightning.ai/docs/pytorch/stable/advanced/training_tricks.html#gradient-clipping\n",
    "    gradient_clip_val=gradient_clip_val,\n",
    "    callbacks=[\n",
    "        # https://lightning.ai/docs/pytorch/stable/common/progress_bar.html#richprogressbar\n",
    "        RichProgressBar(leave=True),\n",
    "        checkpoint_callback,\n",
    "    ],\n",
    "    logger=tb_logger,\n",
    "    # https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "    deterministic=True,\n",
    ")\n",
    "print(trainer.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afdf94-e001-4a9c-a2a4-d65ace3ecb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(\n",
    "    model=model,\n",
    "    dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a577a-49c2-4641-aa72-4e1829dcfe5b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a417a73-8f6f-4640-afc8-229401cedb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint_dir)\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=training_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139bfba-7fca-482a-bf5c-0f633b61fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(\n",
    "    model=model,\n",
    "    dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0117199",
   "metadata": {},
   "source": [
    "## Load saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732061b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = checkpoint_callback.best_model_path\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = TransformerModelModule.load_from_checkpoint(checkpoint_path)\n",
    "print(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_checkpoint = torch.load(checkpoint_path)\n",
    "print(torch_checkpoint.keys())\n",
    "print(torch_checkpoint[\"state_dict\"].keys())\n",
    "print(torch_checkpoint[\"hyper_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f4c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f0272-a661-49ab-be90-ce5674627b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
