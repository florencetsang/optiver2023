{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x14d2104fb9c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_data_from_csv\n",
    "from data_preprocessor.data_preprocessor import CompositeDataPreprocessor, ReduceMemUsageDataPreprocessor, FillNaPreProcessor\n",
    "from data_preprocessor.feature_engineering import (\n",
    "    BasicFeaturesPreprocessor,\n",
    "    DupletsTripletsPreprocessor,\n",
    "    MovingAvgPreProcessor,\n",
    "    RemoveIrrelevantFeaturesDataPreprocessor,\n",
    "    DropTargetNADataPreprocessor,\n",
    "    FarNearPriceFillNaPreprocessor,\n",
    "    MovingAvgFillNaPreprocessor,\n",
    "    RemoveRecordsByStockDateIdPreprocessor,\n",
    ")\n",
    "from data_preprocessor.polynomial_features import PolynomialFeaturesPreProcessor\n",
    "from data_preprocessor.stockid_features import StockIdFeaturesPreProcessor\n",
    "from data_preprocessor.deep_feature_synthesis import DfsPreProcessor\n",
    "from data_generator.data_generator import DefaultTrainEvalDataGenerator, ManualKFoldDataGenerator, TimeSeriesKFoldDataGenerator\n",
    "\n",
    "from model_pipeline.lgb_pipeline import LGBModelPipelineFactory\n",
    "\n",
    "from model_post_processor.model_post_processor import CompositeModelPostProcessor, SaveModelPostProcessor\n",
    "\n",
    "from train_pipeline.train_pipeline import DefaultTrainPipeline\n",
    "from train_pipeline.train_optuna_pipeline import DefaultOptunaTrainPipeline\n",
    "\n",
    "from train_pipeline.train_pipeline_callbacks import MAECallback\n",
    "from utils.scoring_utils import ScoringUtils\n",
    "from model_pipeline.dummy_models import BaselineEstimator\n",
    "\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_fold = 5\n",
    "model_save_dir = './models/'\n",
    "\n",
    "processors = [\n",
    "    RemoveRecordsByStockDateIdPreprocessor([\n",
    "        {\"stock_id\": 19, \"date_id\": 438},\n",
    "        {\"stock_id\": 101, \"date_id\": 328},\n",
    "        {\"stock_id\": 131, \"date_id\": 35},\n",
    "        {\"stock_id\": 158, \"date_id\": 388},\n",
    "    ]),\n",
    "    FarNearPriceFillNaPreprocessor(),\n",
    "    ReduceMemUsageDataPreprocessor(verbose=True),\n",
    "    # BasicFeaturesPreprocessor(),    \n",
    "    # DupletsTripletsPreprocessor(),\n",
    "    # MovingAvgPreProcessor(\"wap\"),\n",
    "    # MovingAvgFillNaPreprocessor(\"wap\", 1.0),\n",
    "    # StockIdFeaturesPreProcessor(),  \n",
    "    # DropTargetNADataPreprocessor(),    \n",
    "    # RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id', 'row_id']),\n",
    "    # FillNaPreProcessor(),\n",
    "    # PolynomialFeaturesPreProcessor(),\n",
    "]\n",
    "\n",
    "# processors = [    \n",
    "#     ReduceMemUsageDataPreprocessor(verbose=True),\n",
    "#     # BasicFeaturesPreprocessor(),\n",
    "#     # DupletsTripletsPreprocessor(),\n",
    "#     # MovingAvgPreProcessor(\"wap\"),   \n",
    "#     # StockIdFeaturesPreProcessor(),   \n",
    "#     # DTWKMeansPreprocessor(),    \n",
    "#     DropTargetNADataPreprocessor(),    \n",
    "#     # RemoveIrrelevantFeaturesDataPreprocessor(['stock_id', 'date_id','time_id', 'row_id']),\n",
    "#     # DfsPreProcessor(),\n",
    "#     # FillNaPreProcessor(),\n",
    "#     # PolynomialFeaturesPreProcessor(),\n",
    "# ]\n",
    "\n",
    "\n",
    "processor = CompositeDataPreprocessor(processors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
      "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
      "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
      "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# DATA_PATH = '/kaggle/input'\n",
    "DATA_PATH = '..'\n",
    "df_train, df_test, revealed_targets, sample_submission = load_data_from_csv(DATA_PATH)\n",
    "print(df_train.columns)\n",
    "\n",
    "raw_data = df_train\n",
    "# df_train = df_train[:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompositeDataPreprocessor - original df shape: (5237980, 17)\n",
      "Processing RemoveRecordsByStockDateIdPreprocessor...\n",
      "RemoveRecordsByStockDateIdPreprocessor - removing 220 records\n",
      "RemoveRecordsByStockDateIdPreprocessor took 0.93s. New df shape: (5237760, 17).\n",
      "Processing FarNearPriceFillNaPreprocessor...\n",
      "FarNearPriceFillNaPreprocessor took 0.12s. New df shape: (5237760, 17).\n",
      "Processing ReduceMemUsageDataPreprocessor...\n",
      "Memory usage of dataframe is 719.30 MB\n",
      "Memory usage after optimization is: 344.66 MB\n",
      "Decreased by 52.08%\n",
      "dtypes:\n",
      "stock_id                     int16\n",
      "date_id                      int16\n",
      "seconds_in_bucket            int16\n",
      "imbalance_size             float32\n",
      "imbalance_buy_sell_flag       int8\n",
      "reference_price            float32\n",
      "matched_size               float32\n",
      "far_price                  float32\n",
      "near_price                 float32\n",
      "bid_price                  float32\n",
      "bid_size                   float32\n",
      "ask_price                  float32\n",
      "ask_size                   float32\n",
      "wap                        float32\n",
      "target                     float32\n",
      "time_id                      int16\n",
      "row_id                      object\n",
      "dtype: object\n",
      "ReduceMemUsageDataPreprocessor took 0.44s. New df shape: (5237760, 17).\n",
      "CompositeDataPreprocessor - final df shape: (5237760, 17)\n"
     ]
    }
   ],
   "source": [
    "# df_train = ReduceMemUsageDataPreprocessor(verbose=True).apply(df_train)\n",
    "df_train = processor.apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380277.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.500000</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.030273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666039e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.040039</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.089844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.028799e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.000000</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.191768e+07</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389746.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.899902</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.406250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010201</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.475500e+05</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.539062</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.100006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0    3.180603e+06   \n",
       "1         1        0                  0    1.666039e+05   \n",
       "2         2        0                  0    3.028799e+05   \n",
       "3         3        0                  0    1.191768e+07   \n",
       "4         4        0                  0    4.475500e+05   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380277.00        1.0   \n",
       "1                       -1         0.999896    1642214.25        1.0   \n",
       "2                       -1         0.999561    1819368.00        1.0   \n",
       "3                       -1         1.000171   18389746.00        1.0   \n",
       "4                       -1         0.999532   17860614.00        1.0   \n",
       "\n",
       "   near_price  bid_price      bid_size  ask_price       ask_size  wap  \\\n",
       "0         1.0   0.999812  60651.500000   1.000026    8493.030273  1.0   \n",
       "1         1.0   0.999896   3233.040039   1.000660   20605.089844  1.0   \n",
       "2         1.0   0.999403  37956.000000   1.000298   18995.000000  1.0   \n",
       "3         1.0   0.999999   2324.899902   1.000214  479032.406250  1.0   \n",
       "4         1.0   0.999394  16485.539062   1.000016     434.100006  1.0   \n",
       "\n",
       "     target  time_id row_id  \n",
       "0 -3.029704        0  0_0_0  \n",
       "1 -5.519986        0  0_0_1  \n",
       "2 -8.389950        0  0_0_2  \n",
       "3 -4.010201        0  0_0_3  \n",
       "4 -7.349849        0  0_0_4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:   0%|                                                                                                                                     | 0/10 [4:33:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/tsfresh/utilities/distribution.py\", line 43, in _function_with_partly_reduce\n    results = list(itertools.chain.from_iterable(results))\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/tsfresh/utilities/distribution.py\", line 42, in <genexpr>\n    results = (map_function(chunk, **kwargs) for chunk in chunk_list)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/extraction.py\", line 386, in _do_extraction_on_chunk\n    return list(_f())\n           ^^^^^^^^^^\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/extraction.py\", line 372, in _f\n    result = [(\"\", func(x))]\n                   ^^^^^^^\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/feature_calculators.py\", line 249, in variance_larger_than_standard_deviation\n    y = np.var(x)\n        ^^^^^^^^^\n  File \"<__array_function__ internals>\", line 200, in var\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/numpy/core/fromnumeric.py\", line 3747, in var\n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/userhome/cs2/tsangsyf/anaconda3_2/lib/python3.11/site-packages/numpy/core/_methods.py\", line 226, in _var\n    arrmean = um.true_divide(arrmean, div, out=arrmean,\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: unsupported operand type(s) for /: 'str' and 'int'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extracted_features \u001b[38;5;241m=\u001b[39m extract_features(df_train, column_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/extraction.py:164\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor, pivot)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m result \u001b[38;5;241m=\u001b[39m _do_extraction(\n\u001b[1;32m    165\u001b[0m     df\u001b[38;5;241m=\u001b[39mtimeseries_container,\n\u001b[1;32m    166\u001b[0m     column_id\u001b[38;5;241m=\u001b[39mcolumn_id,\n\u001b[1;32m    167\u001b[0m     column_value\u001b[38;5;241m=\u001b[39mcolumn_value,\n\u001b[1;32m    168\u001b[0m     column_kind\u001b[38;5;241m=\u001b[39mcolumn_kind,\n\u001b[1;32m    169\u001b[0m     column_sort\u001b[38;5;241m=\u001b[39mcolumn_sort,\n\u001b[1;32m    170\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    171\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    172\u001b[0m     disable_progressbar\u001b[38;5;241m=\u001b[39mdisable_progressbar,\n\u001b[1;32m    173\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[1;32m    174\u001b[0m     default_fc_parameters\u001b[38;5;241m=\u001b[39mdefault_fc_parameters,\n\u001b[1;32m    175\u001b[0m     kind_to_fc_parameters\u001b[38;5;241m=\u001b[39mkind_to_fc_parameters,\n\u001b[1;32m    176\u001b[0m     distributor\u001b[38;5;241m=\u001b[39mdistributor,\n\u001b[1;32m    177\u001b[0m     pivot\u001b[38;5;241m=\u001b[39mpivot,\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Impute the result if requested\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impute_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/extraction.py:294\u001b[0m, in \u001b[0;36m_do_extraction\u001b[0;34m(df, column_id, column_value, column_kind, column_sort, default_fc_parameters, kind_to_fc_parameters, n_jobs, chunk_size, disable_progressbar, show_warnings, distributor, pivot)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe passed distributor is not an DistributorBaseClass object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    288\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    289\u001b[0m     default_fc_parameters\u001b[38;5;241m=\u001b[39mdefault_fc_parameters,\n\u001b[1;32m    290\u001b[0m     kind_to_fc_parameters\u001b[38;5;241m=\u001b[39mkind_to_fc_parameters,\n\u001b[1;32m    291\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m result \u001b[38;5;241m=\u001b[39m distributor\u001b[38;5;241m.\u001b[39mmap_reduce(\n\u001b[1;32m    295\u001b[0m     _do_extraction_on_chunk,\n\u001b[1;32m    296\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    297\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[1;32m    298\u001b[0m     function_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    299\u001b[0m )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pivot:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/utilities/distribution.py:241\u001b[0m, in \u001b[0;36mIterableDistributorBaseClass.map_reduce\u001b[0;34m(self, map_function, data, function_kwargs, chunk_size, data_length)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute(\n\u001b[1;32m    237\u001b[0m             _function_with_partly_reduce, chunk_generator, map_kwargs\n\u001b[1;32m    238\u001b[0m         ),\n\u001b[1;32m    239\u001b[0m     )\n\u001b[0;32m--> 241\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(result))\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/multiprocessing/pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/utilities/distribution.py:43\u001b[0m, in \u001b[0;36m_function_with_partly_reduce\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     42\u001b[0m results \u001b[38;5;241m=\u001b[39m (map_function(chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_list)\n\u001b[0;32m---> 43\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(results))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/utilities/distribution.py:42\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mSmall helper function to call a function (map_function)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mon a list of data chunks (chunk_list) and convert the results into\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m:rtype: list\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 42\u001b[0m results \u001b[38;5;241m=\u001b[39m (map_function(chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_list)\n\u001b[1;32m     43\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(results))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/extraction.py:386\u001b[0m, in \u001b[0;36m_do_extraction_on_chunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_f())\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/extraction.py:372\u001b[0m, in \u001b[0;36m_f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    367\u001b[0m         result \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    368\u001b[0m             (convert_to_output_format(param), func(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam))\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameter_list\n\u001b[1;32m    370\u001b[0m         )\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m         result \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, func(x))]\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, item \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    375\u001b[0m     feature_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(kind) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/tsfresh/feature_extraction/feature_calculators.py:249\u001b[0m, in \u001b[0;36mvariance_larger_than_standard_deviation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;129m@set_property\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfctype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariance_larger_than_standard_deviation\u001b[39m(x):\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    Is variance higher than the standard deviation?\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    :return type: bool\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(x)\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(y)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvar\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3747\u001b[0m, in \u001b[0;36mvar\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3744\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3745\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m var(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_var(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof,\n\u001b[1;32m   3748\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3_2/lib/python3.11/site-packages/numpy/core/_methods.py:226\u001b[0m, in \u001b[0;36m_var\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrmean, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n\u001b[0;32m--> 226\u001b[0m         arrmean \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(arrmean, div, out\u001b[38;5;241m=\u001b[39marrmean,\n\u001b[1;32m    227\u001b[0m                                  casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arrmean, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    229\u001b[0m     arrmean \u001b[38;5;241m=\u001b[39m arrmean\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(arrmean \u001b[38;5;241m/\u001b[39m rcount)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "extracted_features = extract_features(df_train, column_id=\"stock_id\", column_sort=\"time_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_relevant_features\n",
    "\n",
    "features_filtered_direct = extract_relevant_features(timeseries, y,\n",
    "                                                     column_id='id', column_sort='time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
